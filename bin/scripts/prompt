#!/usr/bin/python3

"""
prompt - A TUI for interacting with multiple AI providers

This script provides a text-based user interface for chatting with various AI models
from different providers (Claude, Perplexity, Grok, Ollama). It supports:
- Switching between providers/models mid-conversation
- Maintaining conversation history across provider switches
- Saving conversations to files
- Sending messages to multiple models simultaneously
- Piping conversation output to other commands
"""

import os
import sys
import argparse
import logging
import json
import curses
import textwrap
import threading
import queue
import tempfile
import subprocess
import time
import re
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Tuple, Any, Union, Set, Match
from dataclasses import dataclass, field
from enum import Enum


# Set up logging if debug mode is enabled
def setup_logging(debug: bool) -> None:
    """Configure logging based on debug flag"""
    if debug:
        log_file = os.path.expanduser("~/prompt_debug.log")
        logging.basicConfig(
            filename=log_file,
            level=logging.DEBUG,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        logging.debug("Debug logging initialized")
    else:
        # Disable logging if not in debug mode
        logging.getLogger().disabled = True


# Check if we're in the dev distrobox container and re-exec if not
def ensure_distrobox() -> None:
    """Check if we're in the dev distrobox, if not re-exec the script inside it"""
    ctr_id = os.environ.get("CONTAINER_ID", "")
    
    if ctr_id != "dev":
        logging.debug("Not in dev container, re-execing inside distrobox")
        cmd = [
            "distrobox",
            "enter",
            "dev",
            "--",
            *sys.argv
        ]
        subprocess.run(cmd)
        sys.exit(0)


class MessageRole(Enum):
    """Enum for message roles in a conversation"""
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"


class Theme(Enum):
    """Enum for available color themes"""
    DEFAULT = "default"
    CATPPUCCIN_LATTE = "catppuccin-latte"
    CATPPUCCIN_FRAPPE = "catppuccin-frappe"
    CATPPUCCIN_MACCHIATO = "catppuccin-macchiato"
    CATPPUCCIN_MOCHA = "catppuccin-mocha"


@dataclass
class Message:
    """Represents a message in a conversation"""
    role: MessageRole
    content: str
    timestamp: float = field(default_factory=time.time)
    provider: Optional[str] = None
    model: Optional[str] = None


@dataclass
class Conversation:
    """Represents a full conversation history"""
    messages: List[Message] = field(default_factory=list)
    
    def add_message(self, message: Message) -> None:
        """Add a message to the conversation"""
        self.messages.append(message)
    
    def get_messages_for_provider(self, provider: str, model: str) -> List[Dict[str, Any]]:
        """
        Get messages formatted for a specific provider's API
        
        Different providers may have different message formats/requirements
        """
        # This is a base implementation - provider-specific classes can override
        formatted_messages = []
        for msg in self.messages:
            formatted_messages.append({
                "role": msg.role.value,
                "content": msg.content
            })
        return formatted_messages
    
    def to_markdown(self) -> str:
        """Convert the conversation to markdown format"""
        md = "# AI Conversation\n\n"
        
        for msg in self.messages:
            timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(msg.timestamp))
            
            if msg.provider and msg.model:
                md += f"## {msg.role.value.title()} ({msg.provider}/{msg.model}) - {timestamp}\n\n"
            else:
                md += f"## {msg.role.value.title()} - {timestamp}\n\n"
                
            md += f"{msg.content}\n\n"
            
        return md
    
    def to_json(self) -> str:
        """Convert the conversation to JSON format"""
        conversation_dict = {
            "messages": [
                {
                    "role": msg.role.value,
                    "content": msg.content,
                    "timestamp": msg.timestamp,
                    "provider": msg.provider,
                    "model": msg.model
                }
                for msg in self.messages
            ]
        }
        return json.dumps(conversation_dict, indent=2)


class AIProvider(ABC):
    """Base class for AI provider implementations"""
    
    @abstractmethod
    def get_name(self) -> str:
        """Get the name of the provider"""
        pass
    
    @abstractmethod
    def get_available_models(self) -> List[str]:
        """Get list of available models from this provider"""
        pass
    
    @abstractmethod
    def check_environment(self) -> bool:
        """Check if the necessary environment variables are set"""
        pass
    
    @abstractmethod
    def send_message(self, conversation: Conversation, model: str, 
                    response_queue: queue.Queue) -> None:
        """
        Send a message to the AI provider
        
        Args:
            conversation: Complete conversation history
            model: Model to use for this request
            response_queue: Queue to send response chunks to for display
        """
        pass


class ClaudeProvider(AIProvider):
    """Provider implementation for Anthropic's Claude"""
    
    def get_name(self) -> str:
        return "claude"
    
    def get_available_models(self) -> List[str]:
        return [
            "claude-3-7-sonnet-latest",
            "claude-3-5-sonnet-latest", 
            "claude-3-5-haiku-latest", 
            "claude-3-opus-latest", 
            "claude-3-sonnet-20240229", 
            "claude-3-haiku-20240307"
        ]
    
    def check_environment(self) -> bool:
        return "CLAUDE_API_KEY" in os.environ and os.environ["CLAUDE_API_KEY"] != ""
    
    def send_message(self, conversation: Conversation, model: str, 
                    response_queue: queue.Queue) -> None:
        try:
            import requests
            
            api_key = os.environ.get("CLAUDE_API_KEY", "")
            url = "https://api.anthropic.com/v1/messages"
            
            # Get the last user message
            user_messages = [msg for msg in conversation.messages if msg.role == MessageRole.USER]
            if not user_messages:
                response_queue.put(("ERROR", "No user message found in conversation"))
                return
            
            # Format messages for Claude API
            messages = []
            for msg in conversation.messages:
                messages.append({
                    "role": msg.role.value,
                    "content": msg.content
                })
            
            headers = {
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            
            data = {
                "model": model,
                "max_tokens": 4096,
                "messages": messages,
                "stream": True
            }
            
            logging.debug(f"Claude API request: {url}")
            logging.debug(f"Claude API headers: {headers['anthropic-version']}")
            logging.debug(f"Claude API data: {json.dumps(data)}")
            
            # Send request to Claude API with streaming
            response = requests.post(url, headers=headers, json=data, stream=True)
            
            if response.status_code != 200:
                error_msg = f"Error: {response.status_code}\n{response.text}"
                response_queue.put(("ERROR", error_msg))
                return
            
            # Process the streaming response
            full_response = ""
            for line in response.iter_lines():
                if line:
                    # Skip the initial "data: " prefix
                    line_text = line.decode('utf-8')
                    if line_text.startswith("data: "):
                        line_json = line_text[6:]
                        
                        # The last message is usually "data: [DONE]"
                        if line_json == "[DONE]":
                            break
                            
                        try:
                            event = json.loads(line_json)
                            # Extract content delta if it exists
                            if "delta" in event and "text" in event["delta"]:
                                chunk = event["delta"]["text"]
                                full_response += chunk
                                response_queue.put(("CHUNK", chunk))
                        except json.JSONDecodeError:
                            continue
            
            # Add the assistant's response to the conversation
            response_queue.put(("COMPLETE", {
                "role": MessageRole.ASSISTANT,
                "content": full_response,
                "provider": self.get_name(),
                "model": model
            }))
            
        except Exception as e:
            logging.error(f"Error in Claude provider: {str(e)}")
            response_queue.put(("ERROR", f"Error: {str(e)}"))


class PerplexityProvider(AIProvider):
    """Provider implementation for Perplexity AI"""
    
    def get_name(self) -> str:
        return "perplexity"
    
    def get_available_models(self) -> List[str]:
        return [
            "sonar-pro",
            "sonar", 
            "llama-3.1-sonar-small-128k-online", 
            "llama-3.1-sonar-large-128k-online", 
            "llama-3.1-sonar-huge-128k-online", 
            "llama-3.1-sonar-small-128k-chat", 
            "llama-3.1-sonar-large-128k-chat", 
            "llama-3.1-8b-instruct", 
            "llama-3.1-70b-instruct", 
            "reasoning-pro", 
            "sonar-reasoning-pro", 
            "r1-1776"
        ]
    
    def check_environment(self) -> bool:
        return "PERPLEXITY_TOKEN" in os.environ and os.environ["PERPLEXITY_TOKEN"] != ""
    
    def send_message(self, conversation: Conversation, model: str, 
                    response_queue: queue.Queue) -> None:
        try:
            from perplexipy import PerplexityClient
            
            api_key = os.environ.get("PERPLEXITY_TOKEN", "")
            
            client = PerplexityClient(key=api_key)
            client.model = model
            
            # Get the last user message
            user_messages = [msg for msg in conversation.messages if msg.role == MessageRole.USER]
            if not user_messages:
                response_queue.put(("ERROR", "No user message found in conversation"))
                return
            
            # For perplexity, we'll send the full conversation context
            full_context = ""
            for msg in conversation.messages:
                prefix = "User: " if msg.role == MessageRole.USER else "Assistant: "
                full_context += f"{prefix}{msg.content}\n\n"
            
            logging.debug(f"Perplexity request: model={model}")
            logging.debug(f"Perplexity context (truncated): {full_context[:100]}...")
            
            # Execute the API call with streaming
            full_response = ""
            results = client.queryStreamable(full_context)
            for result in results:
                response_queue.put(("CHUNK", result))
                full_response += result
            
            # Add the assistant's response to the conversation
            response_queue.put(("COMPLETE", {
                "role": MessageRole.ASSISTANT,
                "content": full_response,
                "provider": self.get_name(),
                "model": model
            }))
            
        except Exception as e:
            logging.error(f"Error in Perplexity provider: {str(e)}")
            response_queue.put(("ERROR", f"Error: {str(e)}"))


class GrokProvider(AIProvider):
    """Provider implementation for xAI Grok"""
    
    def get_name(self) -> str:
        return "grok"
    
    def get_available_models(self) -> List[str]:
        return [
            "grok-3-beta",
            "grok-3-mini-fast-beta", 
            "grok-3-fast-beta", 
            "grok-3-mini-beta", 
            "grok-2-1212",
            "grok-2-vision-1212"
        ]
    
    def check_environment(self) -> bool:
        return "GROK_API_KEY" in os.environ and os.environ["GROK_API_KEY"] != ""
    
    def send_message(self, conversation: Conversation, model: str, 
                    response_queue: queue.Queue) -> None:
        try:
            import requests
            
            api_key = os.environ.get("GROK_API_KEY", "")
            url = "https://api.x.ai/v1/chat/completions"
            
            # Format messages for Grok API
            messages = []
            for msg in conversation.messages:
                messages.append({
                    "role": msg.role.value,
                    "content": msg.content
                })
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "max_tokens": 4096,
                "messages": messages,
                "stream": True
            }
            
            logging.debug(f"Grok API request: {url}")
            logging.debug(f"Grok API data: {json.dumps(data)}")
            
            # Send request to Grok API with streaming
            response = requests.post(url, headers=headers, json=data, stream=True)
            
            if response.status_code != 200:
                error_msg = f"Error: {response.status_code}\n{response.text}"
                response_queue.put(("ERROR", error_msg))
                return
            
            # Process the streaming response
            full_response = ""
            for line in response.iter_lines():
                if line:
                    # Skip the initial "data: " prefix
                    line_text = line.decode('utf-8')
                    if line_text.startswith("data: "):
                        line_json = line_text[6:]
                        
                        # The last message is usually "data: [DONE]"
                        if line_json == "[DONE]":
                            break
                            
                        try:
                            event = json.loads(line_json)
                            # Extract content delta if it exists
                            if "choices" in event and len(event["choices"]) > 0:
                                choice = event["choices"][0]
                                if "delta" in choice and "content" in choice["delta"]:
                                    chunk = choice["delta"]["content"]
                                    full_response += chunk
                                    response_queue.put(("CHUNK", chunk))
                        except json.JSONDecodeError:
                            continue
            
            # Add the assistant's response to the conversation
            response_queue.put(("COMPLETE", {
                "role": MessageRole.ASSISTANT,
                "content": full_response,
                "provider": self.get_name(),
                "model": model
            }))
            
        except Exception as e:
            logging.error(f"Error in Grok provider: {str(e)}")
            response_queue.put(("ERROR", f"Error: {str(e)}"))


class OllamaProvider(AIProvider):
    """Provider implementation for Ollama (local models)"""
    
    def __init__(self):
        self.endpoint = "http://localhost:11434"
    
    def get_name(self) -> str:
        return "ollama"
    
    def get_available_models(self) -> List[str]:
        """
        Fetch available models from Ollama
        
        Note: This dynamically fetches from the Ollama instance
        """
        try:
            import requests
            
            url = f"{self.endpoint}/api/tags"
            response = requests.get(url)
            
            if response.status_code == 200:
                data = response.json()
                return [model["name"] for model in data.get("models", [])]
            else:
                logging.error(f"Failed to fetch Ollama models: {response.status_code}")
                return ["llama3.1:8b"]  # Default fallback
                
        except Exception as e:
            logging.error(f"Error fetching Ollama models: {str(e)}")
            return ["llama3.1:8b"]  # Default fallback
    
    def check_environment(self) -> bool:
        """
        For Ollama, we just check if the endpoint is reachable
        No API key needed as it's typically run locally
        """
        try:
            import requests
            response = requests.get(f"{self.endpoint}/api/version")
            return response.status_code == 200
        except:
            return False
    
    def send_message(self, conversation: Conversation, model: str, 
                    response_queue: queue.Queue) -> None:
        try:
            import requests
            
            url = f"{self.endpoint}/api/chat"
            
            # Format messages for Ollama API
            messages = []
            for msg in conversation.messages:
                messages.append({
                    "role": msg.role.value,
                    "content": msg.content
                })
            
            headers = {
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": messages,
                "stream": True
            }
            
            logging.debug(f"Ollama API request: {url}")
            logging.debug(f"Ollama API data: {json.dumps(data)}")
            
            # Send request to Ollama API with streaming
            response = requests.post(url, headers=headers, json=data, stream=True)
            
            if response.status_code != 200:
                error_msg = f"Error: {response.status_code}\n{response.text}"
                response_queue.put(("ERROR", error_msg))
                return
            
            # Process the streaming response
            full_response = ""
            for line in response.iter_lines():
                if line:
                    try:
                        event = json.loads(line.decode('utf-8'))
                        # Extract content from the message
                        if "message" in event and "content" in event["message"]:
                            chunk = event["message"]["content"]
                            full_response += chunk
                            response_queue.put(("CHUNK", chunk))
                        # Handle done message
                        if event.get("done", False):
                            break
                    except json.JSONDecodeError:
                        continue
            
            # Add the assistant's response to the conversation
            response_queue.put(("COMPLETE", {
                "role": MessageRole.ASSISTANT,
                "content": full_response,
                "provider": self.get_name(),
                "model": model
            }))
            
        except Exception as e:
            logging.error(f"Error in Ollama provider: {str(e)}")
            response_queue.put(("ERROR", f"Error: {str(e)}"))


class GeminiProvider(AIProvider):
    """Provider implementation for Google's Gemini"""
    
    def get_name(self) -> str:
        return "gemini"
    
    def get_available_models(self) -> List[str]:
        return [
            "gemini-2.5-pro-preview-05-06", 
            "gemini-2.5-flash-preview-04-17", 
            "gemini-2.0-flash", 
            "gemini-2.0-flash-preview-image-generation", 
            "gemini-2.0-flash-lite", 
            "gemini-1.5-flash", 
            "gemini-1.5-flash-8b", 
            "gemini-1.5-pro", 
            "gemini-embedding-exp", 
            "imagen-3.0-generate-002", 
            "veo-2.0-generate-001", 
            "gemini-2.0-flash-live-001", 
            "text-embedding-004", 
            "embedding-001", 
            "models/aqa"
        ]
    
    def check_environment(self) -> bool:
        return "GEMINI_API_KEY" in os.environ and os.environ["GEMINI_API_KEY"] != ""
    
    def send_message(self, conversation: Conversation, model: str, 
                    response_queue: queue.Queue) -> None:
        try:
            import requests
            
            api_key = os.environ.get("GEMINI_API_KEY", "")
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:streamGenerateContent"
            
            # Format messages for Gemini API
            messages = []
            for msg in conversation.messages:
                role = "user" if msg.role == MessageRole.USER else "model"
                messages.append({
                    "role": role,
                    "parts": [{"text": msg.content}]
                })
            
            headers = {
                "x-goog-api-key": api_key,
                "Content-Type": "application/json"
            }
            
            data = {
                "contents": messages,
                "generation_config": {
                    "max_output_tokens": 4096
                }
            }
            
            logging.debug(f"Gemini API request: {url}")
            logging.debug(f"Gemini API data: {json.dumps(data)}")
            
            # Send request to Gemini API with streaming
            response = requests.post(url, headers=headers, json=data, stream=True)
            
            if response.status_code != 200:
                error_msg = f"Error: {response.status_code}\n{response.text}"
                response_queue.put(("ERROR", error_msg))
                return
            
            # Process the streaming response
            full_response = ""
            
            # Initialize a buffer to handle potential partial JSON in the stream
            buffer = ""
            
            # Keep track of the last text we sent to avoid duplicates
            last_sent_text = ""
            processed_text_segments = set()
            
            # Compile regex pattern for extracting text fields
            import re
            text_pattern = re.compile(r'"text":\s*"((?:\\.|[^"\\])*)"')
            
            # Debug support
            logging.debug(f"Starting to process Gemini streaming response")
            
            # Use iter_content for more reliable streaming behavior
            for chunk in response.iter_content(chunk_size=1024):
                if not chunk:
                    continue
                    
                # Decode chunk and add to buffer    
                chunk_text = chunk.decode('utf-8')
                buffer += chunk_text
                
                logging.debug(f"Received chunk of size {len(chunk_text)}")
                
                # Try the regex approach first - extract any text fields
                matches = text_pattern.findall(buffer)
                if matches:
                    for match in matches:
                        # Unescape the JSON string and normalize spaces
                        text = match.encode('utf-8').decode('unicode_escape').replace('\u00a0', ' ')
                        
                        # Only send text we haven't seen before
                        if text != last_sent_text and text not in processed_text_segments:
                            full_response += text
                            response_queue.put(("CHUNK", text))
                            processed_text_segments.add(text)
                            last_sent_text = text
                
                # Also try to parse complete JSON objects
                try:
                    # Look for complete JSON objects (starts with { and ends with })
                    while buffer:
                        json_start = buffer.find('{')
                        if json_start == -1:
                            break
                            
                        # Find matching closing brace by tracking depth
                        json_depth = 0
                        json_end = -1
                        
                        for i, char in enumerate(buffer[json_start:]):
                            if char == '{':
                                json_depth += 1
                            elif char == '}':
                                json_depth -= 1
                                if json_depth == 0:
                                    json_end = json_start + i + 1
                                    break
                        
                        if json_end != -1:
                            # Extract complete JSON object
                            json_obj = buffer[json_start:json_end]
                            buffer = buffer[json_end:]
                            
                            # Try to parse and extract text
                            try:
                                data = json.loads(json_obj)
                                if "candidates" in data and len(data["candidates"]) > 0:
                                    for candidate in data["candidates"]:
                                        if "content" in candidate and "parts" in candidate["content"]:
                                            for part in candidate["content"]["parts"]:
                                                if "text" in part:
                                                    text = part["text"].replace('\u00a0', ' ')
                                                    if text != last_sent_text and text not in processed_text_segments:
                                                        full_response += text
                                                        response_queue.put(("CHUNK", text))
                                                        processed_text_segments.add(text)
                                                        last_sent_text = text
                            except json.JSONDecodeError:
                                pass  # Incomplete JSON, continue
                        else:
                            # No complete JSON found, keep buffer for next chunk
                            break
                except Exception as e:
                    logging.error(f"Error parsing JSON in Gemini stream: {str(e)}")
                    # Continue processing despite errors
            
            # Add the assistant's response to the conversation
            response_queue.put(("COMPLETE", {
                "role": MessageRole.ASSISTANT,
                "content": full_response,
                "provider": self.get_name(),
                "model": model
            }))
            
        except Exception as e:
            logging.error(f"Error in Gemini provider: {str(e)}")
            response_queue.put(("ERROR", f"Error: {str(e)}"))


class ProviderManager:
    """Manages all available AI providers"""
    
    def __init__(self):
        self.providers: Dict[str, AIProvider] = {}
        
        # Register all providers
        self._register_provider(ClaudeProvider())
        self._register_provider(PerplexityProvider())
        self._register_provider(GrokProvider())
        self._register_provider(OllamaProvider())
        self._register_provider(GeminiProvider())
    
    def _register_provider(self, provider: AIProvider) -> None:
        """Register a new provider"""
        self.providers[provider.get_name()] = provider
    
    def get_provider(self, name: str) -> Optional[AIProvider]:
        """Get a provider by name"""
        return self.providers.get(name)
    
    def get_available_providers(self) -> List[Tuple[str, bool]]:
        """
        Get list of all registered providers with availability status
        
        Returns:
            List of tuples (provider_name, is_available)
        """
        return [(name, provider.check_environment()) 
                for name, provider in self.providers.items()]
    
    def send_message(self, provider_name: str, model: str, 
                    conversation: Conversation, response_queue: queue.Queue) -> None:
        """Send a message using the specified provider and model"""
        provider = self.get_provider(provider_name)
        if not provider:
            response_queue.put(("ERROR", f"Provider '{provider_name}' not found"))
            return
        
        if not provider.check_environment():
            response_queue.put(("ERROR", f"Provider '{provider_name}' is not properly configured"))
            return
        
        # Send the message in a separate thread to keep the UI responsive
        thread = threading.Thread(
            target=provider.send_message,
            args=(conversation, model, response_queue)
        )
        thread.daemon = True
        thread.start()
        
        return thread


class CodeBlockExtractor:
    """Extracts code blocks from message content"""
    
    # Patterns for code block detection
    # Matches ```language\ncode\n``` or `code`
    FENCED_CODE_BLOCK_PATTERN = re.compile(r'```(?P<language>\w*)\s*\n(?P<code>.*?)\n```', re.DOTALL)
    INLINE_CODE_PATTERN = re.compile(r'`(?P<code>[^`]+)`')
    
    # Language-specific syntax highlighting patterns
    KEYWORDS = {
        'python': r'\b(def|class|if|else|elif|for|while|try|except|finally|import|from|as|return|yield|with|in|is|not|and|or|True|False|None)\b',
        'javascript': r'\b(function|const|let|var|if|else|for|while|try|catch|finally|return|await|async|new|class|import|export|this|typeof|instanceof)\b',
        'typescript': r'\b(function|const|let|var|if|else|for|while|try|catch|finally|return|await|async|new|class|import|export|this|interface|type|enum)\b',
        'java': r'\b(public|private|protected|class|interface|enum|static|final|void|if|else|for|while|try|catch|finally|return|new|this|super|abstract)\b',
        'go': r'\b(func|var|const|type|struct|interface|map|if|else|for|range|switch|case|default|defer|go|chan|select|package|import|return)\b',
        'rust': r'\b(fn|let|mut|const|struct|enum|trait|impl|if|else|for|while|loop|match|pub|crate|use|mod|self|static|async|await|unsafe)\b',
        'html': r'\b(html|head|body|div|span|p|a|img|table|tr|td|th|ul|ol|li|h1|h2|h3|h4|h5|h6|form|input|button|script|style)\b',
        'css': r'\b(color|background|margin|padding|font|width|height|display|position|border|flex|grid|animation|transition|transform)\b',
        'c': r'\b(int|char|float|double|void|struct|union|enum|if|else|for|while|do|switch|case|default|return|goto|break|continue|const|static)\b',
        'cpp': r'\b(class|template|namespace|public|private|protected|virtual|override|if|else|for|while|do|switch|case|default|try|catch|throw)\b',
        'text': r'\b()\b',  # No special keywords for plain text
        'bash': r'\b(if|then|else|elif|fi|for|while|until|do|done|case|esac|function|in|select|time|read|echo|exit)\b',
        'ruby': r'\b(def|class|module|if|else|elsif|unless|while|until|for|in|begin|rescue|ensure|end|attr|alias)\b',
        'php': r'\b(function|class|interface|trait|public|private|protected|if|else|elseif|for|foreach|while|switch|case|default|try|catch|finally)\b',
        'json': r'\b(true|false|null)\b',
        'shell': r'\b(if|then|else|elif|fi|for|while|until|do|done|case|esac|function|in|select|time|read|echo|exit)\b',
        'sql': r'\b(SELECT|FROM|WHERE|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP|TABLE|INDEX|JOIN|INNER|LEFT|RIGHT|FULL|ON|GROUP BY|ORDER BY|HAVING)\b',
        'yaml': r'\b(true|false|null|~)\b',
        'markdown': r'\b()\b',  # No special keywords for markdown
        'xml': r'\b(xml|version|encoding|DOCTYPE|html|head|body|div|span|p|a|img|table|tr|td|th)\b',
        'inline': r'\b()\b',  # No special keywords for inline code
    }
    
    # String patterns by language
    STRINGS = {
        'python': r'(\".*?\"|\'.*?\')',
        'javascript': r'(\".*?\"|\'.*?\'|`.*?`)',
        'typescript': r'(\".*?\"|\'.*?\'|`.*?`)',
        'java': r'(\".*?\")',
        'go': r'(\".*?\")',
        'rust': r'(\".*?\")',
        'html': r'(\".*?\"|\'.*?\')',
        'css': r'(\".*?\"|\'.*?\')',
        'c': r'(\".*?\")',
        'cpp': r'(\".*?\")',
        'text': r'',  # No special string handling for plain text
        'bash': r'(\".*?\"|\'.*?\')',
        'ruby': r'(\".*?\"|\'.*?\')',
        'php': r'(\".*?\"|\'.*?\')',
        'json': r'(\".*?\")',
        'shell': r'(\".*?\"|\'.*?\')',
        'sql': r'(\".*?\"|\'.*?\')',
        'yaml': r'(\".*?\"|\'.*?\')',
        'markdown': r'',  # No special string handling for markdown
        'xml': r'(\".*?\"|\'.*?\')',
        'inline': r'',  # No special string handling for inline code
    }
    
    # Comment patterns by language
    COMMENTS = {
        'python': r'(#.*?$)',
        'javascript': r'(\/\/.*?$|\/\*.*?\*\/)',
        'typescript': r'(\/\/.*?$|\/\*.*?\*\/)',
        'java': r'(\/\/.*?$|\/\*.*?\*\/)',
        'go': r'(\/\/.*?$|\/\*.*?\*\/)',
        'rust': r'(\/\/.*?$|\/\*.*?\*\/)',
        'html': r'(<!--.*?-->)',
        'css': r'(\/\*.*?\*\/)',
        'c': r'(\/\/.*?$|\/\*.*?\*\/)',
        'cpp': r'(\/\/.*?$|\/\*.*?\*\/)',
        'text': r'',  # No special comment handling for plain text
        'bash': r'(#.*?$)',
        'ruby': r'(#.*?$)',
        'php': r'(\/\/.*?$|\/\*.*?\*\/|#.*?$)',
        'json': r'',  # No comments in JSON
        'shell': r'(#.*?$)',
        'sql': r'(--.*?$|\/\*.*?\*\/)',
        'yaml': r'(#.*?$)',
        'markdown': r'',  # No special comment handling for markdown
        'xml': r'(<!--.*?-->)',
        'inline': r'',  # No special comment handling for inline code
    }
    
    # Number patterns by language
    NUMBERS = {
        'python': r'(\b\d+\.?\d*\b)',
        'javascript': r'(\b\d+\.?\d*\b)',
        'typescript': r'(\b\d+\.?\d*\b)',
        'java': r'(\b\d+\.?\d*\b)',
        'go': r'(\b\d+\.?\d*\b)',
        'rust': r'(\b\d+\.?\d*\b)',
        'html': r'(\b\d+\.?\d*\b)',
        'css': r'(\b\d+\.?\d*\b)',
        'c': r'(\b\d+\.?\d*\b)',
        'cpp': r'(\b\d+\.?\d*\b)',
        'text': r'',  # No special number handling for plain text
        'bash': r'(\b\d+\.?\d*\b)',
        'ruby': r'(\b\d+\.?\d*\b)',
        'php': r'(\b\d+\.?\d*\b)',
        'json': r'(\b\d+\.?\d*\b)',
        'shell': r'(\b\d+\.?\d*\b)',
        'sql': r'(\b\d+\.?\d*\b)',
        'yaml': r'(\b\d+\.?\d*\b)',
        'markdown': r'',  # No special number handling for markdown
        'xml': r'(\b\d+\.?\d*\b)',
        'inline': r'',  # No special number handling for inline code
    }
    
    # Operator patterns by language
    OPERATORS = {
        'python': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:)',
        'javascript': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'typescript': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'java': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'go': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:)',
        'rust': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:)',
        'html': r'(\=)',
        'css': r'(\:|\;|\{|\})',
        'c': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'cpp': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'text': r'',  # No special operator handling for plain text
        'bash': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\|)',
        'ruby': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'php': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\||\^|\~|\:|\?)',
        'json': r'(\:|\,)',
        'shell': r'(\+|\-|\*|\/|\%|\=|\<|\>|\!|\&|\|)',
        'sql': r'(\+|\-|\*|\/|\=|\<|\>|\!)',
        'yaml': r'(\:|\-)',
        'markdown': r'',  # No special operator handling for markdown
        'xml': r'(\=|\<|\>)',
        'inline': r'',  # No special operator handling for inline code
    }
    
    @staticmethod
    def extract_code_blocks(content: str) -> List[Tuple[str, str, int, int]]:
        """
        Extract code blocks from message content
        
        Returns:
            List of tuples: (language, code, start_pos, end_pos)
        """
        code_blocks = []
        
        # Find all fenced code blocks
        for match in CodeBlockExtractor.FENCED_CODE_BLOCK_PATTERN.finditer(content):
            language = match.group('language') or 'text'
            code = match.group('code')
            start_pos = match.start()
            end_pos = match.end()
            code_blocks.append((language, code, start_pos, end_pos))
        
        # Find all inline code blocks
        for match in CodeBlockExtractor.INLINE_CODE_PATTERN.finditer(content):
            code = match.group('code')
            start_pos = match.start()
            end_pos = match.end()
            code_blocks.append(('inline', code, start_pos, end_pos))
        
        return code_blocks

    @staticmethod
    def highlight_syntax(code: str, language: str) -> List[Tuple[str, int]]:
        """
        Apply syntax highlighting to code
        
        Returns:
            List of tuples: (code_segment, color_pair_number)
        """
        # Default to text if language not supported
        lang = language.lower()
        if lang not in CodeBlockExtractor.KEYWORDS:
            lang = 'text'
        
        # Basic syntax patterns to highlight
        patterns = [
            (re.compile(CodeBlockExtractor.KEYWORDS.get(lang, '')), 7),  # Keywords
            (re.compile(CodeBlockExtractor.STRINGS.get(lang, '')), 8),   # Strings
            (re.compile(CodeBlockExtractor.COMMENTS.get(lang, '')), 9),  # Comments
            (re.compile(CodeBlockExtractor.NUMBERS.get(lang, '')), 10),  # Numbers
            (re.compile(CodeBlockExtractor.OPERATORS.get(lang, '')), 11) # Operators
        ]
        
        # Build a map of character positions to their color pairs
        colors = [(0, len(code), 6)]  # Start with entire code as default color
        
        # Apply each pattern and update color map
        for pattern, color_pair in patterns:
            if not pattern.pattern:
                continue
                
            for match in pattern.finditer(code):
                start, end = match.span()
                # Add this colored segment
                colors.append((start, end, color_pair))
        
        # Sort by start position for rendering
        colors.sort(key=lambda x: x[0])
        
        return colors


class ThemeManager:
    """Manages color themes for the TUI"""
    
    # Catppuccin Mocha colors
    CATPPUCCIN_MOCHA = {
        "rosewater": 217,  # #f5e0dc
        "flamingo": 216,   # #f2cdcd
        "pink": 211,       # #f5c2e7
        "mauve": 183,      # #cba6f7
        "red": 203,        # #f38ba8
        "maroon": 210,     # #eba0ac
        "peach": 215,      # #fab387
        "yellow": 222,     # #f9e2af
        "green": 149,      # #a6e3a1
        "teal": 116,       # #94e2d5
        "sky": 117,        # #89dceb
        "sapphire": 110,   # #74c7ec
        "blue": 111,       # #89b4fa
        "lavender": 147,   # #b4befe
        "text": 253,       # #cdd6f4
        "subtext1": 246,   # #bac2de
        "subtext0": 245,   # #a6adc8
        "overlay2": 244,   # #9399b2
        "overlay1": 240,   # #7f849c
        "overlay0": 239,   # #6c7086
        "surface2": 238,   # #585b70
        "surface1": 237,   # #45475a
        "surface0": 236,   # #313244
        "base": 235,       # #1e1e2e
        "mantle": 234,     # #181825
        "crust": 233,      # #11111b
    }
    
    # Catppuccin Latte colors
    CATPPUCCIN_LATTE = {
        "rosewater": 217,  # #dc8a78
        "flamingo": 216,   # #dd7878
        "pink": 211,       # #ea76cb
        "mauve": 183,      # #8839ef
        "red": 203,        # #d20f39
        "maroon": 210,     # #e64553
        "peach": 215,      # #fe640b
        "yellow": 222,     # #df8e1d
        "green": 149,      # #40a02b
        "teal": 116,       # #179299
        "sky": 117,        # #04a5e5
        "sapphire": 110,   # #209fb5
        "blue": 111,       # #1e66f5
        "lavender": 147,   # #7287fd
        "text": 234,       # #4c4f69
        "subtext1": 238,   # #5c5f77
        "subtext0": 241,   # #6c6f85
        "overlay2": 244,   # #7c7f93
        "overlay1": 248,   # #8c8fa1
        "overlay0": 250,   # #9ca0b0
        "surface2": 252,   # #acb0be
        "surface1": 254,   # #bcc0cc
        "surface0": 255,   # #ccd0da
        "base": 255,       # #eff1f5
        "mantle": 254,     # #e6e9ef
        "crust": 255,      # #dce0e8
    }
    
    # Define theme color mappings
    THEMES = {
        Theme.DEFAULT: {
            "user": (curses.COLOR_GREEN, -1),
            "assistant": (curses.COLOR_BLUE, -1),
            "error": (curses.COLOR_RED, -1),
            "highlight": (curses.COLOR_YELLOW, -1),
            "separator": (curses.COLOR_WHITE, -1),
            "code_block": (curses.COLOR_WHITE, 236),  # Light text on dark background
            "code_keyword": (curses.COLOR_MAGENTA, 236),
            "code_string": (curses.COLOR_GREEN, 236),
            "code_comment": (curses.COLOR_CYAN, 236),
            "code_number": (curses.COLOR_RED, 236),
            "code_operator": (curses.COLOR_YELLOW, 236),
        },
        Theme.CATPPUCCIN_MOCHA: {
            "user": (CATPPUCCIN_MOCHA["green"], -1),
            "assistant": (CATPPUCCIN_MOCHA["blue"], -1),
            "error": (CATPPUCCIN_MOCHA["red"], -1),
            "highlight": (CATPPUCCIN_MOCHA["yellow"], -1),
            "separator": (CATPPUCCIN_MOCHA["lavender"], -1),
            "code_block": (CATPPUCCIN_MOCHA["text"], CATPPUCCIN_MOCHA["surface0"]),
            "code_keyword": (CATPPUCCIN_MOCHA["mauve"], CATPPUCCIN_MOCHA["surface0"]),
            "code_string": (CATPPUCCIN_MOCHA["green"], CATPPUCCIN_MOCHA["surface0"]),
            "code_comment": (CATPPUCCIN_MOCHA["overlay0"], CATPPUCCIN_MOCHA["surface0"]),
            "code_number": (CATPPUCCIN_MOCHA["peach"], CATPPUCCIN_MOCHA["surface0"]),
            "code_operator": (CATPPUCCIN_MOCHA["sky"], CATPPUCCIN_MOCHA["surface0"]),
        },
        Theme.CATPPUCCIN_LATTE: {
            "user": (CATPPUCCIN_LATTE["green"], -1),
            "assistant": (CATPPUCCIN_LATTE["blue"], -1),
            "error": (CATPPUCCIN_LATTE["red"], -1),
            "highlight": (CATPPUCCIN_LATTE["yellow"], -1),
            "separator": (CATPPUCCIN_LATTE["lavender"], -1),
            "code_block": (CATPPUCCIN_LATTE["text"], CATPPUCCIN_LATTE["surface0"]),
            "code_keyword": (CATPPUCCIN_LATTE["mauve"], CATPPUCCIN_LATTE["surface0"]),
            "code_string": (CATPPUCCIN_LATTE["green"], CATPPUCCIN_LATTE["surface0"]),
            "code_comment": (CATPPUCCIN_LATTE["overlay0"], CATPPUCCIN_LATTE["surface0"]),
            "code_number": (CATPPUCCIN_LATTE["peach"], CATPPUCCIN_LATTE["surface0"]),
            "code_operator": (CATPPUCCIN_LATTE["sky"], CATPPUCCIN_LATTE["surface0"]),
        },
    }
    
    @staticmethod
    def apply_theme(theme: Theme) -> None:
        """Apply the specified theme to curses color pairs"""
        if not curses.has_colors():
            return
            
        curses.start_color()
        curses.use_default_colors()  # Allow terminal default background (supports transparency)
        
        theme_colors = ThemeManager.THEMES.get(theme, ThemeManager.THEMES[Theme.DEFAULT])
        
        # Color pairs are indexed from 1
        curses.init_pair(1, theme_colors["user"][0], theme_colors["user"][1])
        curses.init_pair(2, theme_colors["assistant"][0], theme_colors["assistant"][1])
        curses.init_pair(3, theme_colors["error"][0], theme_colors["error"][1])
        curses.init_pair(4, theme_colors["highlight"][0], theme_colors["highlight"][1])
        curses.init_pair(5, theme_colors["separator"][0], theme_colors["separator"][1])
        
        # Code syntax colors (6-11)
        curses.init_pair(6, theme_colors["code_block"][0], theme_colors["code_block"][1])
        curses.init_pair(7, theme_colors["code_keyword"][0], theme_colors["code_keyword"][1])
        curses.init_pair(8, theme_colors["code_string"][0], theme_colors["code_string"][1])
        curses.init_pair(9, theme_colors["code_comment"][0], theme_colors["code_comment"][1])
        curses.init_pair(10, theme_colors["code_number"][0], theme_colors["code_number"][1])
        curses.init_pair(11, theme_colors["code_operator"][0], theme_colors["code_operator"][1])


class UIManager:
    """Manages the TUI interface using curses"""
    
    def __init__(self, stdscr, provider_manager: ProviderManager):
        self.stdscr = stdscr
        self.provider_manager = provider_manager
        self.conversation = Conversation()
        self.response_queue = queue.Queue()
        
        # UI state
        self.current_provider = None
        self.current_model = None
        self.input_buffer = ""
        self.cursor_pos = 0
        self.scroll_pos = 0
        self.max_scroll = 0
        self.active_providers: Set[Tuple[str, str]] = set()  # Set of (provider, model) tuples
        self.threads = []
        self.mode = "chat"  # chat, provider_select, model_select, help, theme_select, split_view
        self.view_mode = "normal"  # normal or split
        self.status_message = ""
        self.status_time = 0
        self.current_theme = Theme.DEFAULT
        self.split_view_column = 0  # Current column in split view
        self.split_view_scroll = {}  # Dict to store scroll position for each provider in split view
        
        # Set initial provider and model
        self._auto_select_provider()
        
        # Apply the default theme
        ThemeManager.apply_theme(self.current_theme)
    
    def _auto_select_provider(self) -> None:
        """Automatically select the first available provider and model"""
        available_providers = self.provider_manager.get_available_providers()
        for provider_name, available in available_providers:
            if available:
                self.current_provider = provider_name
                provider = self.provider_manager.get_provider(provider_name)
                models = provider.get_available_models()
                if models:
                    self.current_model = models[0]
                return
    
    def _add_message(self, message: Message) -> None:
        """Add a message to the conversation"""
        self.conversation.add_message(message)
        # Update visible lines calculation
        self._update_visible_lines()
        # Auto-scroll to bottom when new messages are added
        self.scroll_pos = self.max_scroll
    
    def _get_color(self, color_pair: int) -> int:
        """Get color attribute or default to normal if colors aren't supported"""
        if curses.has_colors():
            return curses.color_pair(color_pair)
        return curses.A_NORMAL
        
    def _change_theme(self, theme: Theme) -> None:
        """Change the current theme and apply it"""
        self.current_theme = theme
        ThemeManager.apply_theme(theme)
        self.set_status(f"Theme changed to {theme.value}")
    
    def set_status(self, message: str, error: bool = False) -> None:
        """Set a temporary status message"""
        self.status_message = message
        self.status_time = time.time()
        self.is_error = error
    
    def handle_input(self) -> bool:
        """
        Handle user input
        
        Returns:
            bool: True if the app should continue, False if it should exit
        """
        key = self.stdscr.getch()
        
        # If timeout occurred (-1) just continue without handling input
        if key == -1:
            return True
            
        # Universal key commands
        if key == curses.KEY_RESIZE:
            # Terminal resized, refresh UI
            return True
        elif key == 20:  # Ctrl+T
            # Switch to theme selection mode
            self.mode = "theme_select"
            return True
        elif key == 22:  # Ctrl+V
            # Toggle split view mode
            if len(self.active_providers) > 1:
                if self.view_mode == "normal":
                    self.view_mode = "split"
                    # Initialize split view scroll positions
                    self.split_view_scroll = {provider: 0 for provider in self.active_providers}
                    self.set_status("Split view enabled - Use Up/Down to scroll active pane")
                else:
                    self.view_mode = "normal"
                    self.set_status("Normal view enabled")
            else:
                self.set_status("Need at least 2 active providers for split view", True)
            return True
        elif key == 27:  # ESC
            if self.mode != "chat":
                # Return to chat mode from any other mode
                self.mode = "chat"
                return True
            # In chat mode, ask if user wants to quit
            self.set_status("Press Ctrl+Q to quit", False)
            return True
        elif key == 17:  # Ctrl+Q
            return False
        elif key == 18:  # Ctrl+R
            # Reset/clear conversation
            self.conversation = Conversation()
            self.set_status("Conversation cleared", False)
            return True
        elif key == 15:  # Ctrl+O
            # Save conversation
            self._save_conversation()
            return True
        elif key == 16:  # Ctrl+P
            # Switch to provider selection mode
            self.mode = "provider_select"
            return True
        elif key == 8:  # Ctrl+H
            # Switch to help mode
            self.mode = "help"
            return True
        
        # Mode-specific key handling
        if self.mode == "chat":
            return self._handle_chat_input(key)
        elif self.mode == "provider_select":
            return self._handle_provider_select_input(key)
        elif self.mode == "model_select":
            return self._handle_model_select_input(key)
        elif self.mode == "theme_select":
            return self._handle_theme_select_input(key)
        elif self.mode == "help":
            # Any key in help mode returns to chat
            self.mode = "chat"
            return True
        
        return True
    
    def _handle_chat_input(self, key: int) -> bool:
        """Handle input in chat mode"""
        if self.view_mode == "split" and len(self.active_providers) > 0:
            # Handle scrolling in split view mode
            active_providers = list(sorted(self.active_providers))
            current_provider = active_providers[self.split_view_column] if self.split_view_column < len(active_providers) else None
            
            if current_provider:
                # Get the scroll position for the current column
                if current_provider not in self.split_view_scroll:
                    self.split_view_scroll[current_provider] = 0
                
                if key == curses.KEY_UP:
                    # Scroll up in the current column
                    if self.split_view_scroll[current_provider] > 0:
                        self.split_view_scroll[current_provider] -= 3  # Scroll 3 lines at a time
                    return True
                elif key == curses.KEY_DOWN:
                    # Scroll down in the current column
                    # No max limit as it's handled per content
                    self.split_view_scroll[current_provider] += 3  # Scroll 3 lines at a time
                    return True
                elif key == curses.KEY_PPAGE:  # Page Up
                    # Scroll up by more lines at once
                    conv_height = self.stdscr.getmaxyx()[0] - 6
                    scroll_amount = max(1, conv_height // 2)
                    if self.split_view_scroll[current_provider] > 0:
                        self.split_view_scroll[current_provider] = max(0, self.split_view_scroll[current_provider] - scroll_amount)
                    return True
                elif key == curses.KEY_NPAGE:  # Page Down
                    # Scroll down by more lines at once
                    conv_height = self.stdscr.getmaxyx()[0] - 6
                    scroll_amount = max(1, conv_height // 2)
                    self.split_view_scroll[current_provider] += scroll_amount
                    return True
            
            # Handle column navigation in split view
            if key == curses.KEY_LEFT:
                # Navigate to previous column
                if self.split_view_column > 0:
                    self.split_view_column -= 1
                    provider = active_providers[self.split_view_column]
                    self.set_status(f"Column {self.split_view_column + 1}: {provider[0]}/{provider[1]}")
                return True
            elif key == curses.KEY_RIGHT:
                # Navigate to next column
                if self.split_view_column < len(active_providers) - 1:
                    self.split_view_column += 1
                    provider = active_providers[self.split_view_column]
                    self.set_status(f"Column {self.split_view_column + 1}: {provider[0]}/{provider[1]}")
                return True
        else:
            # Normal view mode scrolling
            if key == curses.KEY_PPAGE:  # Page Up
                # Scroll up by half a page
                conv_height = self.stdscr.getmaxyx()[0] - 3
                scroll_amount = max(1, conv_height // 2)
                if self.scroll_pos > 0:
                    self.scroll_pos = max(0, self.scroll_pos - scroll_amount)
                return True
            elif key == curses.KEY_NPAGE:  # Page Down
                # Scroll down by half a page
                conv_height = self.stdscr.getmaxyx()[0] - 3
                scroll_amount = max(1, conv_height // 2)
                if self.scroll_pos < self.max_scroll:
                    self.scroll_pos = min(self.max_scroll, self.scroll_pos + scroll_amount)
                return True
            elif key == curses.KEY_UP:
                # Scroll up
                if self.scroll_pos > 0:
                    self.scroll_pos = max(0, self.scroll_pos - 3)
                return True
            elif key == curses.KEY_DOWN:
                # Scroll down
                if self.scroll_pos < self.max_scroll:
                    self.scroll_pos = min(self.max_scroll, self.scroll_pos + 3)
                return True
        
        # Handle message sending with Enter key
        if key == curses.KEY_ENTER or key == 10 or key == 13:  # Enter
            if not self.input_buffer.strip():
                return True
            
            # Add user message to conversation
            user_message = Message(
                role=MessageRole.USER,
                content=self.input_buffer.strip()
            )
            self._add_message(user_message)
            
            # Clear input buffer
            self.input_buffer = ""
            self.cursor_pos = 0
            
            # If no active providers, use the current provider/model
            if not self.active_providers:
                if not self.current_provider or not self.current_model:
                    self.set_status("No provider/model selected", True)
                    return True
                
                # Send message to current provider/model
                thread = self.provider_manager.send_message(
                    self.current_provider,
                    self.current_model,
                    self.conversation,
                    self.response_queue
                )
                if thread:
                    self.threads.append(thread)
            else:
                # Send message to all active providers/models
                for provider_name, model in self.active_providers:
                    thread = self.provider_manager.send_message(
                        provider_name,
                        model,
                        self.conversation,
                        self.response_queue
                    )
                    if thread:
                        self.threads.append(thread)
            
            return True
            
        elif key == curses.KEY_BACKSPACE or key == 127 or key == 8:
            # Backspace
            if self.cursor_pos > 0:
                self.input_buffer = (self.input_buffer[:self.cursor_pos-1] + 
                                    self.input_buffer[self.cursor_pos:])
                self.cursor_pos -= 1
        elif key == curses.KEY_DC:
            # Delete
            if self.cursor_pos < len(self.input_buffer):
                self.input_buffer = (self.input_buffer[:self.cursor_pos] + 
                                    self.input_buffer[self.cursor_pos+1:])
        elif key == curses.KEY_LEFT:
            # Move cursor left
            if self.cursor_pos > 0:
                self.cursor_pos -= 1
        elif key == curses.KEY_RIGHT:
            # Move cursor right
            if self.cursor_pos < len(self.input_buffer):
                self.cursor_pos += 1
        elif key == curses.KEY_HOME:
            # Move cursor to start
            self.cursor_pos = 0
        elif key == curses.KEY_END:
            # Move cursor to end
            self.cursor_pos = len(self.input_buffer)
        elif key == curses.KEY_UP:
            # Scroll conversation up
            if self.scroll_pos > 0:
                self.scroll_pos -= 3  # Increase scroll amount for better UX
        elif key == curses.KEY_DOWN:
            # Scroll conversation down
            if self.scroll_pos < self.max_scroll:
                self.scroll_pos = min(self.max_scroll, self.scroll_pos + 3)  # Increase scroll amount
        elif key == 5:  # Ctrl+E
            # Edit current input in $EDITOR
            self.input_buffer = self._edit_in_external_editor(self.input_buffer)
            self.cursor_pos = len(self.input_buffer)
        elif key == 1:  # Ctrl+A
            # Add/remove current provider to active providers
            if self.current_provider and self.current_model:
                provider_model = (self.current_provider, self.current_model)
                if provider_model in self.active_providers:
                    self.active_providers.remove(provider_model)
                    self.set_status(f"Removed {self.current_provider}/{self.current_model} from active providers")
                else:
                    self.active_providers.add(provider_model)
                    self.set_status(f"Added {self.current_provider}/{self.current_model} to active providers")
        elif key == 24:  # Ctrl+X
            # Clear active providers
            self.active_providers.clear()
            self.set_status("Cleared active providers")
        elif key == 2:  # Ctrl+B
            # Toggle between available providers
            self._cycle_provider()
        elif key == 9:  # Tab
            # Switch to model selection mode
            self.mode = "model_select"
        elif key == 23:  # Ctrl+W
            # Delete word
            if self.cursor_pos > 0:
                # Find the start of the current word
                pos = self.cursor_pos - 1
                while pos > 0 and self.input_buffer[pos] == " ":
                    pos -= 1
                while pos > 0 and self.input_buffer[pos-1] != " ":
                    pos -= 1
                
                self.input_buffer = (self.input_buffer[:pos] + 
                                    self.input_buffer[self.cursor_pos:])
                self.cursor_pos = pos
        elif key == 21:  # Ctrl+U
            # Clear line
            self.input_buffer = ""
            self.cursor_pos = 0
        elif key == 11:  # Ctrl+K
            # Clear from cursor to end
            self.input_buffer = self.input_buffer[:self.cursor_pos]
        elif key >= 32 and key <= 126:
            # Printable character
            self.input_buffer = (self.input_buffer[:self.cursor_pos] + 
                                chr(key) + 
                                self.input_buffer[self.cursor_pos:])
            self.cursor_pos += 1
        
        return True
    
    def _handle_provider_select_input(self, key: int) -> bool:
        """Handle input in provider selection mode"""
        if key == curses.KEY_ENTER or key == 10 or key == 13:  # Enter
            # Return to chat mode
            self.mode = "chat"
            return True
        
        available_providers = self.provider_manager.get_available_providers()
        available_providers = [name for name, available in available_providers if available]
        
        if not available_providers:
            self.set_status("No providers available", True)
            self.mode = "chat"
            return True
        
        if key == curses.KEY_UP:
            # Select previous provider
            current_index = available_providers.index(self.current_provider) if self.current_provider in available_providers else 0
            new_index = (current_index - 1) % len(available_providers)
            self.current_provider = available_providers[new_index]
            
            # Auto-select first model for new provider
            provider = self.provider_manager.get_provider(self.current_provider)
            models = provider.get_available_models()
            if models:
                self.current_model = models[0]
                
        elif key == curses.KEY_DOWN:
            # Select next provider
            current_index = available_providers.index(self.current_provider) if self.current_provider in available_providers else 0
            new_index = (current_index + 1) % len(available_providers)
            self.current_provider = available_providers[new_index]
            
            # Auto-select first model for new provider
            provider = self.provider_manager.get_provider(self.current_provider)
            models = provider.get_available_models()
            if models:
                self.current_model = models[0]
                
        elif key == 9:  # Tab
            # Switch to model selection mode
            self.mode = "model_select"
        
        return True
    
    def _handle_model_select_input(self, key: int) -> bool:
        """Handle input in model selection mode"""
        if key == curses.KEY_ENTER or key == 10 or key == 13:  # Enter
            # Return to chat mode
            self.mode = "chat"
            return True
        
        if not self.current_provider:
            self.set_status("No provider selected", True)
            self.mode = "chat"
            return True
        
        provider = self.provider_manager.get_provider(self.current_provider)
        models = provider.get_available_models()
        
        if not models:
            self.set_status(f"No models available for {self.current_provider}", True)
            self.mode = "chat"
            return True
        
        if key == curses.KEY_UP:
            # Select previous model
            current_index = models.index(self.current_model) if self.current_model in models else 0
            new_index = (current_index - 1) % len(models)
            self.current_model = models[new_index]
        elif key == curses.KEY_DOWN:
            # Select next model
            current_index = models.index(self.current_model) if self.current_model in models else 0
            new_index = (current_index + 1) % len(models)
            self.current_model = models[new_index]
        elif key == 9:  # Tab
            # Switch back to provider selection mode
            self.mode = "provider_select"
        
        return True
    
    def _edit_in_external_editor(self, text: str) -> str:
        """Open an external editor to edit text"""
        editor = os.environ.get("EDITOR", "nano")
        
        with tempfile.NamedTemporaryFile(suffix=".md", mode="w+", delete=False) as temp:
            temp_filename = temp.name
            temp.write(text)
            temp.flush()
        
        try:
            subprocess.run([editor, temp_filename], check=True)
            with open(temp_filename, 'r') as temp:
                return temp.read()
        finally:
            os.unlink(temp_filename)
    
    def _save_conversation(self) -> None:
        """Save the conversation to a file or pipe it to a command"""
        # Set a special mode for saving
        height, width = self.stdscr.getmaxyx()
        
        # Clear the top line and draw prompt
        self.stdscr.addstr(0, 0, " " * (width - 1))
        self.stdscr.addstr(0, 0, "Save to file (or |command): ")
        self.stdscr.refresh()
        
        # Temporarily disable timeout to wait for user input
        self.stdscr.timeout(-1)  # Disable timeout (no keypresses needed)
        
        # Get filename with curses text input
        curses.echo()
        dest = self.stdscr.getstr(0, 28).decode('utf-8').strip()
        curses.noecho()
        
        # Restore timeout to original value (100ms from main loop)
        self.stdscr.timeout(100)
        
        if not dest:
            self.set_status("Save cancelled", False)
            return
        
        try:
            # Determine if we're piping to a command
            if dest.startswith('|'):
                command = dest[1:].strip()
                pipe_process = subprocess.Popen(
                    command, 
                    shell=True, 
                    stdin=subprocess.PIPE, 
                    text=True
                )
                pipe_process.communicate(input=self.conversation.to_markdown())
                if pipe_process.returncode == 0:
                    self.set_status(f"Conversation piped to '{command}'")
                else:
                    self.set_status(f"Error piping to '{command}'", True)
                    
            else:
                # Determine format based on extension
                if dest.endswith('.json'):
                    content = self.conversation.to_json()
                else:
                    # Default to markdown
                    content = self.conversation.to_markdown()
                    if not dest.endswith(('.md', '.markdown')):
                        dest += '.md'
                
                # Expand ~ in path
                dest = os.path.expanduser(dest)
                
                with open(dest, 'w') as f:
                    f.write(content)
                self.set_status(f"Conversation saved to {dest}")
                    
        except Exception as e:
            self.set_status(f"Error saving: {str(e)}", True)
            logging.error(f"Error saving conversation: {str(e)}")
    
    def _cycle_provider(self) -> None:
        """Cycle through available providers"""
        available_providers = self.provider_manager.get_available_providers()
        available_providers = [name for name, available in available_providers if available]
        
        if not available_providers:
            self.set_status("No providers available", True)
            return
        
        if not self.current_provider or self.current_provider not in available_providers:
            self.current_provider = available_providers[0]
        else:
            current_index = available_providers.index(self.current_provider)
            next_index = (current_index + 1) % len(available_providers)
            self.current_provider = available_providers[next_index]
        
        # Auto-select first model for new provider
        provider = self.provider_manager.get_provider(self.current_provider)
        models = provider.get_available_models()
        if models:
            self.current_model = models[0]
            
        self.set_status(f"Switched to {self.current_provider}/{self.current_model}")
    
    def draw(self) -> None:
        """Draw the UI"""
        self.stdscr.clear()
        height, width = self.stdscr.getmaxyx()
        
        if self.mode == "chat":
            self._draw_chat_mode(height, width)
        elif self.mode == "provider_select":
            self._draw_provider_select_mode(height, width)
        elif self.mode == "model_select":
            self._draw_model_select_mode(height, width)
        elif self.mode == "help":
            self._draw_help_mode(height, width)
        elif self.mode == "theme_select":
            self._draw_theme_select_mode(height, width)
        
        self.stdscr.refresh()
    
    def _update_visible_lines(self) -> None:
        """Update calculation of visible lines and max scroll position"""
        height, width = self.stdscr.getmaxyx()
        conv_height = height - 3  # Reserve 3 lines for input
        panel_width = 25
        main_width = width - panel_width - 1  # -1 for separator
        
        # Calculate how much of the screen can be used for conversation
        usable_height = max(conv_height - 2, 1)  # Reserve at least 1 line
        
        # Count lines needed for each message
        visible_lines = 0
        for msg in self.conversation.messages:
            # Role header
            visible_lines += 1
            
            # Extract code blocks to handle them correctly
            code_blocks = CodeBlockExtractor.extract_code_blocks(msg.content)
            
            if code_blocks:
                # Content with code blocks needs special handling
                current_pos = 0
                for language, code, start_pos, end_pos in code_blocks:
                    # Text before code block
                    if current_pos < start_pos:
                        text_before = msg.content[current_pos:start_pos]
                        text_lines = text_before.split('\n')
                        for line in text_lines:
                            line = line.replace('\t', '    ')  # 4 spaces per tab
                            if line.strip():
                                # Only count non-empty lines
                                wrapped_lines = textwrap.wrap(line, main_width - 2)
                                visible_lines += len(wrapped_lines)
                            else:
                                # Count empty lines
                                visible_lines += 1
                    
                    # Count the code block
                    if language == 'inline':
                        # Inline code counts as one line
                        visible_lines += 1
                    else:
                        # Add one line for opening backticks
                        visible_lines += 1
                        
                        # Count code content lines
                        code_lines = code.split('\n')
                        visible_lines += len(code_lines)
                        
                        # Add one line for closing backticks
                        visible_lines += 1
                    
                    # Update position
                    current_pos = end_pos
                
                # Text after last code block
                if current_pos < len(msg.content):
                    text_after = msg.content[current_pos:]
                    text_lines = text_after.split('\n')
                    for line in text_lines:
                        line = line.replace('\t', '    ')  # 4 spaces per tab
                        if line.strip():
                            # Only count non-empty lines
                            wrapped_lines = textwrap.wrap(line, main_width - 2)
                            visible_lines += len(wrapped_lines)
                        else:
                            # Count empty lines
                            visible_lines += 1
            else:
                # Standard content handling
                lines = msg.content.split('\n')
                for line in lines:
                    line = line.replace('\t', '    ')  # 4 spaces per tab
                    if line.strip():
                        # Only count non-empty lines
                        wrapped_lines = textwrap.wrap(line, main_width - 2)
                        visible_lines += len(wrapped_lines)
                    else:
                        # Count empty lines
                        visible_lines += 1
            
            # Empty line after message
            visible_lines += 1
        
        # Calculate max scroll position without extra buffer to allow using full height
        self.max_scroll = max(0, visible_lines - usable_height)
    
    def _draw_chat_mode(self, height: int, width: int) -> None:
        """Draw chat mode UI"""
        # Check if we're in split view mode
        if self.view_mode == "split" and len(self.active_providers) > 1:
            self._draw_split_view_mode(height, width)
            return
            
        # Calculate panel dimensions
        panel_width = 25
        main_width = width - panel_width - 1  # -1 for separator
        
        # Update visible lines calculation
        self._update_visible_lines()
        
        # Draw header for main panel (without showing active providers here)
        header = f" prompt - {self.current_provider}/{self.current_model}"
        self.stdscr.addstr(0, 0, header[:main_width-1])
        self.stdscr.addstr(0, len(header), " " * (main_width - len(header) - 1))
        
        # Draw status message if recent
        if self.status_message and time.time() - self.status_time < 3:
            status_attr = self._get_color(3) if self.is_error else curses.A_NORMAL
            self.stdscr.addstr(0, 0, self.status_message[:main_width-1], status_attr)
        
        # Draw vertical separator with themed color
        for y in range(height):
            self.stdscr.addstr(y, main_width, "", self._get_color(5))
            
        # Draw header for providers panel
        providers_header = " Active Providers "
        if len(providers_header) > panel_width:
            providers_header = providers_header[:panel_width]
        self.stdscr.addstr(0, main_width + 1, providers_header)
        self.stdscr.addstr(0, main_width + 1 + len(providers_header), 
                          " " * (panel_width - len(providers_header)))
                          
        # Draw list of active providers
        y_panel = 1
        if self.active_providers:
            for provider_name, model in sorted(self.active_providers):
                # Create formatted provider display
                provider_text = f" {provider_name}/{model}"
                if len(provider_text) > panel_width - 1:
                    # Truncate if too long
                    provider_text = provider_text[:panel_width - 4] + "..."
                
                # Highlight current provider/model
                attr = self._get_color(4) if (provider_name == self.current_provider and 
                                            model == self.current_model) else curses.A_NORMAL
                
                self.stdscr.addstr(y_panel, main_width + 1, provider_text, attr)
                self.stdscr.addstr(y_panel, main_width + 1 + len(provider_text), 
                                  " " * (panel_width - len(provider_text)))
                y_panel += 1
                
            # Add instruction for managing providers
            if y_panel < height - 4:
                y_panel += 1
                self.stdscr.addstr(y_panel, main_width + 1, " Ctrl+A: Add/Remove")
                y_panel += 1
                self.stdscr.addstr(y_panel, main_width + 1, " Ctrl+X: Clear All")
        else:
            # Show message when no providers are active
            self.stdscr.addstr(y_panel, main_width + 1, " None active")
            y_panel += 1
            self.stdscr.addstr(y_panel, main_width + 1, " Use Ctrl+A to add")
            y_panel += 1
        
        # Draw conversation area - use more vertical space
        conv_height = height - 3  # Reserve 3 lines for input
        
        y_pos = 1
        messages_to_show = []
        
        # Determine which messages to show based on scroll position
        visible_lines = 0
        temp_messages = []
        
        # Count lines needed for each message
        for msg in self.conversation.messages:
            msg_lines = 0
            
            # Role header
            role_text = f"[{msg.role.value.upper()}]"
            if msg.provider and msg.model:
                role_text += f" ({msg.provider}/{msg.model})"
            msg_lines += 1
            
            # Split by newlines first then wrap each line
            lines = msg.content.split('\n')
            wrapped_lines = []
            for line in lines:
                # Replace tabs with spaces
                line = line.replace('\t', '    ')  # 4 spaces per tab
                if line.strip():
                    # Only wrap non-empty lines
                    wrapped_lines.extend(textwrap.wrap(line, main_width - 2))
                else:
                    # Preserve empty lines
                    wrapped_lines.append('')
            msg_lines += len(wrapped_lines)
            
            # Add empty line after message
            msg_lines += 1
            
            temp_messages.append((msg, msg_lines))
            visible_lines += msg_lines
            
        # Calculate max scroll position - allow full pane usage
        usable_height = max(1, conv_height)  # Ensure we have at least 1 line
        self.max_scroll = max(0, visible_lines - usable_height)
        
        # Apply scroll position
        remaining_scroll = self.scroll_pos
        for msg, msg_lines in reversed(temp_messages):
            if remaining_scroll >= msg_lines:
                remaining_scroll -= msg_lines
                continue
            
            messages_to_show.insert(0, (msg, remaining_scroll))
            remaining_scroll = 0
            
            # Try to fill the screen with messages when possible
            if y_pos < conv_height * 0.6:  # If we're using less than 60% of available space
                # Add more messages if available (beyond what scroll position would show)
                if len(messages_to_show) < len(temp_messages):
                    # Get a few more messages to display
                    more_to_add = min(3, len(temp_messages) - len(messages_to_show))
                    for i in range(more_to_add):
                        if i < len(temp_messages) and temp_messages[i][0] not in [m[0] for m in messages_to_show]:
                            messages_to_show.append((temp_messages[i][0], 0))
        
        # Draw visible messages
        for msg, skip_lines in messages_to_show:
            if y_pos >= conv_height:
                break
                
            # Role header with color
            role_text = f"[{msg.role.value.upper()}]"
            if msg.provider and msg.model:
                role_text += f" ({msg.provider}/{msg.model})"
                
            color = 1 if msg.role == MessageRole.USER else 2
            if skip_lines <= 0:
                self.stdscr.addstr(y_pos, 1, role_text, self._get_color(color))
                y_pos += 1
            else:
                skip_lines -= 1
            
            # Extract code blocks for syntax highlighting
            code_blocks = CodeBlockExtractor.extract_code_blocks(msg.content)
            
            # If code blocks exist, handle them specially
            if code_blocks:
                # Split text by code block boundaries and process each segment
                current_pos = 0
                for language, code, start_pos, end_pos in code_blocks:
                    # Process text before code block
                    if current_pos < start_pos:
                        text_before = msg.content[current_pos:start_pos]
                        lines = text_before.split('\n')
                        for line in lines:
                            # Replace tabs with spaces
                            line = line.replace('\t', '    ')  # 4 spaces per tab
                            
                            if line.strip():
                                # Apply word wrapping to non-empty lines
                                wrapped_content = textwrap.wrap(line, main_width - 2)
                                for wrapped_line in wrapped_content:
                                    if skip_lines <= 0:
                                        if y_pos < conv_height:
                                            self.stdscr.addstr(y_pos, 1, wrapped_line)
                                            y_pos += 1
                                    else:
                                        skip_lines -= 1
                            else:
                                # Preserve empty lines
                                if skip_lines <= 0:
                                    if y_pos < conv_height:
                                        self.stdscr.addstr(y_pos, 1, "")
                                        y_pos += 1
                                else:
                                    skip_lines -= 1
                    
                    # Process code block with syntax highlighting
                    if language == 'inline':
                        # Handle inline code - single line, no highlighting
                        if skip_lines <= 0:
                            if y_pos < conv_height:
                                try:
                                    # Calculate available width to prevent writing past screen
                                    available_width = main_width - 4  # Allow some margin
                                    
                                    # Truncate code if it's too long
                                    display_code = code
                                    if len(code) > available_width - 2:  # Account for backticks
                                        display_code = code[:available_width - 5] + "..."
                                    
                                    self.stdscr.addstr(y_pos, 1, "`", self._get_color(6))
                                    self.stdscr.addstr(y_pos, 2, display_code, self._get_color(6))
                                    self.stdscr.addstr(y_pos, 2 + len(display_code), "`", self._get_color(6))
                                except curses.error:
                                    # Handle potential drawing errors gracefully
                                    logging.debug(f"Error rendering inline code: {code[:20]}...")
                                
                                y_pos += 1
                        else:
                            skip_lines -= 1
                    else:
                        # Add language header for code block
                        if skip_lines <= 0:
                            if y_pos < conv_height:
                                try:
                                    self.stdscr.addstr(y_pos, 1, f"```{language}", self._get_color(6))
                                except curses.error:
                                    # Handle potential drawing errors gracefully
                                    logging.debug(f"Error rendering code block header")
                                y_pos += 1
                        else:
                            skip_lines -= 1
                            
                        # Process code with syntax highlighting
                        code_lines = code.split('\n')
                        for code_line in code_lines:
                            if skip_lines <= 0:
                                if y_pos < conv_height:
                                    # Apply syntax highlighting to this line
                                    if code_line.strip():
                                        # Replace tabs with spaces
                                        code_line = code_line.replace('\t', '    ')
                                        
                                        # Get highlighting for this line
                                        highlight_map = CodeBlockExtractor.highlight_syntax(code_line, language)
                                        
                                        try:
                                            # Calculate available width
                                            available_width = main_width - 2
                                            
                                            # Render highlighted line
                                            x_pos = 1
                                            total_written = 0
                                            
                                            for start, end, color_pair in highlight_map:
                                                segment = code_line[start:end]
                                                if segment:
                                                    # Check if adding this segment would exceed screen width
                                                    if total_written + len(segment) >= available_width:
                                                        # Truncate and add ellipsis if there's room
                                                        remaining = available_width - total_written - 3
                                                        if remaining > 0:
                                                            self.stdscr.addstr(y_pos, x_pos, segment[:remaining], self._get_color(color_pair))
                                                            x_pos += remaining
                                                            self.stdscr.addstr(y_pos, x_pos, "...", self._get_color(4))
                                                        break
                                                        
                                                    # Safe to write the full segment
                                                    self.stdscr.addstr(y_pos, x_pos, segment, self._get_color(color_pair))
                                                    x_pos += len(segment)
                                                    total_written += len(segment)
                                        except curses.error:
                                            # Handle potential drawing errors gracefully
                                            logging.debug(f"Error rendering code: {code_line[:20]}...")
                                    else:
                                        # Empty line in code block
                                        try:
                                            self.stdscr.addstr(y_pos, 1, "", self._get_color(6))
                                        except curses.error:
                                            logging.debug("Error rendering empty line in code block")
                                    y_pos += 1
                            else:
                                skip_lines -= 1
                        
                        # Add code block closing
                        if skip_lines <= 0:
                            if y_pos < conv_height:
                                try:
                                    self.stdscr.addstr(y_pos, 1, "```", self._get_color(6))
                                except curses.error:
                                    # Handle potential drawing errors gracefully
                                    logging.debug(f"Error rendering code block footer")
                                y_pos += 1
                        else:
                            skip_lines -= 1
                    
                    # Update current position
                    current_pos = end_pos
                
                # Process any remaining text after the last code block
                if current_pos < len(msg.content):
                    text_after = msg.content[current_pos:]
                    lines = text_after.split('\n')
                    for line in lines:
                        # Replace tabs with spaces
                        line = line.replace('\t', '    ')  # 4 spaces per tab
                        
                        if line.strip():
                            # Apply word wrapping to non-empty lines
                            wrapped_content = textwrap.wrap(line, main_width - 2)
                            for wrapped_line in wrapped_content:
                                if skip_lines <= 0:
                                    if y_pos < conv_height:
                                        self.stdscr.addstr(y_pos, 1, wrapped_line)
                                        y_pos += 1
                                else:
                                    skip_lines -= 1
                        else:
                            # Preserve empty lines
                            if skip_lines <= 0:
                                if y_pos < conv_height:
                                    self.stdscr.addstr(y_pos, 1, "")
                                    y_pos += 1
                            else:
                                skip_lines -= 1
            else:
                # No code blocks, just process as normal text
                lines = msg.content.split('\n')
                for line in lines:
                    # Replace tabs with spaces
                    line = line.replace('\t', '    ')  # 4 spaces per tab
                    
                    if line.strip():
                        # Apply word wrapping to non-empty lines
                        wrapped_content = textwrap.wrap(line, main_width - 2)
                        for wrapped_line in wrapped_content:
                            if skip_lines <= 0:
                                if y_pos < conv_height:
                                    self.stdscr.addstr(y_pos, 1, wrapped_line)
                                    y_pos += 1
                            else:
                                skip_lines -= 1
                    else:
                        # Preserve empty lines
                        if skip_lines <= 0:
                            if y_pos < conv_height:
                                self.stdscr.addstr(y_pos, 1, "")
                                y_pos += 1
                        else:
                            skip_lines -= 1
            
            # Empty line after message
            if y_pos < conv_height and skip_lines <= 0:
                y_pos += 1
        
        # Fill remaining conversation area
        while y_pos < conv_height:
            self.stdscr.addstr(y_pos, 0, " " * (main_width - 1))
            y_pos += 1
        
        # Draw horizontal separator
        self.stdscr.addstr(conv_height, 0, "" * (main_width - 1))
        
        # Draw input area
        prompt = "> "
        self.stdscr.addstr(conv_height + 1, 0, prompt)
        
        # Determine visible part of input based on cursor position
        visible_start = max(0, self.cursor_pos - (main_width - len(prompt) - 5))
        visible_input = self.input_buffer[visible_start:visible_start+main_width-len(prompt)-1]
        
        self.stdscr.addstr(conv_height + 1, len(prompt), visible_input)
        self.stdscr.addstr(conv_height + 1, len(prompt) + len(visible_input), " " * (main_width - len(prompt) - len(visible_input) - 1))
        
        # Draw shortcuts help line
        shortcuts = "/: Scroll | PgUp/PgDn: Page Scroll | Ctrl+P: Provider | Tab: Model | Ctrl+T: Theme | Ctrl+V: Split View | Ctrl+A: Add/Remove | Ctrl+X: Clear | Ctrl+O: Save | Ctrl+Q: Quit"
        if len(shortcuts) > main_width - 1:
            shortcuts = shortcuts[:main_width-4] + "..."
        self.stdscr.addstr(height - 1, 0, shortcuts)
        
        # Position cursor in input field
        cursor_x = len(prompt) + (self.cursor_pos - visible_start)
        self.stdscr.move(conv_height + 1, cursor_x)
    
    def _draw_provider_select_mode(self, height: int, width: int) -> None:
        """Draw provider selection mode UI"""
        # Draw header
        self.stdscr.addstr(0, 0, " Select AI Provider ")
        self.stdscr.addstr(0, 18, "" * (width - 19))
        
        # Get available providers
        available_providers = self.provider_manager.get_available_providers()
        
        # Draw provider list
        y_pos = 2
        for i, (provider_name, available) in enumerate(available_providers):
            prefix = " " if provider_name == self.current_provider else "  "
            status = "[AVAILABLE]" if available else "[UNAVAILABLE]"
            
            # Color based on selection and availability
            if provider_name == self.current_provider:
                attr = self._get_color(4)  # Highlight color
            elif not available:
                attr = curses.A_DIM
            else:
                attr = curses.A_NORMAL
                
            # Provider name and status
            self.stdscr.addstr(y_pos, 2, f"{prefix}{provider_name} {status}", attr)
            y_pos += 1
            
            # Show information about provider
            if available:
                provider = self.provider_manager.get_provider(provider_name)
                models_count = len(provider.get_available_models())
                
                self.stdscr.addstr(y_pos, 4, f" {models_count} model(s) available")
                y_pos += 1
                
                # If this is the current provider, list some models
                if provider_name == self.current_provider:
                    models = provider.get_available_models()[:3]  # Show only first 3
                    for model in models:
                        model_str = f" {model}"
                        if model == self.current_model:
                            model_str += " [SELECTED]"
                            self.stdscr.addstr(y_pos, 6, model_str, self._get_color(4))
                        else:
                            self.stdscr.addstr(y_pos, 6, model_str)
                        y_pos += 1
                    
                    if len(provider.get_available_models()) > 3:
                        self.stdscr.addstr(y_pos, 6, f" ... and {len(provider.get_available_models()) - 3} more")
                        y_pos += 1
            else:
                # Show reason why provider is unavailable
                if provider_name == "claude":
                    self.stdscr.addstr(y_pos, 4, " Missing CLAUDE_API_KEY environment variable")
                elif provider_name == "perplexity":
                    self.stdscr.addstr(y_pos, 4, " Missing PERPLEXITY_TOKEN environment variable")
                elif provider_name == "grok":
                    self.stdscr.addstr(y_pos, 4, " Missing GROK_API_KEY environment variable")
                elif provider_name == "ollama":
                    self.stdscr.addstr(y_pos, 4, " Ollama service not running or unreachable")
                y_pos += 1
            
            # Add spacing between providers
            y_pos += 1
        
        # Draw instructions
        self.stdscr.addstr(height - 3, 0, "" * (width - 1))
        self.stdscr.addstr(height - 2, 2, "/: Navigate | Tab: Model Selection | Enter: Confirm | Esc: Cancel")
    
    def _draw_model_select_mode(self, height: int, width: int) -> None:
        """Draw model selection mode UI"""
        if not self.current_provider:
            self.stdscr.addstr(0, 0, " No provider selected ")
            self.stdscr.addstr(0, 21, "" * (width - 22))
            self.stdscr.addstr(2, 2, "Please select a provider first (Esc, then Ctrl+P)")
            return
        
        # Draw header
        self.stdscr.addstr(0, 0, f" Select {self.current_provider} Model ")
        self.stdscr.addstr(0, len(f" Select {self.current_provider} Model "), "" * (width - len(f" Select {self.current_provider} Model ") - 1))
        
        # Get models for current provider
        provider = self.provider_manager.get_provider(self.current_provider)
        models = provider.get_available_models()
        
        # Draw model list
        y_pos = 2
        for i, model_name in enumerate(models):
            prefix = " " if model_name == self.current_model else "  "
            
            # Color based on selection
            if model_name == self.current_model:
                attr = self._get_color(4)  # Highlight color
            else:
                attr = curses.A_NORMAL
                
            # Model name
            self.stdscr.addstr(y_pos, 2, f"{prefix}{model_name}", attr)
            y_pos += 1
        
        # Draw instructions
        self.stdscr.addstr(height - 3, 0, "" * (width - 1))
        self.stdscr.addstr(height - 2, 2, "/: Navigate | Tab: Provider Selection | Enter: Confirm | Esc: Cancel")
    
    def _draw_theme_select_mode(self, height: int, width: int) -> None:
        """Draw theme selection mode UI"""
        # Draw header
        self.stdscr.addstr(0, 0, " Select Theme ")
        self.stdscr.addstr(0, 14, "" * (width - 15))
        
        # List all available themes
        themes = list(Theme)
        y_pos = 2
        
        for i, theme in enumerate(themes):
            prefix = " " if theme == self.current_theme else "  "
            
            # Highlight current selection
            attr = self._get_color(4) if theme == self.current_theme else curses.A_NORMAL
            
            # Theme name and description
            theme_name = theme.value
            self.stdscr.addstr(y_pos, 2, f"{prefix}{theme_name}", attr)
            y_pos += 2
        
        # Draw instructions
        self.stdscr.addstr(height - 3, 0, "" * (width - 1))
        self.stdscr.addstr(height - 2, 2, "/: Navigate | Enter: Select | Esc: Cancel")
    
    def _handle_theme_select_input(self, key: int) -> bool:
        """Handle input in theme selection mode"""
        if key == curses.KEY_ENTER or key == 10 or key == 13:  # Enter
            # Apply selected theme and return to chat mode
            self._change_theme(self.current_theme)
            self.mode = "chat"
            return True
        
        themes = list(Theme)
        
        if key == curses.KEY_UP:
            # Select previous theme
            current_index = themes.index(self.current_theme)
            new_index = (current_index - 1) % len(themes)
            self.current_theme = themes[new_index]
        elif key == curses.KEY_DOWN:
            # Select next theme
            current_index = themes.index(self.current_theme)
            new_index = (current_index + 1) % len(themes)
            self.current_theme = themes[new_index]
        
        return True
        
    def _draw_split_view_mode(self, height: int, width: int) -> None:
        """Draw split view mode UI with side-by-side provider responses"""
        # Get the list of active providers
        active_providers = list(sorted(self.active_providers))
        if not active_providers:
            # Fallback to normal view if no active providers
            self.view_mode = "normal"
            self._draw_chat_mode(height, width)
            return
            
        # Calculate column dimensions
        num_columns = len(active_providers)
        column_width = width // num_columns
        
        # Draw header for split view
        header = " Split View | Left/Right: Navigate Columns "
        self.stdscr.addstr(0, 0, header)
        self.stdscr.addstr(0, len(header), "" * (width - len(header) - 1))
        
        # Draw provider columns
        for i, (provider, model) in enumerate(active_providers):
            # Calculate the column position
            col_x = i * column_width
            
            # Draw column separator except for first column
            if i > 0:
                for y in range(1, height - 1):
                    self.stdscr.addstr(y, col_x - 1, "", self._get_color(5))
            
            # Highlight current column
            attr = self._get_color(4) if i == self.split_view_column else curses.A_NORMAL
            
            # Draw column header
            col_header = f" {provider}/{model}"
            if len(col_header) > column_width - 2:
                col_header = col_header[:column_width - 5] + "..."
            self.stdscr.addstr(1, col_x, col_header, attr)
            
            # Get the current provider key for scrolling
            current_provider = (provider, model)
            
            # Find the most recent message pair for this provider
            user_message = None
            provider_message = None
            
            # Debug - output provider model tuple
            logging.debug(f"Looking for responses from provider={provider}, model={model}")
            
            # First, find the most recent assistant message from this provider
            for j in range(len(self.conversation.messages) - 1, -1, -1):
                msg = self.conversation.messages[j]
                
                if (msg.role == MessageRole.ASSISTANT and 
                    msg.provider == provider and 
                    msg.model == model):
                    
                    provider_message = msg
                    logging.debug(f"Found provider message: {msg.provider}/{msg.model}: {msg.content[:20]}...")
                    break
            
            # Then find the most recent user message before that assistant message
            if provider_message:
                for j in range(len(self.conversation.messages) - 1, -1, -1):
                    msg = self.conversation.messages[j]
                    
                    if (msg.role == MessageRole.USER and 
                        msg.timestamp < provider_message.timestamp):
                        
                        user_message = msg
                        logging.debug(f"Found user message: {msg.content[:20]}...")
                        break
            
            # Draw the messages in this column
            if provider_message:
                # Draw user message if available
                y_pos = 3
                if user_message:
                    user_prefix = "User: "
                    user_text = user_message.content
                    
                    # Word wrap with smaller width for the columns
                    wrapped_user = textwrap.wrap(user_text, column_width - 3)
                    
                    self.stdscr.addstr(y_pos, col_x, user_prefix, self._get_color(1))
                    y_pos += 1
                    
                    for line in wrapped_user[:3]:  # Limit to first 3 lines
                        if y_pos < height - 8:  # Reserve more space for response
                            self.stdscr.addstr(y_pos, col_x, line)
                            y_pos += 1
                    
                    if len(wrapped_user) > 3:
                        self.stdscr.addstr(y_pos, col_x, "...")
                        y_pos += 1
                    
                    y_pos += 1
                
                # Draw assistant message (always shown)
                assistant_prefix = f"{provider}: "
                self.stdscr.addstr(y_pos, col_x, assistant_prefix, self._get_color(2))
                y_pos += 1
                
                # Get the response content
                response_text = provider_message.content
                
                # Word wrap the response
                wrapped_response = textwrap.wrap(response_text, column_width - 3)
                
                # Apply column-specific scrolling
                if current_provider not in self.split_view_scroll:
                    self.split_view_scroll[current_provider] = 0
                    
                # Skip lines based on scroll position
                skip_lines = self.split_view_scroll[current_provider]
                
                # Adjust skip_lines if it's too large (avoid empty display)
                if skip_lines >= len(wrapped_response):
                    # Limit scrolling to leave at least the last page visible
                    available_lines = height - y_pos - 3
                    max_scroll = max(0, len(wrapped_response) - available_lines // 2)
                    skip_lines = min(skip_lines, max_scroll)
                    self.split_view_scroll[current_provider] = skip_lines
                
                # Draw the wrapped response with scrolling
                available_lines = height - y_pos - 3  # Space for response
                visible_lines = 0
                
                for line_idx, line in enumerate(wrapped_response):
                    if line_idx < skip_lines:
                        continue  # Skip lines above scroll position
                        
                    if visible_lines >= available_lines:
                        # Show truncation indicator
                        self.stdscr.addstr(y_pos, col_x, "... ( to scroll)", self._get_color(4))
                        break
                    
                    self.stdscr.addstr(y_pos, col_x, line)
                    y_pos += 1
                    visible_lines += 1
                    
                # Show scroll indicator at top if scrolled down
                if skip_lines > 0 and y_pos > 10:  # Only if there's room
                    self.stdscr.addstr(10, col_x, "... ( to scroll)", self._get_color(4))
            else:
                # No messages yet
                self.stdscr.addstr(3, col_x, "No response yet from this provider")
        
        # Draw horizontal separator
        self.stdscr.addstr(height - 2, 0, "" * (width - 1))
        
        # Draw input field and help
        prompt = "> "
        self.stdscr.addstr(height - 1, 0, prompt)
        
        # Determine visible part of input
        visible_start = max(0, self.cursor_pos - (width - len(prompt) - 5))
        visible_input = self.input_buffer[visible_start:visible_start+width-len(prompt)-1]
        
        self.stdscr.addstr(height - 1, len(prompt), visible_input)
        
        # Position cursor in input field
        cursor_x = len(prompt) + (self.cursor_pos - visible_start)
        self.stdscr.move(height - 1, cursor_x)
        
    def _draw_help_mode(self, height: int, width: int) -> None:
        """Draw help mode UI"""
        # Draw header
        self.stdscr.addstr(0, 0, " prompt Help ")
        self.stdscr.addstr(0, 13, "" * (width - 14))
        
        # Draw help content
        y_pos = 2
        help_text = [
            "Keyboard Shortcuts:",
            "",
            "Chat Mode:",
            "  Enter          Send message",
            "  Ctrl+E         Open message in external editor ($EDITOR)",
            "  Ctrl+P         Switch to provider selection",
            "  Tab            Switch to model selection",
            "  Ctrl+A         Add/remove current provider/model to active set",
            "  Ctrl+X         Clear active providers",
            "  Ctrl+B         Cycle through available providers",
            "  Ctrl+O         Save conversation (to file or pipe to command)",
            "  Ctrl+R         Reset/clear conversation",
            "  Ctrl+T         Change theme",
            "  Ctrl+V         Toggle split view mode (with multiple active providers)",
            "  Ctrl+Q         Quit",
            "  /            Scroll conversation history",
            "  Ctrl+U         Clear entire input",
            "  Ctrl+K         Clear input from cursor to end",
            "  Ctrl+W         Delete word",
            "",
            "Provider/Model Selection:",
            "  /            Navigate options",
            "  Tab            Switch between provider/model selection",
            "  Enter          Confirm selection",
            "  Esc            Cancel and return to chat",
            "",
            "Active Providers:",
            "  When multiple providers are active, messages will be sent to all of them.",
            "  This allows you to compare responses from different models simultaneously.",
            "",
            "Saving Conversations:",
            "  You can save to a file: ~/conversation.md",
            "  Or pipe to a command: |vipe > ~/conversation.md",
            "  Format is determined by extension (.md or .json)"
        ]
        
        for i, line in enumerate(help_text):
            if y_pos + i >= height - 1:
                break
            
            if not line:
                self.stdscr.addstr(y_pos + i, 2, "")
            elif line.endswith(":"):
                # Section headers
                self.stdscr.addstr(y_pos + i, 2, line, curses.A_BOLD)
            elif line.startswith("  "):
                # Shortcut descriptions
                parts = line.split("  ", 2)
                if len(parts) >= 3:
                    key, desc = parts[1], parts[2]
                    self.stdscr.addstr(y_pos + i, 2, "  ")
                    self.stdscr.addstr(y_pos + i, 4, key, self._get_color(4))
                    self.stdscr.addstr(y_pos + i, 4 + len(key) + (10 - len(key)), desc)
                else:
                    self.stdscr.addstr(y_pos + i, 2, line)
            else:
                self.stdscr.addstr(y_pos + i, 2, line)
        
        # Draw footer
        self.stdscr.addstr(height - 2, 2, "Press any key to return to chat")
    
    def process_responses(self) -> None:
        """Process any responses in the queue"""
        try:
            # Calculate the total visible lines height first to set max_scroll correctly
            height, _ = self.stdscr.getmaxyx()
            conv_height = height - 3
            self._update_visible_lines()
            
            response_received = False
            while not self.response_queue.empty():
                msg_type, data = self.response_queue.get_nowait()
                response_received = True
                
                if msg_type == "CHUNK":
                    # For streaming responses, we need to update the latest assistant message
                    # or create a new one if this is the start of a response
                    assistant_messages = [msg for msg in self.conversation.messages 
                                         if msg.role == MessageRole.ASSISTANT]
                    
                    if assistant_messages and assistant_messages[-1].provider is None:
                        # Update the last assistant message that's still being streamed
                        assistant_messages[-1].content += data
                        # Update scrolling to show latest content
                        self._update_visible_lines()
                        # Keep scroll at bottom during streaming
                        self.scroll_pos = self.max_scroll
                    else:
                        # Create a new assistant message
                        self._add_message(Message(
                            role=MessageRole.ASSISTANT,
                            content=data
                        ))
                
                elif msg_type == "COMPLETE":
                    # Response is complete - update message with final data
                    msg_data = data
                    
                    # Find the incomplete assistant message
                    for i, msg in enumerate(self.conversation.messages):
                        if msg.role == MessageRole.ASSISTANT and msg.provider is None:
                            # Update with provider info
                            self.conversation.messages[i].provider = msg_data["provider"]
                            self.conversation.messages[i].model = msg_data["model"]
                            break
                
                elif msg_type == "ERROR":
                    # Add error as assistant message
                    self._add_message(Message(
                        role=MessageRole.ASSISTANT,
                        content=f"ERROR: {data}",
                        provider="system",
                        model="error"
                    ))
                
                # Update scrolling - make sure we're at the bottom during streaming
                self._update_visible_lines()
                if response_received:
                    self.scroll_pos = self.max_scroll
                    
                self.response_queue.task_done()
        except Exception as e:
            logging.error(f"Error processing responses: {str(e)}")


def main(stdscr) -> None:
    """Main function for the curses application"""
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Interactive TUI for chatting with different AI providers")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")
    args = parser.parse_args()
    
    # Setup logging
    setup_logging(args.debug)
    
    # Ensure we're in the dev distrobox
    ensure_distrobox()
    
    # Configure curses
    curses.curs_set(1)  # Show cursor
    curses.noecho()  # Don't echo input
    curses.cbreak()  # React to keys without Enter
    stdscr.keypad(True)  # Enable special keys
    
    # Initialize managers
    provider_manager = ProviderManager()
    ui_manager = UIManager(stdscr, provider_manager)
    
    # Set up colors for optimal display
    if curses.can_change_color():
        # Try to initialize 256 color mode if available
        try:
            curses.start_color()
            curses.use_default_colors()
        except:
            pass
    
    # Main loop
    while True:
        # Process any responses from providers
        ui_manager.process_responses()
        
        # Draw UI
        ui_manager.draw()
        
        # Set timeout for getch (100ms) to allow for UI updates without keypresses
        stdscr.timeout(100)
        
        # Handle input (returns False to exit)
        if not ui_manager.handle_input():
            break


if __name__ == "__main__":
    try:
        curses.wrapper(main)
    except KeyboardInterrupt:
        # Handle Ctrl+C gracefully
        pass
    except Exception as e:
        # Fall back to basic error reporting if curses fails
        import traceback
        print(f"Error: {str(e)}")
        print(traceback.format_exc())