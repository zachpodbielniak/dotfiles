#!/usr/bin/python3

# dotfiles - Personal configuration files and scripts
# Copyright (C) 2025  Zach Podbielniak
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.


import os
import sys
import subprocess

# Container check for distrobox - do this BEFORE any other imports
ctr_id = os.environ.get("CONTAINER_ID", "")
no_dbox_check = os.environ.get("NO_DBOX_CHECK", "").lower() in ("1", "true")
if not no_dbox_check and ctr_id != "dev":
    cmd = ["distrobox", "enter", "dev", "--", *sys.argv]
    subprocess.run(cmd)
    sys.exit(0)

# Now import everything else inside the dev container
try:
    import argparse
    import json
    import psycopg2
    from psycopg2.extras import RealDictCursor
    from datetime import datetime
    from typing import Optional, List, Dict, Any
    from tabulate import tabulate
    from colorama import init, Fore, Style, Back
    import yaml
    import tempfile
    import shutil
except ImportError as e:
    # We're inside dev container but missing dependencies
    print(f"Error: Missing required Python module: {e}", file=sys.stderr)
    print("Please install the required dependencies:", file=sys.stderr)
    print("  pip install psycopg2-binary tabulate colorama pyyaml", file=sys.stderr)
    sys.exit(1)

# Initialize colorama for cross-platform color support
init(autoreset=True)

# Configuration with environment variables
DB_CONFIG = {
    'host': os.environ.get('TRANSCRIPTION_DB_HOST', '127.0.0.1'),
    'port': int(os.environ.get('TRANSCRIPTION_DB_PORT', '5432')),
    'database': os.environ.get('TRANSCRIPTION_DB_NAME', 'transcriptions'),
    'user': os.environ.get('TRANSCRIPTION_DB_USER', 'postgres'),
    'password': os.environ.get('TRANSCRIPTION_DB_PASSWORD', '')
}

class TranscriptionManager:
    def __init__(self, no_color: bool = False):
        self.no_color = no_color
        self.conn = None
        self.cursor = None
        self._connect()
    
    def _connect(self):
        """Establish persistent database connection"""
        try:
            self.conn = psycopg2.connect(**DB_CONFIG)
            self.cursor = self.conn.cursor(cursor_factory=RealDictCursor)
        except psycopg2.Error as e:
            self._error(f"Database connection failed: {e}")
            sys.exit(1)
    
    def __del__(self):
        """Clean up database connection"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.close()
    
    def _color(self, text: str, color: str) -> str:
        """Apply color to text unless no_color is set"""
        if self.no_color:
            return text
        return f"{color}{text}{Style.RESET_ALL}"
    
    def _error(self, message: str):
        """Print error message"""
        print(self._color(f"Error: {message}", Fore.RED), file=sys.stderr)
    
    def _success(self, message: str):
        """Print success message"""
        print(self._color(message, Fore.GREEN))
    
    def _info(self, message: str):
        """Print info message"""
        print(self._color(message, Fore.CYAN))
    
    def _format_date(self, dt: datetime) -> str:
        """Format datetime for display"""
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    
    def search(self, query: str, limit: int = 10, type_filter: Optional[str] = None,
               tags_filter: Optional[List[str]] = None, output_format: str = 'text',
               verbose: bool = False) -> None:
        """Search transcriptions using full-text search"""
        
        # Build WHERE clauses
        where_clauses = ["tc.content_vector @@ plainto_tsquery('english', %s)"]
        params = [query]
        
        if type_filter:
            where_clauses.append("t.metadata->>'type' = %s")
            params.append(type_filter)
        
        if tags_filter:
            tag_conditions = []
            for tag in tags_filter:
                tag_conditions.append("t.metadata->'tags' ? %s")
                params.append(tag.strip())
            if tag_conditions:
                where_clauses.append(f"({' OR '.join(tag_conditions)})")
        
        where_clause = " AND ".join(where_clauses)
        
        # Main search query
        sql = f"""
        SELECT DISTINCT ON (t.id)
            t.id,
            t.filename,
            t.file_path,
            t.metadata,
            t.transcribed_at,
            ts_rank(tc.content_vector, plainto_tsquery('english', %s)) as rank,
            ts_headline('english', tc.content, plainto_tsquery('english', %s),
                'StartSel=**, StopSel=**, MaxWords=50, MinWords=20') as snippet
        FROM transcriptions t
        JOIN transcription_chunks tc ON t.id = tc.transcription_id
        WHERE {where_clause}
        ORDER BY t.id, rank DESC
        LIMIT %s
        """
        
        params.extend([query, query, limit])
        
        if verbose:
            print(f"DEBUG: SQL Query: {sql}")
            print(f"DEBUG: Params: {params}")
        
        try:
            self.cursor.execute(sql, params)
            results = self.cursor.fetchall()
            
            if output_format == 'json':
                print(json.dumps([dict(r) for r in results], default=str, indent=2))
            elif output_format == 'yaml':
                yaml_data = {'results': []}
                for r in results:
                    item = {
                        'id': str(r['id']),
                        'filename': r['filename'],
                        'transcribed_at': self._format_date(r['transcribed_at']),
                        'rank': float(r['rank']),
                        'snippet': r['snippet'].replace("''", "'")
                    }
                    if r['file_path']:
                        item['file_path'] = r['file_path']
                    if r['metadata']:
                        if r['metadata'].get('type'):
                            item['type'] = r['metadata']['type']
                        if r['metadata'].get('tags'):
                            item['tags'] = r['metadata']['tags']
                    yaml_data['results'].append(item)
                print(yaml.dump(yaml_data, default_flow_style=False))
            elif output_format == 'simple':
                for r in results:
                    print(r['filename'])
            else:  # text format with nice table
                if not results:
                    self._info("No results found.")
                    return
                
                print(self._color(f"\nSearch results for: \"{query}\"", Fore.YELLOW))
                print(self._color("=" * 50, Fore.YELLOW))
                
                table_data = []
                for i, r in enumerate(results, 1):
                    metadata_info = []
                    if r['metadata']:
                        if r['metadata'].get('type'):
                            metadata_info.append(f"Type: {self._color(r['metadata']['type'], Fore.MAGENTA)}")
                        if r['metadata'].get('tags'):
                            tags_colored = [self._color(tag, Fore.BLUE) for tag in r['metadata']['tags']]
                            metadata_info.append(f"Tags: {', '.join(tags_colored)}")
                    
                    snippet = r['snippet'].replace("''", "'")
                    # Highlight matched terms in snippet
                    if not self.no_color:
                        snippet = snippet.replace("**", f"{Fore.YELLOW}{Style.BRIGHT}")
                        snippet = snippet.replace("**", f"{Style.RESET_ALL}")
                    
                    table_data.append([
                        self._color(str(i), Fore.WHITE + Style.BRIGHT),
                        self._color(r['filename'], Fore.CYAN),  # Filename in cyan
                        self._color(self._format_date(r['transcribed_at']), Fore.WHITE),
                        '\n'.join(metadata_info) if metadata_info else self._color('None', Fore.LIGHTBLACK_EX),
                        snippet[:100] + '...' if len(snippet) > 100 else snippet
                    ])
                
                headers = [
                    self._color('#', Fore.WHITE + Style.BRIGHT),
                    self._color('Filename', Fore.CYAN + Style.BRIGHT),
                    self._color('Transcribed', Fore.WHITE + Style.BRIGHT),
                    self._color('Metadata', Fore.YELLOW + Style.BRIGHT),
                    self._color('Snippet', Fore.YELLOW + Style.BRIGHT)
                ]
                print(tabulate(table_data, headers=headers, tablefmt='grid'))
                print(f"\nFound {len(results)} results.")
                
        except psycopg2.Error as e:
            self._error(f"Search failed: {e}")
    
    def view(self, identifier: str, show_metadata: bool = False, 
             output_format: str = 'text', no_timestamps: bool = False) -> None:
        """View full transcription content"""
        
        # Check if identifier looks like a partial UUID (8-36 hex chars with optional dashes)
        import re
        uuid_pattern = re.compile(r'^[0-9a-fA-F-]{8,36}$')
        is_uuid_like = bool(uuid_pattern.match(identifier))
        
        # Determine if identifier is UUID or filename
        is_uuid = False
        if is_uuid_like:
            try:
                # Try to parse as full UUID
                import uuid
                uuid.UUID(identifier)
                is_uuid = True
            except ValueError:
                # Not a full UUID, but might be a partial one
                # Check if it's a valid partial UUID (at least 8 hex chars)
                hex_only = identifier.replace('-', '')
                if len(hex_only) >= 8 and all(c in '0123456789abcdefABCDEF' for c in hex_only):
                    # Try to find a matching UUID
                    self.cursor.execute("""
                        SELECT id FROM transcriptions 
                        WHERE id::text LIKE %s
                        ORDER BY transcribed_at DESC
                    """, [f"{identifier}%"])
                    matches = self.cursor.fetchall()
                    
                    if len(matches) == 0:
                        self._error(f"No transcription found matching partial UUID: {identifier}")
                        return
                    elif len(matches) > 1:
                        self._error(f"Multiple transcriptions found matching partial UUID: {identifier}")
                        print("Please use a longer UUID prefix to uniquely identify the transcription:")
                        for match in matches[:5]:  # Show first 5 matches
                            print(f"  - {match['id']}")
                        if len(matches) > 5:
                            print(f"  ... and {len(matches) - 5} more")
                        return
                    else:
                        # Exactly one match - use it
                        identifier = str(matches[0]['id'])
                        is_uuid = True
        
        # Always aggregate chunks in order to get the full content
        # Use newline separator to properly join chunks
        if is_uuid:
            sql = """
            SELECT t.*, 
                   string_agg(tc.content, E'\n' ORDER BY tc.chunk_number) as full_content
            FROM transcriptions t
            LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id
            WHERE t.id = %s::uuid
            GROUP BY t.id
            """
            params = [identifier]
        else:
            sql = """
            SELECT t.*, 
                   string_agg(tc.content, E'\n' ORDER BY tc.chunk_number) as full_content
            FROM transcriptions t
            LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id
            WHERE t.filename = %s
            GROUP BY t.id
            ORDER BY t.transcribed_at DESC
            LIMIT 1
            """
            params = [identifier]
        
        try:
            self.cursor.execute(sql, params)
            result = self.cursor.fetchone()
            
            if not result:
                self._error(f"No transcription found for: {identifier}")
                return
            
            if output_format == 'json':
                output = dict(result)
                print(json.dumps(output, default=str, indent=2))
            elif output_format == 'yaml':
                output = {
                    'transcription': {
                        'id': str(result['id']),
                        'filename': result['filename'],
                        'transcribed_at': self._format_date(result['transcribed_at']),
                        'content': result['full_content']
                    }
                }
                if result['file_path']:
                    output['transcription']['file_path'] = result['file_path']
                if result['model_used']:
                    output['transcription']['model_used'] = result['model_used']
                if result['duration_seconds']:
                    output['transcription']['duration_seconds'] = result['duration_seconds']
                if result['metadata']:
                    if result['metadata'].get('type'):
                        output['transcription']['type'] = result['metadata']['type']
                    if result['metadata'].get('tags'):
                        output['transcription']['tags'] = result['metadata']['tags']
                print(yaml.dump(output, default_flow_style=False))
            elif output_format == 'simple':
                content = result['full_content']
                if content:
                    lines = content.split('\n')
                    if no_timestamps:
                        # Show only lines without timestamps
                        filtered_lines = [line for line in lines 
                                        if not (line.strip().startswith('[') and '-->' in line)]
                    else:
                        # Check if there are any timestamped lines
                        timestamped_lines = [line for line in lines 
                                           if line.strip().startswith('[') and '-->' in line]
                        if timestamped_lines:
                            # Show only timestamped lines if they exist
                            filtered_lines = timestamped_lines
                        else:
                            # No timestamps found, show all content
                            filtered_lines = lines
                    
                    print('\n'.join(filtered_lines))
            else:  # text format
                if show_metadata:
                    print(self._color("=== METADATA ===", Fore.CYAN))
                    metadata_table = [
                        ['ID', str(result['id'])],
                        ['Filename', result['filename']],
                        ['Path', result['file_path'] or 'N/A'],
                        ['Transcribed', self._format_date(result['transcribed_at'])],
                        ['Model', result['model_used'] or 'unknown'],
                        ['Duration', f"{result['duration_seconds']} seconds" if result['duration_seconds'] else 'unknown']
                    ]
                    
                    if result['metadata']:
                        if result['metadata'].get('type'):
                            metadata_table.append(['Type', result['metadata']['type']])
                        if result['metadata'].get('tags'):
                            metadata_table.append(['Tags', ', '.join(result['metadata']['tags'])])
                    
                    print(tabulate(metadata_table, tablefmt='plain'))
                    print(self._color("\n=== TRANSCRIPTION ===", Fore.CYAN))
                
                # Filter content based on timestamps preference
                content = result['full_content']
                if content:
                    lines = content.split('\n')
                    if no_timestamps:
                        # Show only lines without timestamps
                        filtered_lines = [line for line in lines 
                                        if not (line.strip().startswith('[') and '-->' in line)]
                    else:
                        # Check if there are any timestamped lines
                        timestamped_lines = [line for line in lines 
                                           if line.strip().startswith('[') and '-->' in line]
                        if timestamped_lines:
                            # Show only timestamped lines if they exist
                            filtered_lines = timestamped_lines
                        else:
                            # No timestamps found, show all content
                            filtered_lines = lines
                    
                    print('\n'.join(filtered_lines))
                
        except psycopg2.Error as e:
            self._error(f"View failed: {e}")
    
    def list(self, limit: int = 10, type_filter: Optional[str] = None,
             tags_filter: Optional[List[str]] = None, output_format: str = 'text') -> None:
        """List recent transcriptions"""
        
        # Build WHERE clause
        where_clauses = []
        params = []
        
        if type_filter:
            where_clauses.append("metadata->>'type' = %s")
            params.append(type_filter)
        
        if tags_filter:
            tag_conditions = []
            for tag in tags_filter:
                tag_conditions.append("metadata->'tags' ? %s")
                params.append(tag.strip())
            if tag_conditions:
                where_clauses.append(f"({' OR '.join(tag_conditions)})")
        
        where_clause = "WHERE " + " AND ".join(where_clauses) if where_clauses else ""
        
        sql = f"""
        SELECT id, filename, file_path, transcribed_at, metadata
        FROM transcriptions
        {where_clause}
        ORDER BY transcribed_at DESC
        LIMIT %s
        """
        params.append(limit)
        
        try:
            self.cursor.execute(sql, params)
            results = self.cursor.fetchall()
            
            if output_format == 'json':
                print(json.dumps([dict(r) for r in results], default=str, indent=2))
            elif output_format == 'yaml':
                yaml_data = {'transcriptions': []}
                for r in results:
                    item = {
                        'id': str(r['id']),
                        'filename': r['filename'],
                        'transcribed_at': self._format_date(r['transcribed_at'])
                    }
                    if r['file_path']:
                        item['file_path'] = r['file_path']
                    if r['metadata']:
                        if r['metadata'].get('type'):
                            item['type'] = r['metadata']['type']
                        if r['metadata'].get('tags'):
                            item['tags'] = r['metadata']['tags']
                    yaml_data['transcriptions'].append(item)
                print(yaml.dump(yaml_data, default_flow_style=False))
            elif output_format == 'simple':
                for r in results:
                    print(r['filename'])
            else:  # text format with nice table
                if not results:
                    self._info("No transcriptions found.")
                    return
                
                print(self._color("\nRecent transcriptions:", Fore.YELLOW))
                print(self._color("=" * 80, Fore.YELLOW))
                
                table_data = []
                for r in results:
                    metadata_info = []
                    if r['metadata']:
                        if r['metadata'].get('type'):
                            metadata_info.append(self._color(r['metadata']['type'], Fore.MAGENTA))
                        if r['metadata'].get('tags'):
                            tags_colored = [self._color(tag, Fore.BLUE) for tag in r['metadata']['tags']]
                            metadata_info.append(', '.join(tags_colored))
                    
                    table_data.append([
                        self._color(str(r['id']), Fore.GREEN),  # UUID in green
                        self._color(r['filename'], Fore.CYAN),   # Filename in cyan
                        self._color(self._format_date(r['transcribed_at']), Fore.WHITE),
                        ' | '.join(metadata_info) if metadata_info else self._color('None', Fore.LIGHTBLACK_EX)
                    ])
                
                headers = [
                    self._color('ID', Fore.GREEN + Style.BRIGHT),
                    self._color('Filename', Fore.CYAN + Style.BRIGHT),
                    self._color('Transcribed', Fore.WHITE + Style.BRIGHT),
                    self._color('Type/Tags', Fore.YELLOW + Style.BRIGHT)
                ]
                print(tabulate(table_data, headers=headers, tablefmt='grid'))
                
        except psycopg2.Error as e:
            self._error(f"List failed: {e}")
    
    def delete(self, identifier: str, confirm: bool = False) -> None:
        """Delete a transcription and its chunks"""
        
        # Check if identifier looks like a partial UUID (8-36 hex chars with optional dashes)
        import re
        uuid_pattern = re.compile(r'^[0-9a-fA-F-]{8,36}$')
        is_uuid_like = bool(uuid_pattern.match(identifier))
        
        # Determine if identifier is UUID or filename
        is_uuid = False
        if is_uuid_like:
            try:
                # Try to parse as full UUID
                import uuid
                uuid.UUID(identifier)
                is_uuid = True
            except ValueError:
                # Not a full UUID, but might be a partial one
                # Check if it's a valid partial UUID (at least 8 hex chars)
                hex_only = identifier.replace('-', '')
                if len(hex_only) >= 8 and all(c in '0123456789abcdefABCDEF' for c in hex_only):
                    # Try to find a matching UUID
                    self.cursor.execute("""
                        SELECT id FROM transcriptions 
                        WHERE id::text LIKE %s
                        ORDER BY transcribed_at DESC
                    """, [f"{identifier}%"])
                    matches = self.cursor.fetchall()
                    
                    if len(matches) == 0:
                        self._error(f"No transcription found matching partial UUID: {identifier}")
                        return
                    elif len(matches) > 1:
                        self._error(f"Multiple transcriptions found matching partial UUID: {identifier}")
                        print("Please use a longer UUID prefix to uniquely identify the transcription:")
                        for match in matches[:5]:  # Show first 5 matches
                            print(f"  - {match['id']}")
                        if len(matches) > 5:
                            print(f"  ... and {len(matches) - 5} more")
                        return
                    else:
                        # Exactly one match - use it
                        identifier = str(matches[0]['id'])
                        is_uuid = True
        
        # First, get the transcription details
        if is_uuid:
            sql = "SELECT id, filename FROM transcriptions WHERE id = %s::uuid"
            params = [identifier]
        else:
            sql = """
            SELECT id, filename FROM transcriptions 
            WHERE filename = %s 
            ORDER BY transcribed_at DESC 
            LIMIT 1
            """
            params = [identifier]
        
        try:
            self.cursor.execute(sql, params)
            result = self.cursor.fetchone()
            
            if not result:
                self._error(f"No transcription found for: {identifier}")
                return
            
            # Confirm deletion
            if not confirm:
                print(self._color("About to delete transcription:", Fore.YELLOW))
                print(f"  ID: {result['id']}")
                print(f"  Filename: {result['filename']}")
                response = input(self._color("Are you sure? (y/N): ", Fore.YELLOW))
                if response.lower() != 'y':
                    print("Deletion cancelled.")
                    return
            
            # Delete transcription (chunks are cascade deleted)
            self.cursor.execute("DELETE FROM transcriptions WHERE id = %s::uuid", [result['id']])
            self.conn.commit()
            self._success("Transcription deleted successfully.")
            
        except psycopg2.Error as e:
            self.conn.rollback()
            self._error(f"Delete failed: {e}")
    
    def stats(self) -> None:
        """Show database statistics"""
        
        print(self._color("\nTranscription Database Statistics", Fore.YELLOW))
        print(self._color("=" * 50, Fore.YELLOW))
        
        try:
            # Overall statistics
            self.cursor.execute("""
                SELECT 
                    COUNT(DISTINCT t.id) as total_transcriptions,
                    COUNT(tc.id) as total_chunks,
                    COALESCE(SUM(tc.character_count), 0) as total_characters,
                    COALESCE(AVG(tc.character_count), 0)::integer as avg_chunk_size
                FROM transcriptions t
                LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id
            """)
            stats = self.cursor.fetchone()
            
            stats_table = [
                [self._color('Total Transcriptions', Fore.CYAN), self._color(f"{stats['total_transcriptions']:,}", Fore.GREEN)],
                [self._color('Total Chunks', Fore.CYAN), self._color(f"{stats['total_chunks']:,}", Fore.GREEN)],
                [self._color('Total Characters', Fore.CYAN), self._color(f"{stats['total_characters']:,}", Fore.GREEN)],
                [self._color('Average Chunk Size', Fore.CYAN), self._color(f"{stats['avg_chunk_size']:,}", Fore.GREEN)]
            ]
            print(tabulate(stats_table, tablefmt='plain'))
            
            # Top types
            print(self._color("\nTop 5 Types:", Fore.CYAN))
            self.cursor.execute("""
                SELECT 
                    COALESCE(metadata->>'type', 'none') as type,
                    COUNT(*) as count
                FROM transcriptions
                GROUP BY metadata->>'type'
                ORDER BY count DESC
                LIMIT 5
            """)
            types = self.cursor.fetchall()
            if types:
                type_table = [[self._color(t['type'], Fore.MAGENTA), self._color(f"{t['count']:,}", Fore.GREEN)] for t in types]
                headers = [self._color('Type', Fore.MAGENTA + Style.BRIGHT), self._color('Count', Fore.GREEN + Style.BRIGHT)]
                print(tabulate(type_table, headers=headers, tablefmt='simple'))
            
            # Top tags
            print(self._color("\nTop 10 Tags:", Fore.CYAN))
            self.cursor.execute("""
                SELECT 
                    tag,
                    COUNT(*) as count
                FROM (
                    SELECT jsonb_array_elements_text(metadata->'tags') as tag
                    FROM transcriptions
                    WHERE metadata->'tags' IS NOT NULL
                ) t
                GROUP BY tag
                ORDER BY count DESC
                LIMIT 10
            """)
            tags = self.cursor.fetchall()
            if tags:
                tag_table = [[self._color(t['tag'], Fore.BLUE), self._color(f"{t['count']:,}", Fore.GREEN)] for t in tags]
                headers = [self._color('Tag', Fore.BLUE + Style.BRIGHT), self._color('Count', Fore.GREEN + Style.BRIGHT)]
                print(tabulate(tag_table, headers=headers, tablefmt='simple'))
                
        except psycopg2.Error as e:
            self._error(f"Stats failed: {e}")
    
    def get_transcription_info(self, trans_id: str) -> Optional[Dict]:
        """Get transcription information by ID.
        
        Returns:
            Dictionary with transcription details or None if not found
        """
        try:
            self.cursor.execute("""
                SELECT id, filename, file_path, transcribed_at, metadata
                FROM transcriptions
                WHERE id = %s::uuid
            """, [trans_id])
            
            result = self.cursor.fetchone()
            if result:
                return dict(result)
            return None
        except psycopg2.Error as e:
            self._error(f"Failed to get transcription info: {e}")
            return None
    
    def fzf_select_transcription(self, for_action: str = 'view') -> Optional[str]:
        """Select a transcription using fzf with preview.
        
        Args:
            for_action: The action to perform ('view', 'delete')
            
        Returns:
            Selected transcription ID or None if cancelled
        """
        try:
            # Check if fzf is available
            fzf_path = shutil.which('fzf')
            if not fzf_path:
                self._error("fzf command not found. Please install fzf.")
                return None
            
            # Get all transcriptions
            self.cursor.execute("""
                SELECT 
                    t.id,
                    t.filename,
                    t.file_path,
                    t.transcribed_at,
                    t.metadata,
                    LEFT(string_agg(tc.content, ' ' ORDER BY tc.chunk_number), 100) as preview
                FROM transcriptions t
                LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id
                GROUP BY t.id
                ORDER BY t.transcribed_at DESC
            """)
            
            transcriptions = self.cursor.fetchall()
            
            if not transcriptions:
                self._info("No transcriptions found.")
                return None
            
            # Create temporary file with transcription entries for fzf
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for trans in transcriptions:
                    # Format: UUID | timestamp | filename | type/tags | preview
                    timestamp = trans['transcribed_at'].strftime('%Y-%m-%d %H:%M')
                    
                    metadata_parts = []
                    if trans['metadata']:
                        if trans['metadata'].get('type'):
                            metadata_parts.append(trans['metadata']['type'])
                        if trans['metadata'].get('tags'):
                            metadata_parts.append(f"[{', '.join(trans['metadata']['tags'])}]")
                    metadata_str = ' '.join(metadata_parts) if metadata_parts else 'no metadata'
                    
                    preview = trans['preview'] or ''
                    preview = preview.replace('\n', ' ').strip()[:80] + '...' if len(preview) > 80 else preview
                    
                    line = f"{str(trans['id'])[:8]} | {timestamp} | {trans['filename']} | {metadata_str} | {preview}"
                    f.write(line + '\n')
                temp_file = f.name
            
            # Set PGPASSWORD if available
            if DB_CONFIG.get('password'):
                os.environ['PGPASSWORD'] = DB_CONFIG['password']
            
            # Create preview script
            preview_script = f"""#!/bin/bash
export PGPASSWORD='{DB_CONFIG.get('password', '')}'
uuid="${{1%% *}}"
# Find full UUID from partial
full_uuid=$(psql -h {DB_CONFIG['host']} -p {DB_CONFIG['port']} -d {DB_CONFIG['database']} -U {DB_CONFIG['user']} -t -c "SELECT id FROM transcriptions WHERE id::text LIKE '$uuid%' LIMIT 1" 2>/dev/null | tr -d ' ')
if [ -z "$full_uuid" ]; then
    echo "Transcription not found"
    exit 1
fi
# Get transcription content
psql -h {DB_CONFIG['host']} -p {DB_CONFIG['port']} -d {DB_CONFIG['database']} -U {DB_CONFIG['user']} -t -c "
SELECT string_agg(content, E'\\\\n' ORDER BY chunk_number)
FROM transcription_chunks
WHERE transcription_id = '$full_uuid'::uuid
" 2>/dev/null | head -50
"""
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.sh', delete=False) as f:
                f.write(preview_script)
                preview_file = f.name
            
            os.chmod(preview_file, 0o755)
            
            try:
                # Run fzf
                action_text = {
                    'view': 'Select a transcription to view',
                    'delete': 'Select a transcription to delete'
                }
                
                # Run fzf with proper TTY handling
                fzf_cmd = [
                    fzf_path,
                    '--preview', f'{preview_file} {{}}',
                    '--preview-window', 'down:50%:wrap',
                    '--header', f'{action_text.get(for_action, "Select a transcription")} (Ctrl-C to cancel)',
                    '--bind', 'ctrl-/:toggle-preview'
                ]
                
                # Run fzf
                result = subprocess.run(fzf_cmd, stdin=open(temp_file), capture_output=True, text=True)
                
                if result.returncode == 0 and result.stdout.strip():
                    selected = result.stdout.strip()
                    # Extract the partial UUID
                    trans_uuid = selected.split(' | ')[0]
                    
                    # Get full UUID
                    self.cursor.execute("SELECT id FROM transcriptions WHERE id::text LIKE %s LIMIT 1", [f"{trans_uuid}%"])
                    full_uuid = self.cursor.fetchone()
                    
                    if full_uuid:
                        return str(full_uuid['id'])
                
                return None
                
            finally:
                os.unlink(temp_file)
                os.unlink(preview_file)
                if 'PGPASSWORD' in os.environ:
                    del os.environ['PGPASSWORD']
                    
        except Exception as e:
            self._error(f"FZF selection failed: {e}")
            return None


def main():
    parser = argparse.ArgumentParser(
        description='Unified management tool for transcriptions stored in PostgreSQL',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
EXAMPLES:
    # Search for content
    transcriptions search "action items"
    transcriptions search --type meeting --limit 5 "budget"
    
    # View transcription
    transcriptions view 75647fb6-5a16-44a5-9155-2bc0aab58b0f
    transcriptions view 75647fb6  # Using partial UUID (first 8 chars)
    transcriptions view recording.mp3
    transcriptions view -m recording.mp3  # With metadata
    transcriptions view --fzf  # Select with fzf
    
    # List recent transcriptions
    transcriptions list
    transcriptions list --limit 20 --type meeting
    transcriptions list --fzf  # Select and show info table
    transcriptions list --fzf --id  # Select and output just the ID
    transcriptions list --fzf --name  # Select and output just the filename
    
    # Delete transcription
    transcriptions delete recording.mp3
    transcriptions delete -y 75647fb6-5a16-44a5-9155-2bc0aab58b0f
    transcriptions delete -y 75647fb6  # Using partial UUID
    transcriptions delete --fzf  # Select with fzf
    transcriptions delete --fzf -y  # Select with fzf and skip confirmation
    
    # Show statistics
    transcriptions stats

ENVIRONMENT VARIABLES:
    TRANSCRIPTION_DB_HOST     Database host (default: 127.0.0.1)
    TRANSCRIPTION_DB_PORT     Database port (default: 5432)
    TRANSCRIPTION_DB_NAME     Database name (default: transcriptions)
    TRANSCRIPTION_DB_USER     Database user (default: postgres)
    TRANSCRIPTION_DB_PASSWORD Database password (default: none)
"""
    )
    
    # Subcommands
    subparsers = parser.add_subparsers(dest='action', help='Action to perform')
    
    # Search command
    search_parser = subparsers.add_parser('search', help='Search transcriptions using full-text search')
    search_parser.add_argument('query', help='Search query')
    search_parser.add_argument('-l', '--limit', type=int, default=10, help='Number of results to show (default: 10)')
    search_parser.add_argument('-t', '--type', help='Filter by transcription type')
    search_parser.add_argument('-T', '--tags', help='Filter by tags (comma-separated)')
    search_parser.add_argument('-f', '--format', choices=['text', 'simple', 'json', 'yaml'], 
                              default='text', help='Output format')
    search_parser.add_argument('-v', '--verbose', action='store_true', help='Enable verbose output')
    
    # View command
    view_parser = subparsers.add_parser('view', help='View full transcription content')
    view_parser.add_argument('identifier', nargs='?', help='UUID or filename (omit with --fzf)')
    view_parser.add_argument('-m', '--metadata', action='store_true', help='Include metadata in output')
    view_parser.add_argument('-f', '--format', choices=['text', 'simple', 'json', 'yaml'], 
                            default='text', help='Output format')
    view_parser.add_argument('--no-timestamps', action='store_true', 
                            help='Show content without timestamps (default: show only timestamped lines)')
    view_parser.add_argument('--fzf', action='store_true', help='Select transcription using fzf')
    
    # List command
    list_parser = subparsers.add_parser('list', help='List recent transcriptions')
    list_parser.add_argument('-l', '--limit', type=int, default=10, help='Number of results to show (default: 10)')
    list_parser.add_argument('-t', '--type', help='Filter by transcription type')
    list_parser.add_argument('-T', '--tags', help='Filter by tags (comma-separated)')
    list_parser.add_argument('-f', '--format', choices=['text', 'simple', 'json', 'yaml'], 
                            default='text', help='Output format')
    list_parser.add_argument('--fzf', action='store_true', help='Select transcription using fzf')
    list_parser.add_argument('--id', '--uuid', action='store_true', help='With --fzf, output only the ID')
    list_parser.add_argument('--name', action='store_true', help='With --fzf, output only the filename')
    
    # Delete command
    delete_parser = subparsers.add_parser('delete', help='Delete a transcription and its chunks')
    delete_parser.add_argument('identifier', nargs='?', help='UUID or filename (omit with --fzf)')
    delete_parser.add_argument('-y', '--yes', action='store_true', help='Skip confirmation prompt')
    delete_parser.add_argument('--fzf', action='store_true', help='Select transcription using fzf')
    
    # Stats command
    stats_parser = subparsers.add_parser('stats', help='Show database statistics')
    
    # Global options
    parser.add_argument('--no-color', action='store_true', help='Disable colored output')
    
    args = parser.parse_args()
    
    if not args.action:
        parser.print_help()
        sys.exit(0)
    
    # Create manager instance
    manager = TranscriptionManager(no_color=args.no_color)
    
    # Execute action
    try:
        if args.action == 'search':
            tags = args.tags.split(',') if args.tags else None
            manager.search(args.query, limit=args.limit, type_filter=args.type,
                          tags_filter=tags, output_format=args.format,
                          verbose=args.verbose)
        elif args.action == 'view':
            if args.fzf:
                selected_id = manager.fzf_select_transcription(for_action='view')
                if selected_id:
                    manager.view(selected_id, show_metadata=args.metadata,
                                output_format=args.format, no_timestamps=args.no_timestamps)
            elif args.identifier:
                manager.view(args.identifier, show_metadata=args.metadata,
                            output_format=args.format, no_timestamps=args.no_timestamps)
            else:
                print("Error: Either provide an identifier or use --fzf to select", file=sys.stderr)
                sys.exit(1)
        elif args.action == 'list':
            if args.fzf:
                selected_id = manager.fzf_select_transcription(for_action='list')
                if selected_id:
                    # Get transcription info
                    info = manager.get_transcription_info(selected_id)
                    if info:
                        if args.id:
                            # Just print the ID
                            print(str(info['id']))
                        elif args.name:
                            # Just print the filename
                            print(info['filename'])
                        else:
                            # Print markdown table with details - horizontal layout
                            id_str = str(info['id'])
                            filename_str = info['filename']
                            transcribed_str = manager._format_date(info['transcribed_at'])
                            
                            # Handle metadata
                            type_str = '_none_'
                            tags_str = '_none_'
                            if info['metadata']:
                                if info['metadata'].get('type'):
                                    type_str = info['metadata']['type']
                                if info['metadata'].get('tags'):
                                    tags_str = ', '.join(f"`{tag}`" for tag in info['metadata']['tags'])
                            
                            # Headers and values
                            headers = ['ID', 'Filename', 'Transcribed', 'Type', 'Tags']
                            values = [f"`{id_str[:8]}...`", filename_str, transcribed_str, type_str, tags_str]
                            
                            # Calculate column widths
                            col_widths = []
                            for i, header in enumerate(headers):
                                col_widths.append(max(len(header), len(values[i])))
                            
                            # Print header row
                            header_row = '| ' + ' | '.join(f"{headers[i]:<{col_widths[i]}}" for i in range(len(headers))) + ' |'
                            print(header_row)
                            
                            # Print separator row
                            sep_row = '|' + '|'.join(f"{'-' * (width + 2)}" for width in col_widths) + '|'
                            print(sep_row)
                            
                            # Print data row
                            data_row = '| ' + ' | '.join(f"{values[i]:<{col_widths[i]}}" for i in range(len(values))) + ' |'
                            print(data_row)
            else:
                tags = args.tags.split(',') if args.tags else None
                manager.list(limit=args.limit, type_filter=args.type,
                            tags_filter=tags, output_format=args.format)
        elif args.action == 'delete':
            if args.fzf:
                selected_id = manager.fzf_select_transcription(for_action='delete')
                if selected_id:
                    manager.delete(selected_id, confirm=args.yes)
            elif args.identifier:
                manager.delete(args.identifier, confirm=args.yes)
            else:
                print("Error: Either provide an identifier or use --fzf to select", file=sys.stderr)
                sys.exit(1)
        elif args.action == 'stats':
            manager.stats()
    except KeyboardInterrupt:
        print("\nOperation cancelled.")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()