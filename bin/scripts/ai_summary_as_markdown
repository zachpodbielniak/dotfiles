#!/usr/bin/python3
#
# AI Summary as Markdown
# ======================
# This script generates structured markdown summaries from any text input using AI.
# It provides specialized prompt templates for different content types and leverages
# aipy for AI processing, with support for provider routing, model selection, and emoji enhancement.
#
# Author: Zach (with contributions from Claude)
# License: N/A
# 
# Usage:
#   cat input.txt | ai_summary_as_markdown [options]
#
# Options:
#   --type TYPE              Content type to determine specialized summary format
#   --principle              Focus on higher-level principles instead of literal content
#   --prompt TEXT            Append custom instructions to the built-in prompt
#   --debug                  Toggle debug logging
#   --provider PROVIDER      AI provider to use (optional - aipy will auto-route based on model)
#   --model MODEL            Specific model to use (aipy will auto-route to correct provider)
#   --no-preserve            Don't save chat transaction to database or files
#   --emojis [MODE]          Encourage emoji usage ('light' or 'heavy'; default: light)
#   --enhance-emojis         Post-process response to add appropriate emojis
#   --dry-run                Show what command would be executed without running it
#   -L, --list-models        List all available models from aipy
#
# Examples:
#   cat meeting.txt | ai_summary_as_markdown --type meeting
#   cat youtube_transcript.txt | ai_summary_as_markdown --type youtube
#   cat article.txt | ai_summary_as_markdown --principle
#   cat doc.txt | ai_summary_as_markdown --type custom --prompt "Custom instructions here"
#   cat input.txt | ai_summary_as_markdown --model grok-3  # Auto-routes to grokpy
#   cat input.txt | ai_summary_as_markdown --model claude-sonnet-4-20250514  # Auto-routes to claudpy
#   cat input.txt | ai_summary_as_markdown --provider geminpy  # Uses default Gemini model
#   cat input.txt | ai_summary_as_markdown --emojis heavy --enhance-emojis
#   cat input.txt | ai_summary_as_markdown --no-preserve --emojis light
#   cat input.txt | ai_summary_as_markdown --dry-run  # Show what would happen
#   ai_summary_as_markdown -L  # List all available models
#

import sys
import argparse
from sys import stdin, argv
from subprocess import run

# ===========================================
# PROMPT TEMPLATE DEFINITIONS
# ===========================================
# Each prompt is specialized for a particular content type
# Format pattern: specific elements to extract and formatting instructions

# Meeting transcript prompt template
# Focuses on agenda, points discussed, decisions, and action items
prompt_meeting: str = """
Summarize the following meeting transcript by outlining:
- The meeting agenda
- Major discussion points, organized under relevant agenda sections and listed as bullet points
- What decisions were agreed upon
- Key takeaways from the meeting, specifying who owns each action item.
"""

# Book summary prompt template
# Handles both fiction and non-fiction with appropriate structure
prompt_book: str = """
Create a detailed summary of the book content provided below. Detect if it is fiction or non-fiction based on the content. For fiction, include a concise plot overview, central themes, and significant points or developments broken down by chapter. For non-fiction, outline the primary arguments or topics discussed in each chapter and emphasize the main takeaways.

The book content follows after the separator line.
"""

# Research paper prompt template
# Extracts academic structure of hypothesis, methods, findings, limitations
prompt_research: str = """
Summarize this research paper by outlining:
- Research objectives/hypotheses
- Methodology used (study design/data sources)
- Key findings/results organized by section
- Limitations of the research
- Conclusions & implications for future work
"""

# Lecture transcript prompt template
# Organizes educational content with learning objectives and key concepts
prompt_lecture: str = """
Convert this lecture transcript into an outline featuring:
- The main topic and learning objectives
- Key definitions/formulas introduced (italicized)
- Case studies/examples referenced
- Questions raised during Q&A session
- Connections to other topics in the field
"""

# Tutorial/guide prompt template
# Structures instructional content with prerequisites and steps
prompt_tutorial: str = """
Transform this technical guide into a structured summary:
- Core objective/task explained
- Prerequisites/tools required
- Step-by-step process overview (numbered list)
- Common pitfalls & troubleshooting tips
- Suggestions for further learning
Use markdown code blocks for commands/examples where applicable.
"""

# Interview transcript prompt template
# Extracts background, themes, quotes and insights
prompt_interview: str = """
Condense this interview transcript into:
- Introducing the person being interviewed and their background
- Primary topics/themes covered
- Notable quotes from interviewee(s)
- Contextual insights about tone/subtext
- Key takeaways and actionable advice
"""

# Debate analysis prompt template
# Balances arguments from multiple perspectives
prompt_debate: str = """
Analyze this debate by:
- Identifying the central question or topic of disagreement
- Summarizing the strongest arguments from each side in a balanced way
- Highlighting points of agreement and areas of fundamental disagreement
- Noting logical fallacies or rhetorical techniques used
- Providing a balanced conclusion about the state of the debate
"""

# Podcast episode prompt template
# Includes timestamps and references for audio content
prompt_podcast: str = """
Summarize this podcast episode by identifying:
- Episode topic and guest information
- Main discussion segments with approximate timestamps
- Central arguments/theories proposed
- Resources/references mentioned
- Key takeaways and conclusions
"""

# Legal document prompt template
# Focuses on parties, clauses, obligations and risks
prompt_legal: str = """
Analyze this legal document to extract:
- Parties involved & effective dates
- 3-5 most consequential clauses/sections
- Obligations per party (bullet-pointed)
- Termination conditions & penalties
- Potential risks or concerning clauses
"""

# Medical case study prompt template
# Structures patient information, diagnosis, treatment and outcomes
prompt_medical: str = """
Summarize this medical case study by organizing:
- Patient presentation (demographics & chief complaints)
- Diagnostic tests/results
- Treatment pathway and procedures
- Outcome at discharge/follow-up
- Learning points and recommendations for similar cases
"""

# Product review prompt template
# Evaluates strengths, weaknesses, and comparisons
prompt_review: str = """
Synthesize this product review or multiple reviews into:
- Overall assessment and recommendation
- Key strengths and standout features
- Limitations, weaknesses, or concerns
- Comparison with alternatives (if mentioned)
- Ideal use cases or target users
"""

# Project information prompt template
# Structures goals, timeline, resources and success metrics
prompt_project: str = """
Structure this project information as:
- Project overview and objectives
- Key stakeholders and responsibilities
- Timeline with milestones and deliverables
- Resource requirements and constraints
- Risk assessment and mitigation strategies
- Success metrics and evaluation criteria
"""

# Higher-level principles extraction prompt
# Used with --principle flag to extract conceptual insights
prompt_principles: str = """
focus on the higher level principles that can be derived from this, intead of the literal values: give me a list of potential areas of my life that these principles could be applied.
"""

# General-purpose summary prompt template
# Default fallback for unspecified content types
prompt_general: str = """
Summarize the following input in a clear and concise manner, highlighting the most important points and main ideas for quick understanding. 
"""

# Technical documentation prompt template
# Extracts purpose, audience, components and usage information
prompt_techdoc: str = """
Summarize this technical documentation into structured sections:
- Purpose and primary goal
- Target audience
- Core components/functions/endpoints
- Setup steps (prerequisites, installation, configuration)
- Common use cases with examples
- Troubleshooting tips
"""

# Case study prompt template
# Focuses on problem statement, approach, results and applications
prompt_casestudy: str = """
Condense this case study into:
- Background and problem statement
- Methodology and solutions tested
- Key results and metrics (with quantitative impact)
- Takeaways and broader applicability
"""

# Event recap prompt template
# Summarizes event details, themes, sessions and outcomes
prompt_event: str = """
Summarize this event as:
- Event details (title, date, organizer)
- Key themes with speaker highlights
- Notable sessions/panels
- Networking outcomes
- Next steps/actions
"""

# Academic paper prompt template
# Similar to research but with more focus on academic contributions
prompt_academic: str = """
Summarize this academic paper with:
- Research question/hypothesis
- Methodology approach
- Key findings with statistical significance
- Implications to the field
- Limitations and future work directions
"""

# Email thread prompt template
# Organizes participants, discussions, decisions and action items
prompt_email: str = """
Condense this email thread into:
- Participants and their roles
- Main discussion topics
- Decisions made (with owners and deadlines)
- Open questions requiring follow-up
- Timeline of critical exchanges
"""

# Social media analysis prompt template
# Extracts trends, sentiment, influencers and recommendations
prompt_social: str = """
Analyze this social media data into:
- Top trends/hashtags/keywords with frequency
- Sentiment breakdown with percentages
- Key influencers and notable content
- Actionable recommendations based on trends
"""

# Course curriculum prompt template
# Structures learning objectives, modules and assessments
prompt_course: str = """
Structure this course information into:
- Learning objectives
- Module breakdown with topics, readings, and assignments
- Skills developed through the course
- Assessment methods and criteria
"""

# Survey results prompt template
# Summarizes demographics, insights and follow-up areas
prompt_survey: str = """
Summarize these survey results into:
- Demographic information of respondents
- Key insights and response patterns
- Notable quotes from participants
- Areas requiring follow-up investigation
"""

# User manual prompt template
# Extracts setup, safety, functionality and troubleshooting
prompt_manual: str = """
Extract critical information from this user manual into:
- Setup checklist with required tools
- Safety warnings and precautions
- Core functionality instructions
- Troubleshooting table for common issues
"""

# Product specifications prompt template
# Focuses on technical details, features and compatibility
prompt_product: str = """
Extract specifications from this product document:
- Product details and category
- Technical specifications
- Key features compared to competitors
- Compatibility requirements
- Pricing tiers and availability
"""

# Scientific paper prompt template
# Emphasizes methodological innovations and statistical findings
prompt_scientific: str = """
Create an enhanced summary of this scientific paper:
- Research question/hypothesis
- Methodological innovations
- Key findings with statistical data
- Limitations and suggested future research
"""

# Cleanup prompt template
# Preserves main content while removing navigation and non-essential elements
prompt_cleanup: str = """
Clean up the following content by preserving ONLY the main article/document content while removing all non-essential elements. Your task is to:

1. PRESERVE completely:
   - The main article text, paragraphs, and sections
   - All headings and subheadings from the main content
   - Important lists, quotes, and code blocks within the article
   - Images and their captions that are part of the main content
   - Tables and data that support the main narrative

2. REMOVE completely:
   - Navigation menus and links (e.g., "Home", "About", "Contact")
   - Sidebar content and widgets
   - Header and footer boilerplate text
   - Social media sharing buttons and links
   - Advertisement placeholders or promotional content
   - Cookie notices and privacy policy banners
   - "Related articles" or "You might also like" sections
   - Comment sections and user interactions
   - Newsletter signup forms
   - Copyright notices and legal disclaimers
   - Breadcrumb navigation
   - Tag clouds or category lists
   - Author bio boxes (unless integral to understanding the content)
   - Site-wide announcements or banners

3. OUTPUT FORMAT:
   - Return the cleaned content in markdown format
   - Maintain the original structure and hierarchy of the main content
   - Keep the natural flow and readability of the article
   - Do not add any summary or interpretation - just clean extraction
   - Do not add any prefatory text like "Here is the cleaned content" - start directly with the content

The goal is to extract what a reader would see if they used "Reader Mode" in a web browser - just the core article content without any website chrome or navigation elements.
"""

# YouTube video prompt template
# Optimized for video transcripts with timestamps and visual/audio context
prompt_youtube: str = """
Summarize this YouTube video transcript into a comprehensive yet concise format:

## Video Overview
- Provide a 2-3 sentence overview of the video's main topic and purpose
- Include the video creator/channel context if mentioned
- Note the video style (tutorial, vlog, documentary, review, etc.)

## Key Topics & Timestamps
- List the main topics covered with approximate timestamps when available
- Format as bullet points with timestamps like [MM:SS] if present
- Group related subtopics together

## Main Content Summary
- Summarize the core content in 3-5 paragraphs
- Focus on the key information, insights, or instructions provided
- Preserve any important technical details, statistics, or examples
- Note any visual demonstrations or screen shares described

## Notable Quotes & Moments
- Extract 2-4 memorable or important quotes
- Include any humor, personal anecdotes, or engaging moments
- Note significant visual elements mentioned (charts, demos, reactions)

## Key Takeaways
- List 3-5 main points viewers should remember
- Include any calls-to-action or recommendations made
- Note any resources, links, or references mentioned

## Additional Context
- Mention any sponsor segments or promotional content (briefly)
- Note if this is part of a series or references other videos
- Include any important viewer corrections or clarifications mentioned

Focus on making the summary useful for someone who wants to understand the video's content without watching it, while preserving enough detail that they could decide if watching the full video would be valuable.
"""

# Initialize empty prompt string that will be filled during execution
prompt: str = ""


# ===========================================
# MAIN EXECUTION LOGIC
# ===========================================

# Global try-except for robust error handling throughout the script
try:
    # Define the valid summary types that can be selected via --type
    # Each entry must have a corresponding prompt_<type> variable defined above
    SUMMARY_TYPES = ["meeting", "book", "research", "lecture", "tutorial",
                    "interview", "debate", "podcast", "legal", "medical",
                    "review", "project", "general", "custom", "techdoc",
                    "casestudy", "event", "academic", "email", "social",
                    "course", "survey", "manual", "product", "scientific",
                    "cleanup", "youtube"]

    # Set up command-line argument parsing with organized groups
    parser = argparse.ArgumentParser(
        description="ü§ñ Generate AI-powered content summaries in markdown format",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
üéØ Quick Examples:
  cat input.txt | ai_summary_as_markdown --type meeting
  cat input.txt | ai_summary_as_markdown --model grok-3 --emojis heavy
  ai_summary_as_markdown -f config.yaml -f README.md --type techdoc
  ai_summary_as_markdown --image screenshot.png --auto-type
  ai_summary_as_markdown -L  # List all models
  cat input.txt | ai_summary_as_markdown --dry-run  # Preview command
        """
    )

    # üìã CORE PROCESSING OPTIONS
    core_group = parser.add_argument_group("üìã Core Processing Options")
    core_group.add_argument("--type", choices=SUMMARY_TYPES,
                           required=False, help="Summary type for specialized formatting", default="")
    core_group.add_argument("--principle", action="store_true", required=False, default=False,
                           help="Focus on higher-level principles instead of literal content")
    core_group.add_argument("--prompt", required=False, help="Append custom instructions to the built-in prompt", default="")

    # ü§ñ AI PROVIDER & MODEL OPTIONS  
    ai_group = parser.add_argument_group("ü§ñ AI Provider & Model Options")
    ai_group.add_argument("--provider", choices=["perpy", "claudpy", "grokpy", "ollampy", "geminpy"], required=False,
                         help="AI provider to use (optional - aipy auto-routes based on model)")
    ai_group.add_argument("--model", required=False, help="Specific model to use (aipy auto-routes to correct provider)", default="")
    ai_group.add_argument("--auto-type", action="store_true", required=False, default=False,
                         help="Automatically detect content type using AI analysis")

    # üé® STYLE & ENHANCEMENT OPTIONS
    style_group = parser.add_argument_group("üé® Style & Enhancement Options")
    style_group.add_argument("--emojis", nargs="?", const="light", choices=["light", "heavy"], required=False,
                            help="Encourage emoji usage: 'light' (default) or 'heavy'")
    style_group.add_argument("--enhance-emojis", action="store_true", required=False, default=False,
                            help="Post-process response to add appropriate emojis")
    style_group.add_argument("--style", choices=["personal", "academic", "business", "casual"], required=False,
                            help="Adjust tone and formality of the summary")
    style_group.add_argument("--length", choices=["brief", "standard", "detailed"], required=False,
                            help="Control summary depth and detail level")
    style_group.add_argument("--plain-language", action="store_true", required=False, default=False,
                            help="Simplify complex terminology for general readability")
    style_group.add_argument("--reading-level", choices=["elementary", "middle", "high", "college", "graduate"], required=False,
                            help="Target specific reading comprehension level")

    # üß† INTELLIGENCE & ANALYSIS OPTIONS
    intel_group = parser.add_argument_group("üß† Intelligence & Analysis Options")
    intel_group.add_argument("--sentiment-analysis", action="store_true", required=False, default=False,
                            help="Include sentiment scoring in the summary")
    intel_group.add_argument("--key-entities", action="store_true", required=False, default=False,
                            help="Extract and highlight people, places, organizations")
    intel_group.add_argument("--topic-modeling", action="store_true", required=False, default=False,
                            help="Automatically detect and categorize main topics")
    intel_group.add_argument("--confidence-score", action="store_true", required=False, default=False,
                            help="Show AI confidence levels for summary sections")
    intel_group.add_argument("--fact-check", action="store_true", required=False, default=False,
                            help="Highlight claims that might need verification")
    intel_group.add_argument("--bias-detection", action="store_true", required=False, default=False,
                            help="Flag potential bias in source material")

    # üîç QUALITY & ASSESSMENT OPTIONS
    quality_group = parser.add_argument_group("üîç Quality & Assessment Options")
    quality_group.add_argument("--quality-score", action="store_true", required=False, default=False,
                              help="Rate the quality of source material")
    quality_group.add_argument("--completeness-check", action="store_true", required=False, default=False,
                              help="Identify gaps in information coverage")
    quality_group.add_argument("--source-reliability", action="store_true", required=False, default=False,
                              help="Assess credibility and reliability of content")
    quality_group.add_argument("--plagiarism-check", action="store_true", required=False, default=False,
                              help="Basic similarity and originality detection")

    # üè≠ DOMAIN-SPECIFIC OPTIONS
    domain_group = parser.add_argument_group("üè≠ Domain-Specific Processing")
    domain_group.add_argument("--financial-metrics", action="store_true", required=False, default=False,
                             help="Enhanced processing for financial documents")
    domain_group.add_argument("--code-analysis", action="store_true", required=False, default=False,
                             help="Specialized handling for programming content")
    domain_group.add_argument("--legal-terms", action="store_true", required=False, default=False,
                             help="Legal document specialized processing")
    domain_group.add_argument("--medical-terminology", action="store_true", required=False, default=False,
                             help="Healthcare content terminology handling")
    domain_group.add_argument("--academic-citations", action="store_true", required=False, default=False,
                             help="Research paper reference and citation handling")

    # üìä COMPARATIVE & MULTI-DOCUMENT OPTIONS
    compare_group = parser.add_argument_group("üìä Comparative & Multi-Document Analysis")
    compare_group.add_argument("--compare-sources", nargs="+", required=False,
                              help="Compare and analyze multiple source files")
    compare_group.add_argument("--diff-summaries", action="store_true", required=False, default=False,
                              help="Compare outputs from different AI models")
    compare_group.add_argument("--consensus-summary", action="store_true", required=False, default=False,
                              help="Generate consensus from multiple AI model outputs")
    compare_group.add_argument("--contrasting-views", action="store_true", required=False, default=False,
                              help="Highlight disagreements between sources")

    # üìù CONTENT ENHANCEMENT OPTIONS
    content_group = parser.add_argument_group("üìù Content Enhancement & Structure")
    content_group.add_argument("--focus-areas", nargs="+", choices=["technical", "business", "creative", "educational"], required=False,
                              help="Emphasize specific aspects of the content")
    content_group.add_argument("--timeline", action="store_true", required=False, default=False,
                              help="Create chronological timeline for time-based content")
    content_group.add_argument("--add-questions", action="store_true", required=False, default=False,
                              help="Generate relevant discussion questions")
    content_group.add_argument("--create-flashcards", action="store_true", required=False, default=False,
                              help="Extract key concepts as Q&A pairs")
    content_group.add_argument("--action-items", action="store_true", required=False, default=False,
                              help="Auto-extract and format action items")
    content_group.add_argument("--highlight-quotes", action="store_true", required=False, default=False,
                              help="Special formatting for important quotes")

    # üë• COLLABORATION & WORKFLOW OPTIONS
    collab_group = parser.add_argument_group("üë• Collaboration & Workflow")
    collab_group.add_argument("--comment-sections", action="store_true", required=False, default=False,
                             help="Add collaboration spaces in outputs")
    collab_group.add_argument("--review-mode", action="store_true", required=False, default=False,
                             help="Generate reviewer-friendly versions")
    collab_group.add_argument("--approval-workflow", action="store_true", required=False, default=False,
                             help="Format for approval and sign-off processes")

    # üîß PRE-PROCESSING OPTIONS
    preproc_group = parser.add_argument_group("üîß Pre-Processing Options")
    preproc_group.add_argument("--extract-first", action="store_true", required=False, default=False,
                              help="Clean and extract main content before processing")
    preproc_group.add_argument("--translate-from", required=False,
                              help="Translate input from specified language before processing")

    # üìÅ INPUT & MEDIA OPTIONS
    input_group = parser.add_argument_group("üìÅ Input & Media Options")
    input_group.add_argument("-f", "--file", action="append", dest="files", required=False,
                            help="Include file content in the context (can be specified multiple times)")
    input_group.add_argument("--image", action="append", dest="images", required=False,
                            help="Include image files for vision analysis (can be specified multiple times)")

    # ‚öôÔ∏è SYSTEM & UTILITY OPTIONS
    system_group = parser.add_argument_group("‚öôÔ∏è System & Utility Options")
    system_group.add_argument("--debug", action="store_true", required=False, default=False,
                             help="Print debug logging to stderr")
    system_group.add_argument("--no-preserve", action="store_true", required=False, default=False,
                             help="Don't save chat transaction to database or files")
    system_group.add_argument("--dry-run", action="store_true", required=False, default=False,
                             help="Show what command would be executed without running it")
    system_group.add_argument("-L", "--list-models", action="store_true", required=False, default=False,
                             help="List all available models from aipy")

    # Parse the arguments provided by the user
    args = parser.parse_args()

    # Handle list-models flag early (no need for prompt processing)
    if args.list_models:
        if (True == args.debug):
            print("[DEBUG] Listing models via aipy -L", file=sys.stderr, flush=True)
        result = run("aipy -L", shell=True)
        sys.exit(result.returncode)

    # ===========================================
    # AI PROCESSING ORCHESTRATION FUNCTIONS
    # ===========================================
    
    def make_ai_request(prompt, model_preference=None, purpose="analysis"):
        """Make a single AI request with proper model selection and error handling."""
        cmd = ["aipy"]
        
        # Use specified model or fall back to appropriate defaults for different purposes
        if model_preference:
            cmd.extend(["--model", model_preference])
        elif args.model:
            cmd.extend(["--model", args.model])
        elif args.provider:
            # Use provider defaults
            default_models = {
                "perpy": "llama-3.1-sonar-small-128k-online",
                "claudpy": "claude-3-5-haiku-latest", 
                "grokpy": "grok-3-mini",
                "ollampy": "gemma3:4b",
                "geminpy": "gemini-2.0-flash"
            }
            if args.provider in default_models:
                cmd.extend(["--model", default_models[args.provider]])
        else:
            # Smart defaults based on purpose
            purpose_models = {
                "analysis": "claude-3-5-haiku-latest",  # Fast for analysis
                "detection": "gpt-4o-mini",  # Good for classification
                "enhancement": "claude-sonnet-4-20250514",  # High quality for main content
                "comparison": "claude-sonnet-4-20250514"  # Detailed for comparisons
            }
            cmd.extend(["--model", purpose_models.get(purpose, "claude-3-5-haiku-latest")])
        
        # Add file arguments if specified (for auxiliary AI requests)
        if args.files:
            for file_path in args.files:
                cmd.extend(["--file", file_path])
        
        # Add image arguments if specified (for auxiliary AI requests)
        if args.images:
            for image_path in args.images:
                cmd.extend(["--image", image_path])
        
        # Always preserve unless explicitly disabled
        if args.no_preserve:
            cmd.append("--no-preserve")
        
        if args.debug:
            print(f"[DEBUG] AI request ({purpose}): {' '.join(cmd)}", file=sys.stderr, flush=True)
        
        try:
            result = run(cmd, input=prompt.encode('utf-8'), capture_output=True)
            if result.returncode == 0:
                return result.stdout.decode('utf-8', errors='replace').strip()
            else:
                if args.debug:
                    print(f"[DEBUG] AI request failed: {result.stderr.decode('utf-8', errors='replace')}", file=sys.stderr, flush=True)
                return None
        except Exception as e:
            if args.debug:
                print(f"[DEBUG] AI request exception: {e}", file=sys.stderr, flush=True)
            return None

    def detect_content_type(text_sample):
        """Use AI to automatically detect the best content type for the input."""
        type_prompt = f"""Analyze the following text and determine which content type would be most appropriate for summarization. 

Available types: {', '.join(SUMMARY_TYPES)}

Consider the structure, language, format, and content to classify this text. Respond with ONLY the single best matching type from the list above.

Text to analyze:
{text_sample[:1000]}..."""

        detected_type = make_ai_request(type_prompt, purpose="detection")
        if detected_type and detected_type.lower().strip() in SUMMARY_TYPES:
            return detected_type.lower().strip()
        return "general"  # fallback

    def analyze_content_quality(text):
        """Analyze various quality aspects of the content."""
        quality_results = {}
        
        if args.quality_score:
            quality_prompt = f"""Rate the quality of this content on a scale of 1-10 and provide a brief explanation.

Consider: clarity, organization, factual accuracy, completeness, and usefulness.

Format your response as: "Score: X/10 - Brief explanation"

Content:
{text[:2000]}..."""
            
            quality_results['quality_score'] = make_ai_request(quality_prompt, purpose="analysis")

        if args.completeness_check:
            completeness_prompt = f"""Analyze this content for completeness and identify any obvious gaps or missing information.

List 3-5 specific areas that could be expanded or clarified.

Content:
{text[:2000]}..."""
            
            quality_results['completeness'] = make_ai_request(completeness_prompt, purpose="analysis")

        if args.source_reliability:
            reliability_prompt = f"""Assess the reliability and credibility of this content.

Consider: source citations, factual claims, bias indicators, and authority markers.

Provide a brief reliability assessment.

Content:
{text[:2000]}..."""
            
            quality_results['reliability'] = make_ai_request(reliability_prompt, purpose="analysis")

        return quality_results

    def analyze_content_intelligence(text):
        """Perform various AI-powered content analysis."""
        intel_results = {}
        
        if args.sentiment_analysis:
            sentiment_prompt = f"""Analyze the sentiment and emotional tone of this content.

Provide overall sentiment (positive/negative/neutral) and key emotional themes.

Content:
{text[:2000]}..."""
            
            intel_results['sentiment'] = make_ai_request(sentiment_prompt, purpose="analysis")

        if args.key_entities:
            entities_prompt = f"""Extract and categorize key entities from this content.

Identify: People, Organizations, Places, Dates, and other significant entities.

Format as a structured list.

Content:
{text[:2000]}..."""
            
            intel_results['entities'] = make_ai_request(entities_prompt, purpose="analysis")

        if args.topic_modeling:
            topics_prompt = f"""Identify and categorize the main topics and themes in this content.

Provide 3-5 primary topics with brief descriptions.

Content:
{text[:2000]}..."""
            
            intel_results['topics'] = make_ai_request(topics_prompt, purpose="analysis")

        return intel_results

    def enhance_content_structure(text, base_summary):
        """Add structural enhancements to the summary."""
        enhancements = {}
        
        if args.timeline:
            timeline_prompt = f"""Create a chronological timeline from this content, if applicable.

Extract dates, events, and sequences. Format as a timeline.

Original content:
{text[:1500]}..."""
            
            enhancements['timeline'] = make_ai_request(timeline_prompt, purpose="enhancement")

        if args.add_questions:
            questions_prompt = f"""Generate 5-7 thoughtful discussion questions based on this summary.

Make questions that encourage critical thinking and deeper exploration.

Summary:
{base_summary[:1500]}..."""
            
            enhancements['questions'] = make_ai_request(questions_prompt, purpose="enhancement")

        if args.create_flashcards:
            flashcards_prompt = f"""Extract key concepts and create flashcard-style Q&A pairs.

Format: Q: Question | A: Answer (5-8 pairs)

Summary:
{base_summary[:1500]}..."""
            
            enhancements['flashcards'] = make_ai_request(flashcards_prompt, purpose="enhancement")

        if args.action_items:
            actions_prompt = f"""Extract actionable items, tasks, or recommendations from this content.

Format as a prioritized action list.

Content:
{text[:1500]}..."""
            
            enhancements['actions'] = make_ai_request(actions_prompt, purpose="enhancement")

        return enhancements

    # ===========================================
    # DYNAMIC PROMPT MAPPING
    # ===========================================
    # Build a mapping from summary type names to their corresponding prompt templates
    # This allows easy extension by just adding new prompt_<type> variables

    if (True == args.debug):
        print("[DEBUG] Building prompt map from defined types", file=sys.stderr, flush=True)

    # Initialize with default mapping for empty type
    prompt_map = {
        "": prompt_general  # Default to general if empty
    }

    # Dynamically add each defined type to the prompt map
    for type_name in SUMMARY_TYPES:
        if (True == args.debug):
            print(f"[DEBUG] Processing type: {type_name}", file=sys.stderr, flush=True)

        if type_name == "custom":
            # Custom type uses the user-provided prompt instead of a predefined template
            prompt_map[type_name] = ""  # Empty template - will use args.prompt directly
            if (True == args.debug):
                print(f"[DEBUG] Added custom type with empty prompt", file=sys.stderr, flush=True)

        elif type_name == "general":
            # General type uses the generic summary prompt
            prompt_map[type_name] = prompt_general
            if (True == args.debug):
                print(f"[DEBUG] Added general type with general prompt", file=sys.stderr, flush=True)

        else:
            # For other types, look up the prompt variable by name (e.g., prompt_meeting)
            prompt_var_name = f"prompt_{type_name}"
            if prompt_var_name in locals():
                # If found, add it to the map
                prompt_map[type_name] = locals()[prompt_var_name]
                if (True == args.debug):
                    print(f"[DEBUG] Added {type_name} with {prompt_var_name}", file=sys.stderr, flush=True)
            else:
                # If not found, log a warning (this shouldn't happen if SUMMARY_TYPES is properly maintained)
                if (True == args.debug):
                    print(f"[DEBUG] Warning: No prompt found for {type_name}", file=sys.stderr, flush=True)

    # ===========================================
    # INPUT PROCESSING AND PRE-PROCESSING
    # ===========================================
    
    # Read raw bytes from stdin (allows handling of binary content)
    data_bytes = stdin.buffer.read()
    
    # Decode the input with UTF-8, replacing invalid characters to prevent crashes
    # This ensures the script can handle various encodings gracefully
    original_data = data_bytes.decode('utf-8', errors='replace')
    
    # Apply pre-processing stages
    processed_data = original_data
    
    # Stage 1: Content extraction and cleaning
    if args.extract_first:
        if args.debug:
            print("[DEBUG] Applying content extraction pre-processing", file=sys.stderr, flush=True)
        extract_prompt = f"""Clean and extract the main content from this text, removing navigation, ads, boilerplate, and non-essential elements.

Return only the core article/document content in clean, readable format.

Content to clean:
{original_data[:3000]}..."""
        
        extracted = make_ai_request(extract_prompt, purpose="analysis")
        if extracted:
            processed_data = extracted
    
    # Stage 2: Translation
    if args.translate_from:
        if args.debug:
            print(f"[DEBUG] Translating from {args.translate_from} to English", file=sys.stderr, flush=True)
        translate_prompt = f"""Translate the following text from {args.translate_from} to English. Maintain the original meaning, tone, and structure.

Text to translate:
{processed_data[:3000]}..."""
        
        translated = make_ai_request(translate_prompt, purpose="analysis")
        if translated:
            processed_data = translated

    # Stage 3: Auto-detect content type if requested
    detected_type = None
    if args.auto_type:
        if args.debug:
            print("[DEBUG] Auto-detecting content type", file=sys.stderr, flush=True)
        detected_type = detect_content_type(processed_data)
        if args.debug:
            print(f"[DEBUG] Detected content type: {detected_type}", file=sys.stderr, flush=True)
    
    # ===========================================
    # PROMPT SELECTION AND ASSEMBLY
    # ===========================================
    
    # Get the selected summary type, prioritizing auto-detection
    summary_type = detected_type if detected_type else (args.type if args.type else "general")

    if (True == args.debug):
        print(f"[DEBUG] Using summary type: {summary_type}", file=sys.stderr, flush=True)

    # Retrieve the appropriate prompt template from the map
    base_prompt = prompt_map.get(summary_type, prompt_general)

    # Handle prompt assembly based on type and options
    if summary_type == "custom":
        # For custom type, use only the user-provided prompt
        prompt = f"{args.prompt}\n"
    else:
        # For predefined types, combine the template with any additional user instructions
        prompt = f"{base_prompt} {args.prompt}\n"

    # Apply style and enhancement modifiers
    style_modifiers = []
    
    if args.style:
        style_map = {
            "personal": "Use a personal, conversational tone that feels approachable and friendly.",
            "academic": "Use formal academic language with precise terminology and structured analysis.",
            "business": "Use professional business language focused on actionable insights and clear outcomes.",
            "casual": "Use casual, easy-to-understand language suitable for general audiences."
        }
        style_modifiers.append(style_map[args.style])
    
    if args.length:
        length_map = {
            "brief": "Keep the summary concise and focused on only the most essential points.",
            "standard": "Provide a balanced summary with key points and supporting details.",
            "detailed": "Create a comprehensive summary with extensive detail and analysis."
        }
        style_modifiers.append(length_map[args.length])
    
    if args.plain_language:
        style_modifiers.append("Use simple, clear language and explain technical terms when necessary.")
    
    if args.reading_level:
        level_map = {
            "elementary": "Write at an elementary school reading level with simple vocabulary.",
            "middle": "Write at a middle school reading level with moderate complexity.",
            "high": "Write at a high school reading level with standard vocabulary.",
            "college": "Write at a college reading level with sophisticated vocabulary.",
            "graduate": "Write at a graduate level with advanced terminology and concepts."
        }
        style_modifiers.append(level_map[args.reading_level])
    
    if args.focus_areas:
        focus_text = ", ".join(args.focus_areas)
        style_modifiers.append(f"Focus particularly on these aspects: {focus_text}.")
    
    # Add domain-specific processing instructions
    domain_modifiers = []
    
    if args.financial_metrics:
        domain_modifiers.append("Pay special attention to financial metrics, ratios, performance indicators, and monetary values. Include relevant financial analysis and context.")
    
    if args.code_analysis:
        domain_modifiers.append("Focus on code structure, algorithms, best practices, and technical implementation details. Use proper code formatting and explain programming concepts clearly.")
    
    if args.legal_terms:
        domain_modifiers.append("Carefully handle legal terminology, cite relevant clauses, and explain legal implications. Maintain accuracy in legal language and concepts.")
    
    if args.medical_terminology:
        domain_modifiers.append("Use proper medical terminology while ensuring explanations are clear. Include relevant medical context and maintain clinical accuracy.")
    
    if args.academic_citations:
        domain_modifiers.append("Pay special attention to citations, references, research methodology, and academic contributions. Maintain scholarly standards and accuracy.")
    
    # Combine all modifiers with the base prompt
    if style_modifiers or domain_modifiers:
        modifier_text = " ".join(style_modifiers + domain_modifiers)
        prompt = f"{prompt}\n\nAdditional instructions: {modifier_text}"

    # Apply principles modification if requested
    if (True == args.principle):
        if (True == args.debug):
            print("[DEBUG] principles mode is in use", file=sys.stderr, flush=True)
        # Prepend the principles prompt to focus on abstract concepts
        prompt = f"{prompt_principles} {prompt}"

    # Log the final assembled prompt for debugging
    if (True == args.debug):
        print(f"[DEBUG] final prompt:\n{prompt[:500]}...", file=sys.stderr, flush=True)

    # Store the final data for processing
    data = processed_data
 
    # Combine the prompt and input data with a separator
    query: str = f"{prompt}\n--------------------------\n{data}"
    
    # ===========================================
    # AI PROCESSING AND OUTPUT
    # ===========================================

    # PHASE 1: PRE-ANALYSIS (Quality and Intelligence)
    if args.debug:
        print("[DEBUG] Starting Phase 1: Pre-analysis", file=sys.stderr, flush=True)
    
    quality_results = analyze_content_quality(data)
    intel_results = analyze_content_intelligence(data)
    
    # PHASE 2: COMPARATIVE ANALYSIS 
    comparative_results = {}
    if args.compare_sources:
        if args.debug:
            print("[DEBUG] Processing comparative analysis", file=sys.stderr, flush=True)
        # Read additional source files for comparison
        additional_sources = []
        for source_file in args.compare_sources:
            try:
                with open(source_file, 'r', encoding='utf-8', errors='replace') as f:
                    additional_sources.append(f.read())
            except Exception as e:
                if args.debug:
                    print(f"[DEBUG] Failed to read {source_file}: {e}", file=sys.stderr, flush=True)
        
        if additional_sources:
            compare_prompt = f"""Compare and analyze the following sources, highlighting key differences, agreements, and unique insights from each.

Primary source:
{data[:1500]}...

Additional sources:
{chr(10).join([f"Source {i+1}: {src[:1000]}..." for i, src in enumerate(additional_sources)])}

Provide a comparative analysis showing contrasts and consensus."""
            
            comparative_results['comparison'] = make_ai_request(compare_prompt, purpose="comparison")
    
    # Build the command using aipy with automatic provider routing
    provider_cmd = "aipy"

    # Add model argument if specified (aipy will auto-route to correct provider)
    if args.model:
        provider_cmd += f" --model {args.model}"
    elif args.provider:
        # If provider specified but no model, use default model for that provider
        default_models = {
            "perpy": "llama-3.1-sonar-large-128k-online",
            "claudpy": "claude-sonnet-4-20250514", 
            "grokpy": "grok-2-1212",
            "ollampy": "llama3.1:latest",
            "geminpy": "gemini-2.0-flash"
        }
        if args.provider in default_models:
            provider_cmd += f" --model {default_models[args.provider]}"
    # If neither model nor provider specified, let aipy use its own defaults
    
    # Add no-preserve flag if specified
    if args.no_preserve:
        provider_cmd += " --no-preserve"
    
    # Add emoji flags if specified
    if args.emojis:
        provider_cmd += f" --emojis {args.emojis}"
    
    if args.enhance_emojis:
        provider_cmd += " --enhance-emojis"
    
    # Add file arguments if specified
    if args.files:
        for file_path in args.files:
            provider_cmd += f" --file {file_path}"
    
    # Add image arguments if specified
    if args.images:
        for image_path in args.images:
            provider_cmd += f" --image {image_path}"

    if (True == args.debug):
        print(f"[DEBUG] Using aipy command: {provider_cmd}", file=sys.stderr, flush=True)

    # Handle dry-run mode
    if args.dry_run:
        print("üîç DRY RUN MODE - Showing what would be executed:")
        print("=" * 50)
        print(f"üìã Summary Configuration:")
        print(f"   ‚Ä¢ Content Type: {summary_type}")
        print(f"   ‚Ä¢ Auto-Type Detection: {'Yes' if args.auto_type else 'No'}")
        print(f"   ‚Ä¢ Principles Mode: {'Yes' if args.principle else 'No'}")
        print(f"   ‚Ä¢ Custom Prompt: {'Yes' if args.prompt else 'No'}")
        if args.provider:
            print(f"   ‚Ä¢ Provider: {args.provider}")
        if args.model:
            print(f"   ‚Ä¢ Model: {args.model}")
        else:
            print(f"   ‚Ä¢ Model: aipy default (uses built-in model selection)")
        print(f"   ‚Ä¢ No Preserve: {'Yes' if args.no_preserve else 'No'}")
        if args.emojis:
            print(f"   ‚Ä¢ Emoji Mode: {args.emojis}")
        print(f"   ‚Ä¢ Enhance Emojis: {'Yes' if args.enhance_emojis else 'No'}")
        
        print(f"\nüé® Style Options:")
        if args.style:
            print(f"   ‚Ä¢ Style: {args.style}")
        if args.length:
            print(f"   ‚Ä¢ Length: {args.length}")
        if args.plain_language:
            print(f"   ‚Ä¢ Plain Language: Yes")
        if args.reading_level:
            print(f"   ‚Ä¢ Reading Level: {args.reading_level}")
        if args.focus_areas:
            print(f"   ‚Ä¢ Focus Areas: {', '.join(args.focus_areas)}")

        print(f"\nüß† Intelligence Features:")
        if args.sentiment_analysis:
            print(f"   ‚Ä¢ Sentiment Analysis: Yes")
        if args.key_entities:
            print(f"   ‚Ä¢ Key Entities Extraction: Yes")  
        if args.topic_modeling:
            print(f"   ‚Ä¢ Topic Modeling: Yes")
        if args.confidence_score:
            print(f"   ‚Ä¢ Confidence Scoring: Yes")
        if args.fact_check:
            print(f"   ‚Ä¢ Fact Checking: Yes")
        if args.bias_detection:
            print(f"   ‚Ä¢ Bias Detection: Yes")

        print(f"\nüîç Quality Assessment:")
        if args.quality_score:
            print(f"   ‚Ä¢ Quality Scoring: Yes")
        if args.completeness_check:
            print(f"   ‚Ä¢ Completeness Check: Yes")
        if args.source_reliability:
            print(f"   ‚Ä¢ Source Reliability: Yes")
        if args.plagiarism_check:
            print(f"   ‚Ä¢ Plagiarism Check: Yes")

        print(f"\nüè≠ Domain-Specific Processing:")
        if args.financial_metrics:
            print(f"   ‚Ä¢ Financial Metrics: Yes")
        if args.code_analysis:
            print(f"   ‚Ä¢ Code Analysis: Yes")
        if args.legal_terms:
            print(f"   ‚Ä¢ Legal Terms: Yes")
        if args.medical_terminology:
            print(f"   ‚Ä¢ Medical Terminology: Yes")
        if args.academic_citations:
            print(f"   ‚Ä¢ Academic Citations: Yes")

        print(f"\nüìä Comparative Analysis:")
        if args.compare_sources:
            print(f"   ‚Ä¢ Compare Sources: {', '.join(args.compare_sources)}")
        if args.diff_summaries:
            print(f"   ‚Ä¢ Model Comparison: Yes")
        if args.consensus_summary:
            print(f"   ‚Ä¢ Consensus Summary: Yes")
        if args.contrasting_views:
            print(f"   ‚Ä¢ Contrasting Views: Yes")

        print(f"\nüìù Content Enhancement:")
        if args.timeline:
            print(f"   ‚Ä¢ Timeline Generation: Yes")
        if args.add_questions:
            print(f"   ‚Ä¢ Discussion Questions: Yes")
        if args.create_flashcards:
            print(f"   ‚Ä¢ Flashcard Creation: Yes")
        if args.action_items:
            print(f"   ‚Ä¢ Action Items Extraction: Yes")
        if args.highlight_quotes:
            print(f"   ‚Ä¢ Quote Highlighting: Yes")

        print(f"\nüë• Collaboration Features:")
        if args.comment_sections:
            print(f"   ‚Ä¢ Comment Sections: Yes")
        if args.review_mode:
            print(f"   ‚Ä¢ Review Mode: Yes")
        if args.approval_workflow:
            print(f"   ‚Ä¢ Approval Workflow: Yes")

        print(f"\nüìÅ Input & Media:")
        if args.files:
            print(f"   ‚Ä¢ Files: {', '.join(args.files)}")
        if args.images:
            print(f"   ‚Ä¢ Images: {', '.join(args.images)}")

        print(f"\nüîß Pre-Processing:")
        if args.extract_first:
            print(f"   ‚Ä¢ Content Extraction: Yes")
        if args.translate_from:
            print(f"   ‚Ä¢ Translation from: {args.translate_from}")

        print()
        print(f"üöÄ Main Command that would be executed:")
        print(f"   {provider_cmd}")
        
        # Show estimated AI calls
        total_calls = 1  # Main summary
        if args.auto_type:
            total_calls += 1
        if args.quality_score or args.completeness_check or args.source_reliability:
            total_calls += sum([args.quality_score, args.completeness_check, args.source_reliability])
        if args.sentiment_analysis or args.key_entities or args.topic_modeling:
            total_calls += sum([args.sentiment_analysis, args.key_entities, args.topic_modeling])
        if args.timeline or args.add_questions or args.create_flashcards or args.action_items:
            total_calls += sum([args.timeline, args.add_questions, args.create_flashcards, args.action_items])
        if args.diff_summaries:
            total_calls += 3  # Three comparison models
        if args.consensus_summary:
            total_calls += 1
        if args.extract_first:
            total_calls += 1
        if args.translate_from:
            total_calls += 1
        
        print(f"üìä Estimated AI API calls: {total_calls}")
        print()
        print(f"üìù Prompt that would be sent:")
        print("-" * 30)
        print(prompt[:200] + "..." if len(prompt) > 200 else prompt)
        print("-" * 30)
        print(f"üìä Input data length: {len(data)} characters")
        print()
        print("‚ú® No actual AI calls would be made in dry-run mode")
        sys.exit(0)

    # PHASE 3: MAIN SUMMARY GENERATION
    if args.debug:
        print("[DEBUG] Starting Phase 3: Main summary generation", file=sys.stderr, flush=True)
    
    # Run the selected AI provider to process the input
    result = run(
        provider_cmd,
        input=query.encode('utf-8'),
        shell=True,
        capture_output=True
    )
    
    # Handle the results
    if result.returncode == 0:
        # Success - get the generated summary
        base_summary = result.stdout.decode('utf-8', errors='replace')
        
        # PHASE 4: POST-PROCESSING AND ENHANCEMENTS
        if args.debug:
            print("[DEBUG] Starting Phase 4: Post-processing enhancements", file=sys.stderr, flush=True)
        
        # Generate enhancements
        enhancement_results = enhance_content_structure(data, base_summary)
        
        # PHASE 5: MULTI-MODEL PROCESSING
        additional_outputs = {}
        if args.diff_summaries or args.consensus_summary:
            if args.debug:
                print("[DEBUG] Starting Phase 5: Multi-model processing", file=sys.stderr, flush=True)
            
            # Generate summaries from different models for comparison
            test_models = ["claude-3-5-haiku-latest", "gpt-4o-mini", "grok-3-mini"]
            model_summaries = {}
            
            for model in test_models:
                if model != (args.model or ""):  # Skip if it's the same as main model
                    model_summary = make_ai_request(query, model_preference=model, purpose="comparison")
                    if model_summary:
                        model_summaries[model] = model_summary
            
            if args.consensus_summary and len(model_summaries) > 0:
                consensus_prompt = f"""Create a consensus summary by analyzing these different AI model outputs and combining their best insights:

Main summary:
{base_summary}

Alternative summaries:
{chr(10).join([f"{model}: {summary[:800]}..." for model, summary in model_summaries.items()])}

Generate a final summary that incorporates the best elements from all versions."""
                
                consensus_result = make_ai_request(consensus_prompt, purpose="enhancement")
                if consensus_result:
                    additional_outputs['consensus'] = consensus_result
            
            if args.diff_summaries:
                additional_outputs['model_comparison'] = model_summaries
        
        # PHASE 6: SPECIALIZED ANALYSIS
        specialized_results = {}
        
        if args.bias_detection:
            bias_prompt = f"""Analyze this content for potential bias, unfair representations, or one-sided perspectives.

Identify any:
- Political or ideological bias
- Cultural or demographic bias  
- Commercial or promotional bias
- Selection bias in data/examples

Content to analyze:
{data[:2000]}..."""
            
            specialized_results['bias_analysis'] = make_ai_request(bias_prompt, purpose="analysis")
        
        if args.fact_check:
            fact_prompt = f"""Identify claims in this content that should be fact-checked or verified.

Highlight:
- Statistical claims
- Historical facts
- Scientific assertions
- Attributions/quotes

Mark confidence levels for verifiability.

Content:
{base_summary[:1500]}..."""
            
            specialized_results['fact_check'] = make_ai_request(fact_prompt, purpose="analysis")
        
        if args.confidence_score:
            confidence_prompt = f"""Analyze this summary and provide confidence scores (1-10) for different sections.

Consider:
- Certainty of facts presented
- Completeness of coverage
- Accuracy of interpretation

Summary to analyze:
{base_summary[:1500]}..."""
            
            specialized_results['confidence'] = make_ai_request(confidence_prompt, purpose="analysis")
        
        # PHASE 7: FINAL OUTPUT ASSEMBLY
        if args.debug:
            print("[DEBUG] Starting Phase 7: Final output assembly", file=sys.stderr, flush=True)
        
        # Start with the base summary
        output_parts = [base_summary]
        
        # Add quality assessment section
        if quality_results:
            output_parts.append("\n## üìä Quality Assessment\n")
            for key, value in quality_results.items():
                if value:
                    section_title = key.replace('_', ' ').title()
                    output_parts.append(f"### {section_title}\n{value}\n")
        
        # Add intelligence analysis section
        if intel_results:
            output_parts.append("\n## üß† Content Analysis\n")
            for key, value in intel_results.items():
                if value:
                    section_title = key.replace('_', ' ').title()
                    output_parts.append(f"### {section_title}\n{value}\n")
        
        # Add comparative analysis
        if comparative_results:
            output_parts.append("\n## üîç Comparative Analysis\n")
            for key, value in comparative_results.items():
                if value:
                    section_title = key.replace('_', ' ').title()
                    output_parts.append(f"### {section_title}\n{value}\n")
        
        # Add enhancements
        if enhancement_results:
            output_parts.append("\n## ‚ú® Enhanced Content\n")
            for key, value in enhancement_results.items():
                if value:
                    section_title = key.replace('_', ' ').title()
                    output_parts.append(f"### {section_title}\n{value}\n")
        
        # Add specialized analysis
        if specialized_results:
            output_parts.append("\n## üî¨ Specialized Analysis\n")
            for key, value in specialized_results.items():
                if value:
                    section_title = key.replace('_', ' ').title()
                    output_parts.append(f"### {section_title}\n{value}\n")
        
        # Add multi-model results
        if additional_outputs:
            if 'consensus' in additional_outputs:
                output_parts.append("\n## ü§ù Consensus Summary\n")
                output_parts.append(additional_outputs['consensus'])
            
            if 'model_comparison' in additional_outputs:
                output_parts.append("\n## üîÑ Model Comparison\n")
                for model, summary in additional_outputs['model_comparison'].items():
                    output_parts.append(f"### {model}\n{summary[:500]}...\n")
        
        # Add contrasting views if requested
        if args.contrasting_views and comparative_results:
            output_parts.append("\n## ‚öñÔ∏è Contrasting Perspectives\n")
            contrast_prompt = f"""Identify and highlight the main points of disagreement, contradiction, or alternative perspectives in this content.

Focus on:
- Opposing viewpoints
- Conflicting evidence
- Alternative interpretations

Content summary:
{base_summary[:1500]}..."""
            
            contrasting_result = make_ai_request(contrast_prompt, purpose="analysis")
            if contrasting_result:
                output_parts.append(contrasting_result)
        
        # Add collaboration sections if requested
        if args.comment_sections:
            output_parts.append("\n## üí¨ Collaboration Space\n")
            output_parts.append("<!-- Add your comments and feedback here -->\n")
            output_parts.append("**Discussion Points:**\n- \n- \n- \n")
        
        if args.review_mode:
            output_parts.append("\n## ‚úÖ Review Checklist\n")
            output_parts.append("- [ ] Content accuracy verified\n")
            output_parts.append("- [ ] Key points captured\n")
            output_parts.append("- [ ] Formatting consistent\n")
            output_parts.append("- [ ] Ready for distribution\n")
        
        if args.approval_workflow:
            output_parts.append("\n## üìã Approval Workflow\n")
            output_parts.append("**Reviewer:** _________________ **Date:** _________\n")
            output_parts.append("**Approver:** ________________ **Date:** _________\n")
            output_parts.append("**Status:** [ ] Draft [ ] Under Review [ ] Approved\n")
        
        # Output the final assembled result
        final_output = "\n".join(output_parts)
        print(final_output)
        
    else:
        # Error in AI processing - provide helpful error information
        print(f"* Error in AI processing\n\n{result.stderr.decode('utf-8', errors='replace')}")
        sys.exit(1)
        
except Exception as e:
    # Catch-all for any other exceptions to prevent cryptic crashes
    print(f"* Error in AI summary script\n\n{str(e)}")
    sys.exit(1)
