#!/usr/bin/python3

from os import environ
from subprocess import run
from sys import argv, exit, stdin, stderr
import argparse
import json
import requests
import sys

ctr_id: str|None = ""
api_key: str|None = ""

if ("CONTAINER_ID" in environ):
    ctr_id = environ.get("CONTAINER_ID")

# if we are not in the 'dev' distrobox re-exec the script
# inside of the 'dev' distrobox
if ("dev" != ctr_id):
    cmd: list[str] = [
        "distrobox",
        "enter",
        "dev",
        "--",
        *argv
    ]

    run(cmd)
    exit(0)

if ("OPENAI_API_KEY" in environ):
    api_key = environ.get("OPENAI_API_KEY")
    if ("" == api_key):
        print("OPENAI_API_KEY is empty")
        exit(1)
else:
    print("OPENAI_API_KEY is not set")
    exit(1)

# Parse arguments
parser = argparse.ArgumentParser(description="Query OpenAI API")
parser.add_argument("--prompt", help="Prompt to prepend to the input")
parser.add_argument("--model", default="gpt-4-turbo",
                    help="Model to use (default: gpt-4-turbo)")
parser.add_argument("--debug", action="store_true", help="Enable debug mode (shows request details)")
parser.add_argument("--json", action="store_true", help="Return a clean JSON response without streaming")
parser.add_argument("--embedding", action="store_true", help="Generate an embedding vector instead of a text response")
args = parser.parse_args()

# Since outside of the distrobox we may not have these modules
# quietly ignore the fact that they may not exist
try:
    # Read from standard input
    query = stdin.read()

    # Prepend prompt if provided
    if args.prompt:
        if query:
            query = f"{args.prompt}\n\n{query}"
        else:
            query = args.prompt

    # Set up API call
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    # Set the API endpoint based on the request type
    if args.embedding:
        # Use the embeddings API endpoint for OpenAI
        url = "https://api.openai.com/v1/embeddings"
        data = {
            "model": args.model if "embedding" in args.model else "text-embedding-3-small",
            "input": query
        }
    else:
        # Use the chat completions API endpoint for regular requests
        url = "https://api.openai.com/v1/chat/completions"
        data = {
            "model": args.model,
            "messages": [
                {
                    "role": "user",
                    "content": query
                }
            ],
            # Don't stream if JSON output is requested
            "stream": not args.json
        }

    # Print debug info if requested
    if args.debug:
        print(f"Debug: API URL: {url}", file=sys.stderr)
        print(f"Debug: Headers (API key partially hidden): {{'Authorization': 'Bearer {api_key[:5]}...{api_key[-4:]}', 'Content-Type': 'application/json'}}", file=sys.stderr)
        print(f"Debug: Data: {json.dumps(data)}", file=sys.stderr)

    # Send request to OpenAI API
    response = requests.post(url, headers=headers, json=data, stream=data.get("stream", False))

    if response.status_code != 200:
        print(f"Error: {response.status_code}")
        print(response.text)
        exit(1)
    
    # Handle the response based on request type
    if args.embedding:
        # Process embeddings response (never streamed)
        response_data = response.json()
        if "data" in response_data and len(response_data["data"]) > 0:
            # Extract and output just the embedding vector in JSON format
            embedding = response_data["data"][0]["embedding"]
            print(json.dumps({"embedding": embedding}))
        else:
            print(json.dumps(response_data))
    elif args.json:
        # Process standard JSON response (not streamed)
        response_data = response.json()
        # For chat completions, extract the message content
        if "choices" in response_data and len(response_data["choices"]) > 0:
            message = response_data["choices"][0]["message"]
            print(message["content"])
        else:
            # Just print the raw response as fallback
            print(json.dumps(response_data))
    else:
        # Process streaming response
        for line in response.iter_lines():
            if line:
                # Skip the initial "data: " prefix
                line_text = line.decode('utf-8')
                if line_text.startswith("data: "):
                    line_json = line_text[6:]
                    
                    # The last message is usually "data: [DONE]"
                    if line_json == "[DONE]":
                        break
                        
                    try:
                        event = json.loads(line_json)
                        # Extract content delta if it exists
                        if "choices" in event and len(event["choices"]) > 0:
                            choice = event["choices"][0]
                            if "delta" in choice and "content" in choice["delta"]:
                                print(choice["delta"]["content"], end="", flush=True)
                    except json.JSONDecodeError:
                        continue

except (ImportError, Exception) as e:
    print(f"Error: {e}")
    exit(1)