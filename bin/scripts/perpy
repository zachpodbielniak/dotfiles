#!/usr/bin/python3

from os import environ
from subprocess import run
from sys import argv, exit, stdin, stderr
import argparse
import json
import sys


ctr_id: str|None = ""
api_key: str|None = ""

if ("CONTAINER_ID" in environ):
    ctr_id = environ.get("CONTAINER_ID")

# if we are not in the 'dev' distrobox re-exec the script
# inside of the 'dev' distrobox
if ("dev" != ctr_id):
    cmd: list[str] = [
        "distrobox",
        "enter",
        "dev",
        "--",
        *argv
    ]

    run(cmd)
    exit(0)

if ("PERPLEXITY_TOKEN" in environ):
    api_key = environ.get("PERPLEXITY_TOKEN")
else:
    print("PERPLEXITY_TOKEN is not set")
    exit(1)

# Parse arguments
parser = argparse.ArgumentParser(description="Query Perplexity API")
parser.add_argument("--prompt", help="Prompt to prepend to the input")
parser.add_argument("--model", default="sonar-pro", help="Model to use (default: sonar-pro). Available models: sonar, sonar-pro, reasoning-pro, sonar-reasoning-pro, r1-1776")
parser.add_argument("--debug", action="store_true", help="Enable debug mode (shows request details)")
parser.add_argument("--json", action="store_true", help="Return a clean JSON response without streaming")
parser.add_argument("-S", "--no-streaming", action="store_true", help="Disable streaming mode for cleaner output capture")
parser.add_argument("--embedding", action="store_true", help="Generate an embedding vector instead of a text response")
parser.add_argument("-f", "--file", action="append", dest="files",
                    help="Include file content in the context (can be specified multiple times)")
parser.add_argument("-L", "--list-models", action="store_true",
                    help="List available models from the Perplexity API")
parser.add_argument("--no-color", action="store_true",
                    help="Disable colored output")
args = parser.parse_args()

# Since outside of the distrobox we may not have these modules
# quietly ignore the fact that they may not exist
try:
    # Handle list-models option first
    if args.list_models:
        # Check if colors should be disabled
        use_colors = not args.no_color and environ.get("NO_COLOR", "").lower() not in ("1", "true")
        
        # ANSI color codes (conditionally set based on use_colors)
        class Colors:
            HEADER = '\033[95m' if use_colors else ''
            BLUE = '\033[94m' if use_colors else ''
            CYAN = '\033[96m' if use_colors else ''
            GREEN = '\033[92m' if use_colors else ''
            YELLOW = '\033[93m' if use_colors else ''
            RED = '\033[91m' if use_colors else ''
            BOLD = '\033[1m' if use_colors else ''
            UNDERLINE = '\033[4m' if use_colors else ''
            END = '\033[0m' if use_colors else ''
        
        # Note: Perplexity doesn't provide a public models listing endpoint
        # Maintaining a curated list of known models
        models = [
            ("sonar-pro", "Sonar Pro", "Premium model with web search (default)"),
            ("sonar", "Sonar", "Standard model with web search"),
            ("reasoning-pro", "Reasoning Pro", "Advanced reasoning model"),
            ("sonar-reasoning-pro", "Sonar Reasoning Pro", "Premium reasoning model"),
            ("r1-1776", "R1-1776", "Revolutionary reasoning model"),
        ]
        
        # Calculate column widths
        max_model = max(len(model[0]) for model in models)
        max_name = max(len(model[1]) for model in models)
        max_desc = max(len(model[2]) for model in models)
        
        # Ensure minimum widths
        max_model = max(max_model, len("Model ID"))
        max_name = max(max_name, len("Name"))
        max_desc = max(max_desc, len("Description"))
        
        # Print header
        print(f"\n{Colors.BOLD}{Colors.CYAN}Available Perplexity Models:{Colors.END}")
        print(f"{Colors.BOLD}{'─' * (max_model + max_name + max_desc + 6)}{Colors.END}")
        
        # Print table header
        print(f"{Colors.BOLD}{Colors.HEADER}{'Model ID':<{max_model}} {'Name':<{max_name}} {'Description':<{max_desc}}{Colors.END}")
        print(f"{Colors.BOLD}{'─' * max_model} {'─' * max_name} {'─' * max_desc}{Colors.END}")
        
        # Print table rows
        for i, (model_id, name, description) in enumerate(models):
            # Alternate row colors
            color = Colors.CYAN if i % 2 == 0 else Colors.BLUE
            name_color = Colors.GREEN
            desc_color = Colors.YELLOW
            
            print(f"{color}{model_id:<{max_model}}{Colors.END} "
                  f"{name_color}{name:<{max_name}}{Colors.END} "
                  f"{desc_color}{description:<{max_desc}}{Colors.END}")
        
        print(f"{Colors.BOLD}{'─' * (max_model + max_name + max_desc + 6)}{Colors.END}")
        print(f"{Colors.BOLD}Total models: {Colors.GREEN}{len(models)}{Colors.END}\n")
        
        exit(0)
    
    from perplexipy import PerplexityClient
    client: PerplexityClient
    client = PerplexityClient(key=api_key)
    client.model = args.model

    # Print debug info if requested
    if args.debug:
        print(f"Debug: Using Perplexity API", file=sys.stderr)
        print(f"Debug: API key (partially hidden): {api_key[:5]}...{api_key[-4:]}", file=sys.stderr)
        print(f"Debug: Model: {args.model}", file=sys.stderr)
except ImportError:
    pass

# Read file contents if any files were specified
file_contents = []
if args.files:
    for file_path in args.files:
        try:
            with open(file_path, 'r') as f:
                file_content = f.read()
                file_contents.append(f"=== File: {file_path} ===\n{file_content}\n")
        except IOError as e:
            print(f"Warning: Could not read file {file_path}: {e}", file=stderr)

# Read from standard input
query = stdin.read()

# Combine file contents with query
combined_parts = []

# Add file contents first if any
if file_contents:
    combined_parts.extend(file_contents)

# Add prompt if provided
if args.prompt:
    combined_parts.append(args.prompt)

# Add stdin content if any
if query:
    combined_parts.append(query)

# Combine all parts
if combined_parts:
    query = "\n".join(combined_parts)
else:
    query = ""

# Print debug info for query if requested
if args.debug:
    print(f"Debug: Query: {query[:100]}{'...' if len(query) > 100 else ''}", file=sys.stderr)

# Execute the API call based on the request type
if args.embedding:
    # Use the get_embedding method for embeddings
    # Note: Default to sonar-small-online model for embeddings
    embedding_model = "sonar-small-online"
    if args.debug:
        print(f"Debug: Generating embedding with model {embedding_model}", file=sys.stderr)
    
    try:
        # Generate embedding
        embedding = client.get_embedding(query, model=embedding_model)
        # Output as JSON for semantic_search to parse
        print(json.dumps({"embedding": embedding}))
    except Exception as e:
        if args.debug:
            print(f"Debug: Error generating embedding: {e}", file=sys.stderr)
        # Fallback to empty embedding
        print(json.dumps({"embedding": []}))
        
# Execute normal query with or without streaming
elif args.json or args.no_streaming:
    # Use non-streaming version for clean output
    if args.debug:
        print(f"Debug: Executing non-streaming query", file=sys.stderr)
    result = client.query(query)
    print(result)
else:
    # Use streaming version for interactive output
    if args.debug:
        print(f"Debug: Executing streaming query", file=sys.stderr)
    results = client.queryStreamable(query)
    for result in results:
        # flush since it may not have a '\n' to give it
        # a streaming output appearance
        print(result, end="", flush=True)

