#!/bin/bash
set -euo pipefail

# ==============================================================================
# sbi - Second Brain Ingest
# ==============================================================================
# Author: Zach
# Version: 1.0
# Last Updated: May 4, 2025
# Location: ~/.dotfiles/bin/scripts/sbi
#
# Description:
# A comprehensive utility for ingesting various content types into a second brain 
# knowledge management system organized using the PARA methodology (Projects, 
# Areas, Resources, Archives). This script handles multiple content formats, from
# plain text to multimedia, converting them to a consistent Neorg format.
#
# Features:
# - Supports multiple content types (text, audio, video, web content, ebooks, PDFs)
# - Automatically transcribes audio/video files using Whisper
# - Generates AI summaries of content
# - Processes YouTube videos and other web content directly from URLs
# - Supports piping content from stdin
# - Integrates with the PARA organizational structure
# - Provides content editing capabilities
# - Supports custom naming for ingested content
# - Offers directory structure viewing and navigation
# - Handles append mode for existing files
#
# Dependencies:
# - transcribe_audio: For audio transcription (via Whisper distrobox)
# - strip_audio: For extracting audio from video (via FFmpeg)
# - ai_summary_as_neorg: For generating summaries in Neorg format
# - perpy: For AI-based PARA category detection
# - mton: For Markdown to Neorg conversion
# - yt-dlp: For YouTube content downloading
# - pandoc: For document format conversion
# - curl: For web content downloading
# - vipe: For editing content within pipes
# - Various fallback utilities: lynx/w3m, pdftotext, etc.
#
# Usage: See the show_help() function or run with --help flag
# ==============================================================================

# Configuration
NOTES_DIR="$HOME/Documents/notes"  # Base directory for second brain
DEFAULT_PARA="00_inbox"            # Default PARA category if none specified
PARA_MAP=("00_inbox" "01_projects" "02_areas" "03_resources" "04_archives")  # Valid PARA categories

show_help() {
    cat << EOF
Usage: sbi [OPTIONS] FILE1 [FILE2 ...]

Ingest files into second brain with PARA organization.

Options:
  -h, --help              Show this help message
  -p, --para CATEGORY     Specify PARA category (inbox, project, area, resource, archive, detect)
  -c, --category PATH     Specify subcategory path (e.g., "personal" or "technical/linux")
  -l, --list              List the second brain directory structure
  -L, --list-files        List the second brain directory structure including files
  -f, --full-path         Show full paths in directory listings
  --format FORMAT         Specify format for stdin content (e.g., "txt", "md", "json")
  -e, --edit              Edit content before writing to file
  --name-seed NAME        Use NAME as seed for filename (for stdin content)

Examples:
  sbi document.md                          # Ingest to inbox
  sbi --para project document.md           # Ingest to projects
  sbi --para resource --category technical/linux document.md  # Ingest to specific path
  sbi --para detect document.md            # Auto-detect PARA category
  sbi --list                               # List directory structure
  echo "* My neorg content" | sbi          # Pipe neorg content directly
  cat data.json | sbi --format json        # Pipe content with specified format
  echo "Draft note" | sbi --edit           # Open editor to modify before saving
  echo "Meeting notes" | sbi --name-seed "team meeting" # Use custom filename
  sbi recording.mp3                        # Transcribe audio and create summary
  sbi meeting.mp4                          # Extract audio, transcribe, and summarize
  sbi https://youtu.be/dQw4w9WgXcQ        # Download YouTube audio, transcribe, and summarize
  sbi https://example.com/article          # Download web page, summarize, and convert to neorg
  sbi document.pdf                         # Convert PDF, generate summary, and save as neorg
  sbi book.epub                            # Convert ebook, generate summary, and save as neorg
  sbi document.docx                        # Convert Office document, generate summary, and save as neorg
  sbi presentation.pptx                    # Convert presentation, generate summary, and save as neorg
EOF
    exit 0
}

list_structure() {
    # Function: list_structure
    # Purpose: Display the directory structure of the Second Brain
    # Arguments:
    #   $1 - Optional PARA category filter (inbox, project, area, resource, archive)
    #   $2 - Optional subcategory path filter
    #   $3 - Optional boolean to include files in listing (true/false)
    #   $4 - Optional boolean to show full paths (true/false)
    # Returns: Prints directory structure to stdout and exits
    
    local filter_para=""       # PARA category to filter by
    local filter_category=""   # Subcategory path to filter by
    local include_files=false  # Whether to include files in the listing
    local show_full_path=false # Whether to show full paths instead of relative paths
    
    # Parse arguments for filtering
    if [[ $# -ge 1 ]]; then
        filter_para="$1"  # First arg is PARA category
    fi
    
    if [[ $# -ge 2 ]]; then
        filter_category="$2"  # Second arg is subcategory path
    fi
    
    if [[ $# -ge 3 && "$3" == "true" ]]; then
        include_files=true  # Third arg controls file inclusion
    fi
    
    if [[ $# -ge 4 && "$4" == "true" ]]; then
        show_full_path=true  # Fourth arg controls path format
    fi
    
    # Check for required utilities
    if ! command -v find &> /dev/null || ! command -v sort &> /dev/null; then
        echo "Error: Required tools 'find' and 'sort' not found."
        exit 1
    fi
    
    echo "Second Brain Structure at: $NOTES_DIR"
    
    # Make sure NOTES_DIR exists
    if [[ ! -d "$NOTES_DIR" ]]; then
        echo "Error: Notes directory '$NOTES_DIR' does not exist."
        exit 1
    fi
    
    # Map PARA type to folder name
    local target_para=""
    if [[ -n "$filter_para" ]]; then
        case "$filter_para" in
            inbox)
                target_para="00_inbox"
                ;;
            project)
                target_para="01_projects"
                ;;
            area)
                target_para="02_areas"
                ;;
            resource)
                target_para="03_resources"
                ;;
            archive)
                target_para="04_archives"
                ;;
            *)
                echo "Error: Invalid PARA type. Must be one of: inbox, project, area, resource, archive"
                exit 1
                ;;
        esac
        
        # Check if the PARA directory exists
        if [[ ! -d "$NOTES_DIR/$target_para" ]]; then
            echo "Error: PARA directory '$target_para' does not exist."
            exit 1
        fi
        
        # If category is specified, check if that path exists
        if [[ -n "$filter_category" ]]; then
            local category_path="$NOTES_DIR/$target_para/$filter_category"
            if [[ ! -d "$category_path" ]]; then
                echo "Error: Category path '$filter_category' does not exist under '$target_para'."
                exit 1
            fi
            
            # Print filtered directory structure with category
            echo "Directory structure for $target_para/$filter_category:"
            
            # List all directories under the specified category
            if [[ "$show_full_path" == true ]]; then
                echo "$target_para/$filter_category/"
            fi
            
            # Start with base indentation level based on category depth
            local base_depth=$(echo "$filter_category" | tr -cd '/' | wc -c)
            
            # Find type based on whether to include files
            local find_type="-type d"
            if [[ "$include_files" == true ]]; then
                find_type=""  # No type filter to include both files and directories
            fi
            
            # List directories and optionally files under the specified category
            find "$category_path" $find_type -print | sort | while read -r path; do
                # Skip the category directory itself
                if [[ "$path" == "$category_path" ]]; then
                    continue
                fi
                
                # Get relative path from category directory
                rel_path="${path#$category_path/}"
                
                # Skip empty entries
                if [[ -z "$rel_path" ]]; then
                    continue
                fi
                
                # Calculate directory depth for indentation (relative to category)
                depth=$(echo "$rel_path" | tr -cd '/' | wc -c)
                indent=$(printf '%*s' "$((depth*2))" '')
                
                # Determine what to display based on full path option
                if [[ "$show_full_path" == true ]]; then
                    # Show the full path from the notes directory
                    display_path="${path#$NOTES_DIR/}"
                    
                    if [[ -d "$path" ]]; then
                        echo "${display_path}/"
                    elif [[ "$include_files" == true ]]; then
                        echo "${display_path}"
                    fi
                else
                    # Show just the item name with indentation
                    item_name=$(basename "$path")
                    
                    if [[ -d "$path" ]]; then
                        echo "${indent}${item_name}/"
                    elif [[ "$include_files" == true ]]; then
                        echo "${indent}${item_name}"
                    fi
                fi
            done
        else
            # Print filtered directory structure for PARA only
            echo "Directory structure for $target_para:"
            
            # List PARA directory itself when using full path
            if [[ "$show_full_path" == true ]]; then
                echo "$target_para/"
            fi
            
            # Find type based on whether to include files
            local find_type="-type d"
            if [[ "$include_files" == true ]]; then
                find_type=""  # No type filter to include both files and directories
            fi
            
            # List directories and optionally files under the specified PARA
            find "$NOTES_DIR/$target_para" -mindepth 1 $find_type -print | sort | while read -r path; do
                # Get relative path from PARA directory
                rel_path="${path#$NOTES_DIR/$target_para/}"
                
                # Skip empty entries
                if [[ -z "$rel_path" ]]; then
                    continue
                fi
                
                # Calculate directory depth for indentation
                depth=$(echo "$rel_path" | tr -cd '/' | wc -c)
                indent=$(printf '%*s' "$((depth*2))" '')
                
                # Determine what to display based on full path option
                if [[ "$show_full_path" == true ]]; then
                    # Show the full path from the notes directory
                    display_path="${path#$NOTES_DIR/}"
                    
                    if [[ -d "$path" ]]; then
                        echo "${display_path}/"
                    elif [[ "$include_files" == true ]]; then
                        echo "${display_path}"
                    fi
                else
                    # Show just the item name with indentation
                    item_name=$(basename "$path")
                    
                    if [[ -d "$path" ]]; then
                        echo "${indent}${item_name}/"
                    elif [[ "$include_files" == true ]]; then
                        echo "${indent}${item_name}"
                    fi
                fi
            done
        fi
    else
        # Show full directory structure (all PARA folders)
        echo "Directory structure:"
        
        # List all PARA directories
        for para in 00_inbox 01_projects 02_areas 03_resources 04_archives; do
            para_dir="$NOTES_DIR/$para"
            
            # Skip if the directory doesn't exist
            if [[ ! -d "$para_dir" ]]; then
                continue
            fi
            
            # Print the top-level PARA folder, optionally with full path
            if [[ "$show_full_path" == true ]]; then
                echo "$para/"
            else
                echo "$para"
            fi
            
            # Find type based on whether to include files
            local find_type="-type d"
            if [[ "$include_files" == true ]]; then
                find_type=""  # No type filter to include both files and directories
            fi
            
            # List directories and optionally files with proper indentation
            find "$para_dir" -mindepth 1 $find_type -print | sort | while read -r path; do
                # Get relative path from PARA directory
                rel_path="${path#$para_dir/}"
                
                # Skip empty entries
                if [[ -z "$rel_path" ]]; then
                    continue
                fi
                
                # Calculate directory depth for indentation
                depth=$(echo "$rel_path" | tr -cd '/' | wc -c)
                indent=$(printf '%*s' "$((depth*2 + 2))" '')
                
                # Determine what to display based on full path option
                if [[ "$show_full_path" == true ]]; then
                    # Show the full path from the notes directory
                    display_path="${path#$NOTES_DIR/}"
                    
                    if [[ -d "$path" ]]; then
                        echo "${display_path}/"
                    elif [[ "$include_files" == true ]]; then
                        echo "${display_path}"
                    fi
                else
                    # Show just the item name with indentation
                    item_name=$(basename "$path")
                    
                    if [[ -d "$path" ]]; then
                        echo "${indent}${item_name}/"
                    elif [[ "$include_files" == true ]]; then
                        echo "${indent}${item_name}"
                    fi
                fi
            done
        done
    fi
    
    exit 0
}

detect_para_category() {
    # Function: detect_para_category
    # Purpose: Use AI to detect the appropriate PARA category for content
    # Arguments:
    #   $1 - The file to analyze
    # Returns: Prints the detected category (inbox, project, area, resource, archive)
    #          and returns 0 if successful
    
    local file="$1"
    local content
    
    # Check if perpy exists (AI tool for text analysis)
    if ! command -v perpy &> /dev/null; then
        echo "Error: 'perpy' script not found. Defaulting to inbox."
        echo "inbox"
        return
    fi
    
    # Read the file content
    content=$(cat "$file")
    
    # Create a prompt for perpy to determine the PARA category
    # We're asking for a single-word response from the defined PARA categories
    # This helps ensure consistent categorization
    local category
    local query="Please analyze this content and determine which PARA category it belongs to. Respond with EXACTLY ONE WORD from these options: project, area, resource, archive. DO NOT include any explanation.\n\n${content}"

    # Send query to perpy and handle response
    # - Remove newlines
    # - Convert to lowercase
    # - Trim whitespace
    category=$(perpy <<< "${query}" | tr -d '\n' | tr '[:upper:]' '[:lower:]' | xargs)
    
    # Validate and clean response to ensure it's one of our expected categories
    # Use pattern matching to handle partial matches or extra text
    case "$category" in
        *project*)
            echo "project"  # Active projects with defined outcomes
            ;;
        *area*)
            echo "area"     # Ongoing responsibilities with standards
            ;;
        *resource*)
            echo "resource" # Topics and themes of interest
            ;;
        *archive*)
            echo "archive"  # Inactive items from other categories
            ;;
        *)
            echo "inbox"    # Default to inbox if we can't determine category
            ;;
    esac
}

# Function to edit content using vipe or direct editor if edit flag is set
edit_with_vipe() {
    # Function: edit_with_vipe
    # Purpose: Edit file content with vipe or fallback to direct editor
    # Arguments:
    #   $1 - Input file path
    #   $2 - Output file path
    # Returns: None, modifies output_file with edited content
    
    local input_file="$1"   # Source file to read
    local output_file="$2"  # Destination file to write
    
    if [[ "$EDIT_FLAG" == true ]]; then
        # Only attempt editing if edit flag is set
        
        # Check if vipe is installed (moreutils package)
        if ! command -v vipe &> /dev/null; then
            echo "Warning: 'vipe' utility not found. Skipping edit phase."
            cp "$input_file" "$output_file"
            return
        fi
        
        # Use vipe to edit the content in the pipeline
        # vipe allows editing content within a pipe using $EDITOR
        # If vipe fails, fall back to direct editor
        if ! cat "$input_file" | vipe > "$output_file" 2>/dev/null; then
            echo "Warning: vipe failed. Falling back to direct editor."
            # Fall back to using the default editor directly on the input file
            EDIT_TMP="$input_file"
            ${EDITOR:-vi} "$EDIT_TMP"  # Use $EDITOR if set, otherwise default to vi
            cp "$EDIT_TMP" "$output_file"
        fi
    else
        # No edit requested, just copy the file without modification
        cp "$input_file" "$output_file"
    fi
}

convert_to_neorg() {
    # Function: convert_to_neorg
    # Purpose: Convert various file formats to Neorg format
    # Arguments:
    #   $1 - Input file path
    #   $2 - Output file path
    # Returns: 0 on success, non-zero on failure
    
    local input_file="$1"    # Source file to convert
    local output_file="$2"   # Destination file for neorg content
    local file_ext="${input_file##*.}"  # File extension to determine format
    local temp_output        # Temporary file for conversion
    
    # Special case for stdin with format already specified or any stdin in edit mode
    # We've already handled this content appropriately earlier
    if [[ "$STDIN_MODE" == true && "$input_file" == "$TEMP_FILE" ]]; then
        # Just copy the content as-is - we've already handled editing in the stdin processing 
        # and/or formatted it as a code block
        cp "$input_file" "$output_file"
        return 0
    fi
    
    # Handle Markdown files with special conversion
    if [[ "$file_ext" == "md" || "$file_ext" == "markdown" || "$file_ext" == "MD" ]]; then
        # Check if mton (Markdown to Neorg converter) exists
        if command -v mton &> /dev/null; then
            # Create temp file for intermediate result
            temp_output=$(mktemp /tmp/sbi-convert-XXXXXX)
            
            # Read the content and pass it to mton for conversion
            local content
            content=$(cat "$input_file")
            mton <<< "${content}" > "$temp_output"
            
            # Edit the converted content if requested
            if [[ "$EDIT_FLAG" == true ]]; then
                edit_with_vipe "$temp_output" "$output_file"
            else
                cp "$temp_output" "$output_file"
            fi
            
            # Clean up temporary files
            rm -f "$temp_output"
            return 0
        else
            echo "Warning: 'mton' script not found for Markdown conversion. Falling back to code block."
        fi
    fi
    
    # For all other formats (or if mton fails), put content in a Neorg code block
    # This preserves the original format while still making it Neorg-compatible
    temp_output=$(mktemp /tmp/sbi-convert-XXXXXX)
    
    {
        echo "@code $file_ext"  # Start Neorg code block with file extension as language
        cat "$input_file"       # Include the file content
        echo "@end"             # End Neorg code block
    } > "$temp_output"
    
    # Edit if requested
    if [[ "$EDIT_FLAG" == true ]]; then
        edit_with_vipe "$temp_output" "$output_file"
    else
        cp "$temp_output" "$output_file"
    fi
    
    # Clean up temporary files
    rm -f "$temp_output"
    return 0  # Indicate successful conversion
}

is_neorg_file() {
    # Function: is_neorg_file
    # Purpose: Determine if a file is already in Neorg format
    # Arguments:
    #   $1 - File path to check
    # Returns: 0 if the file is Neorg, 1 otherwise
    
    local file="$1"
    local file_ext="${file##*.}"
    
    # Check if it's a .norg file by extension
    if [[ "$file_ext" == "norg" ]]; then
        return 0  # It's a .norg file, so definitely Neorg format
    fi
    
    # Special case for stdin content:
    # If it's our temp file from stdin AND no format was specified,
    # we assume it's already in neorg format
    if [[ "$STDIN_MODE" == true && "$file" == "$TEMP_FILE" && -z "$STDIN_FORMAT" ]]; then
        return 0  # Stdin with no format specified is assumed to be Neorg
    fi
    
    # For all other cases, assume it's not a Neorg file
    # Even if format is specified for stdin, the convert_to_neorg function
    # will handle it properly, so no need for special case here
    return 1  # Not a Neorg file
}

# Function to detect audio files by extension
is_audio_file() {
    # Function: is_audio_file
    # Purpose: Detect if a file is an audio file based on its extension
    # Arguments:
    #   $1 - File path to check
    # Returns: 0 if file is audio, 1 otherwise
    
    local file="$1"
    local file_ext="${file##*.}"  # Extract extension
    local file_ext_lower=$(echo "$file_ext" | tr '[:upper:]' '[:lower:]')  # Case-insensitive matching
    
    # Common audio file extensions
    case "$file_ext_lower" in
        mp3|wav|ogg|flac|m4a|aac|wma|opus)
            return 0  # File is a recognized audio format
            ;;
        *)
            return 1  # Not a recognized audio file
            ;;
    esac
}

# Function to detect video files by extension
is_video_file() {
    # Function: is_video_file
    # Purpose: Detect if a file is a video file based on its extension
    # Arguments:
    #   $1 - File path to check
    # Returns: 0 if file is video, 1 otherwise
    
    local file="$1"
    local file_ext="${file##*.}"  # Extract extension
    local file_ext_lower=$(echo "$file_ext" | tr '[:upper:]' '[:lower:]')  # Case-insensitive matching
    
    # Common video file extensions
    case "$file_ext_lower" in
        mp4|mkv|avi|mov|wmv|flv|webm|m4v|mpg|mpeg)
            return 0  # File is a recognized video format
            ;;
        *)
            return 1  # Not a recognized video file
            ;;
    esac
}

# Function to detect ebook files by extension
is_ebook_file() {
    # Function: is_ebook_file
    # Purpose: Detect if a file is an ebook based on its extension
    # Arguments:
    #   $1 - File path to check
    # Returns: 0 if file is an ebook, 1 otherwise
    
    local file="$1"
    local file_ext="${file##*.}"  # Extract extension
    local file_ext_lower=$(echo "$file_ext" | tr '[:upper:]' '[:lower:]')  # Case-insensitive matching
    
    # Common ebook file extensions
    case "$file_ext_lower" in
        # Multiple ebook formats supported
        epub|mobi|azw|azw3|fb2|lit|prc|pdb)
            return 0  # File is a recognized ebook format
            ;;
        *)
            return 1  # Not a recognized ebook file
            ;;
    esac
}

# Function to detect PDF files by extension
is_pdf_file() {
    # Function: is_pdf_file
    # Purpose: Detect if a file is a PDF based on its extension
    # Arguments:
    #   $1 - File path to check
    # Returns: 0 if file is PDF, 1 otherwise
    
    local file="$1"
    local file_ext="${file##*.}"  # Extract extension
    local file_ext_lower=$(echo "$file_ext" | tr '[:upper:]' '[:lower:]')  # Case-insensitive matching
    
    # Check for PDF extension
    if [[ "$file_ext_lower" == "pdf" ]]; then
        return 0  # File is a PDF
    else
        return 1  # Not a PDF file
    fi
}

# Function to detect office document files by extension
is_office_file() {
    # Function: is_office_file
    # Purpose: Detect if a file is an office document based on its extension
    # Arguments:
    #   $1 - File path to check
    # Returns: 0 if file is an office document, 1 otherwise
    
    local file="$1"
    local file_ext="${file##*.}"  # Extract extension
    local file_ext_lower=$(echo "$file_ext" | tr '[:upper:]' '[:lower:]')  # Case-insensitive matching
    
    # Common office document extensions
    case "$file_ext_lower" in
        # Microsoft Office and Open Document formats
        docx|pptx|odt|odp)
            return 0  # File is a recognized office document format
            ;;
        *)
            return 1  # Not a recognized office document
            ;;
    esac
}

# Function to detect if a string is a URL
is_url() {
    # Function: is_url
    # Purpose: Detect if a string is a valid URL
    # Arguments:
    #   $1 - String to check
    # Returns: 0 if string is a URL, 1 otherwise
    
    local input="$1"
    
    # Basic URL pattern matching for HTTP/HTTPS URLs
    # This is a simple regex to match URLs starting with http:// or https://
    if [[ "$input" =~ ^https?:// ]]; then
        return 0  # String is a URL
    else
        return 1  # Not a URL
    fi
}

# Function to detect YouTube URLs specifically
is_youtube_url() {
    # Function: is_youtube_url
    # Purpose: Detect if a URL is from YouTube
    # Arguments:
    #   $1 - URL to check
    # Returns: 0 if URL is from YouTube, 1 otherwise
    
    local url="$1"
    
    # Match common YouTube URL patterns
    # Using grep with regex for more reliable pattern matching
    # - youtube.com/watch (standard YouTube URL)
    # - youtu.be/ (YouTube short URL)
    if echo "$url" | grep -q -E 'youtube\.com/watch|youtu\.be/'; then
        return 0  # URL is from YouTube
    else
        return 1  # Not a YouTube URL
    fi
}

# Function to download a generic URL and convert to markdown
download_url_as_markdown() {
    local url="$1"
    local output_file="$2"
    
    echo "Downloading web page from URL: $url"
    
    # Create temp directory for processing
    local temp_dir=$(mktemp -d /tmp/sbi-url-XXXXXX)
    local html_file="${temp_dir}/page.html"
    local md_file="${temp_dir}/page.md"
    
    # Check if curl is installed
    if ! command -v curl &> /dev/null; then
        echo "Error: curl not found. Please install it to download web pages."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Download the webpage with curl
    echo "Fetching web page content..."
    if ! curl -s -L --max-redirs 5 --connect-timeout 10 --max-time 30 -A "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36" "$url" > "$html_file"; then
        echo "Error: Failed to download web page."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Check if pandoc is installed for HTML to Markdown conversion
    if command -v pandoc &> /dev/null; then
        echo "Converting HTML to Markdown using pandoc..."
        if ! pandoc -f html -t markdown_strict "$html_file" -o "$md_file"; then
            echo "Error: Failed to convert HTML to Markdown with pandoc."
            rm -rf "$temp_dir"
            return 1
        fi
    # Fallback to using distrobox with pandoc if system pandoc isn't available
    elif command -v distrobox &> /dev/null; then
        echo "Attempting to use pandoc via distrobox..."
        if ! distrobox enter dev -- pandoc -f html -t markdown_strict "$html_file" -o "$md_file"; then
            echo "Error: Failed to convert HTML to Markdown with pandoc via distrobox."
            rm -rf "$temp_dir"
            return 1
        fi
    # Last resort: Use a very simple HTML to text conversion with lynx or w3m
    elif command -v lynx &> /dev/null; then
        echo "Using lynx for basic HTML to text conversion..."
        if ! lynx -dump -nolist "$html_file" > "$md_file"; then
            echo "Error: Failed to convert HTML to text with lynx."
            rm -rf "$temp_dir"
            return 1
        fi
    elif command -v w3m &> /dev/null; then
        echo "Using w3m for basic HTML to text conversion..."
        if ! w3m -dump "$html_file" > "$md_file"; then
            echo "Error: Failed to convert HTML to text with w3m."
            rm -rf "$temp_dir"
            return 1
        fi
    else
        echo "Error: No HTML to Markdown conversion tools found (pandoc, lynx, or w3m)."
        # Store the URL in the metadata
        echo "$url" > "${output_file}.url"
        # Copy the raw HTML as a fallback
        cp "$html_file" "$output_file"
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Extract title from HTML for potential use as filename
    local title=$(grep -oP '(?<=<title>).*?(?=</title>)' "$html_file" | head -1 | sed 's/[^a-zA-Z0-9 ]/-/g' | tr -s ' ' '_')
    
    # Store URL and title in metadata files
    echo "$url" > "${output_file}.url"
    if [[ -n "$title" ]]; then
        echo "$title" > "${output_file}.title"
    fi
    
    # Copy the markdown to the output file
    cp "$md_file" "$output_file"
    
    # Clean up
    rm -rf "$temp_dir"
    
    echo "Successfully downloaded and converted URL to Markdown: $output_file"
    return 0
}

# Function to download audio from YouTube URL
download_youtube_audio() {
    local url="$1"
    local output_file="$2"
    
    echo "Downloading audio from YouTube URL: $url"
    
    # Check if yt-dlp is installed
    if ! command -v yt-dlp &> /dev/null; then
        echo "Error: yt-dlp not found. Please install it to download YouTube videos."
        return 1
    fi
    
    # Create temporary directory for yt-dlp 
    local dl_dir=$(dirname "$output_file")
    
    # Download best audio quality and convert to ogg
    # Use more reliable options: specify extension explicitly and use output template
    local base_name=$(basename "$output_file")
    
    # For better reliability:
    # 1. Using wav format which is more widely supported by transcribe_audio
    # 2. Use explicit output template with the wav extension
    # 3. Add --no-playlist to avoid playlist processing
    # 4. Add --no-check-certificate for some problematic URLs
    # 5. Add verbose output for debugging
    echo "Running yt-dlp to download audio in WAV format..."
    if ! yt-dlp -f "bestaudio" -x --audio-format wav --audio-quality 0 \
              --no-playlist --no-check-certificate --verbose \
              -o "${dl_dir}/${base_name}.wav" "$url"; then
        echo "Error: Failed to download audio from YouTube URL."
        return 1
    fi
    
    echo "yt-dlp completed. Checking for downloaded file..."
    # First check for the expected WAV file
    if [[ -f "${dl_dir}/${base_name}.wav" ]]; then
        echo "Found WAV file: ${dl_dir}/${base_name}.wav"
        cp "${dl_dir}/${base_name}.wav" "${output_file}"
        echo "Copied WAV file to: ${output_file}"
    else
        # Fallback: find any file that might have been created
        echo "WAV file not found at expected location. Searching for alternatives..."
        local found_file=$(find "$dl_dir" -name "${base_name}.*" -type f | head -1)
        
        # If we found something, use it
        if [[ -n "$found_file" && -f "$found_file" ]]; then
            echo "Found alternative file: ${found_file}"
            cp "$found_file" "${output_file}"
            echo "Copied alternative file to: ${output_file}"
        else
            echo "Error: Downloaded file not found."
            return 1
        fi
    fi
    
    # Final verification
    if [[ ! -f "$output_file" ]]; then
        echo "Error: Failed to process downloaded file."
        return 1
    fi
    
    echo "Successfully downloaded audio to: $output_file"
    return 0
}

# Function to process audio files (transcribe and summarize)
process_audio_file() {
    local input_file="$1"
    local output_file="$2"
    local filename_base="$3"
    
    echo "Processing audio file: $input_file"
    
    # Create temp directory for processing
    local temp_dir=$(mktemp -d /tmp/sbi-audio-XXXXXX)
    
    # Generate transcript with transcribe_audio
    echo "Transcribing audio..."
    local transcript_file="${temp_dir}/transcript.txt"
    if ! transcribe_audio "$input_file"; then
        echo "Error: Transcription failed."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Check if transcript was generated
    if [[ ! -f "${input_file}.txt" ]]; then
        echo "Error: Expected transcript file not found at ${input_file}.txt"
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Move the transcript to our temp directory
    mv "${input_file}.txt" "$transcript_file"
    
    # Generate summary in neorg format
    echo "Generating summary..."
    ai_summary_as_neorg < "${transcript_file}" > "$output_file"
    
    # Add source information to the beginning of the file
    local temp_output="${temp_dir}/output.norg"
    
    # Check if this is from a YouTube URL
    local youtube_url=""
    if [[ -f "${input_file}.yturl" ]]; then
        youtube_url=$(cat "${input_file}.yturl")
    fi
    
    {
        echo "* Audio Summary: ${filename_base}"
        echo
        if [[ -n "$youtube_url" ]]; then
            echo "Source: YouTube video"
            echo "URL: ${youtube_url}"
        else
            echo "Source audio: ${input_file}"
        fi
        echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
        echo
        echo "* Summary"
        echo
        cat "$output_file"
    } > "$temp_output"
    
    # Replace output file with our enhanced version
    mv "$temp_output" "$output_file"
    
    # Clean up
    rm -rf "$temp_dir"
    
    echo "Audio processing complete."
    return 0
}

# Function to convert ebook/PDF to markdown
convert_document_to_markdown() {
    local input_file="$1"
    local output_file="$2"
    
    echo "Converting document to markdown: $input_file"
    
    # Create temp directory for processing
    local temp_dir=$(mktemp -d /tmp/sbi-doc-convert-XXXXXX)
    
    # Get file extension and determine input format for pandoc
    local file_ext="${input_file##*.}"
    local file_ext_lower=$(echo "$file_ext" | tr '[:upper:]' '[:lower:]')
    local pandoc_input_format=""
    
    # Map file extensions to pandoc input formats
    case "$file_ext_lower" in
        epub)
            pandoc_input_format="epub"
            ;;
        pdf)
            pandoc_input_format="pdf"
            ;;
        mobi|azw|azw3)
            # Pandoc doesn't directly support these formats
            # Try using epub as a fallback (might not work)
            pandoc_input_format="epub"
            echo "Warning: Pandoc might not fully support $file_ext_lower format."
            ;;
        docx)
            pandoc_input_format="docx"
            ;;
        pptx)
            pandoc_input_format="pptx"
            ;;
        *)
            # For other formats, try to use the extension as the format
            pandoc_input_format="$file_ext_lower"
            echo "Using $file_ext_lower as pandoc input format (may not be supported)."
            ;;
    esac
    
    # Check if pandoc is installed
    if command -v pandoc &> /dev/null; then
        echo "Using pandoc for conversion with format: $pandoc_input_format..."
        if ! pandoc -f "$pandoc_input_format" -t markdown_strict --extract-media="${temp_dir}/media" "$input_file" -o "$output_file"; then
            echo "Error: Pandoc conversion failed."
            # Try fallback to distrobox
            echo "Trying pandoc via distrobox..."
            if command -v distrobox &> /dev/null; then
                if ! distrobox enter dev -- pandoc -f "$pandoc_input_format" -t markdown_strict --extract-media="${temp_dir}/media" "$input_file" -o "$output_file"; then
                    echo "Error: Distrobox pandoc conversion also failed."
                    
                    # For EPUB files, try unzipping and extracting content directly as a last resort
                    if [[ "$file_ext_lower" == "epub" ]] && command -v unzip &> /dev/null; then
                        echo "Attempting direct EPUB extraction as last resort..."
                        local epub_dir="${temp_dir}/epub_extract"
                        mkdir -p "$epub_dir"
                        
                        if unzip -q "$input_file" -d "$epub_dir"; then
                            # Try to find and extract content from OPF file
                            local opf_file=$(find "$epub_dir" -name "*.opf" | head -1)
                            local content_files=$(grep -o 'href="[^"]*\.x\?html\?"' "$opf_file" 2>/dev/null | sed 's/href="//;s/"$//' | sort)
                            
                            if [[ -n "$content_files" ]]; then
                                echo "# $(basename "${input_file%.*}")" > "$output_file"
                                echo >> "$output_file"
                                echo "*Extracted from EPUB file: $(basename "$input_file")*" >> "$output_file"
                                echo >> "$output_file"
                                
                                # Extract text from HTML files
                                for html_file in $content_files; do
                                    # Get the directory of the OPF file
                                    local opf_dir=$(dirname "$opf_file")
                                    local full_path="$opf_dir/$html_file"
                                    
                                    # If the file exists, extract text
                                    if [[ -f "$full_path" ]]; then
                                        # Use lynx or w3m to convert HTML to text
                                        if command -v lynx &> /dev/null; then
                                            lynx -dump -nolist "$full_path" >> "$output_file"
                                        elif command -v w3m &> /dev/null; then
                                            w3m -dump "$full_path" >> "$output_file"
                                        else
                                            # Last resort: crude HTML tag removal
                                            sed -e 's/<[^>]*>//g' "$full_path" >> "$output_file"
                                        fi
                                        echo >> "$output_file"
                                        echo "---" >> "$output_file"
                                        echo >> "$output_file"
                                    fi
                                done
                                
                                # If we succeeded in extracting something
                                if [[ -s "$output_file" ]]; then
                                    echo "Successfully extracted content directly from EPUB."
                                    rm -rf "$epub_dir"
                                else
                                    rm -rf "$temp_dir"
                                    return 1
                                fi
                            else
                                rm -rf "$temp_dir"
                                return 1
                            fi
                        else
                            rm -rf "$temp_dir"
                            return 1
                        fi
                    else
                        rm -rf "$temp_dir"
                        return 1
                    fi
                fi
            else
                # If direct extraction failed or wasn't attempted
                echo "Error: No fallback conversion method available."
                rm -rf "$temp_dir"
                return 1
            fi
        fi
    # Try using distrobox with pandoc if system pandoc isn't available
    elif command -v distrobox &> /dev/null; then
        echo "Using pandoc via distrobox with format: $pandoc_input_format..."
        if ! distrobox enter dev -- pandoc -f "$pandoc_input_format" -t markdown_strict --extract-media="${temp_dir}/media" "$input_file" -o "$output_file"; then
            echo "Error: Distrobox pandoc conversion failed."
            rm -rf "$temp_dir"
            return 1
        fi
    # For PDFs, try pdftotext as a fallback
    elif [[ "$file_ext_lower" == "pdf" ]] && command -v pdftotext &> /dev/null; then
        echo "Using pdftotext for PDF conversion..."
        if ! pdftotext -layout "$input_file" "$temp_dir/temp.txt"; then
            echo "Error: pdftotext conversion failed."
            rm -rf "$temp_dir"
            return 1
        fi
        # Convert plain text to simple markdown
        {
            # Add title from filename
            echo "# $(basename "${input_file%.*}")"
            echo
            # Add file info
            echo "*Converted from PDF file: $(basename "$input_file")*"
            echo
            # Add content with paragraph breaks
            awk 'BEGIN{print ""}; {print $0"\n"}' "$temp_dir/temp.txt"
        } > "$output_file"
    # Try using pdf2txt.py from pdfminer if available
    elif [[ "$file_ext_lower" == "pdf" ]] && command -v pdf2txt.py &> /dev/null; then
        echo "Using pdf2txt.py for PDF conversion..."
        if ! pdf2txt.py -o "$temp_dir/temp.txt" "$input_file"; then
            echo "Error: pdf2txt.py conversion failed."
            rm -rf "$temp_dir"
            return 1
        fi
        # Convert plain text to simple markdown
        {
            # Add title from filename
            echo "# $(basename "${input_file%.*}")"
            echo
            # Add file info
            echo "*Converted from PDF file: $(basename "$input_file")*"
            echo
            # Add content with paragraph breaks
            awk 'BEGIN{print ""}; {print $0"\n"}' "$temp_dir/temp.txt"
        } > "$output_file"
    # Try unzip-based approach for EPUB as a standalone fallback
    elif [[ "$file_ext_lower" == "epub" ]] && command -v unzip &> /dev/null; then
        echo "Attempting direct EPUB extraction as standalone method..."
        local epub_dir="${temp_dir}/epub_extract"
        mkdir -p "$epub_dir"
        
        if unzip -q "$input_file" -d "$epub_dir"; then
            # Try to find and extract content from OPF file
            local opf_file=$(find "$epub_dir" -name "*.opf" | head -1)
            
            if [[ -n "$opf_file" && -f "$opf_file" ]]; then
                local content_files=$(grep -o 'href="[^"]*\.x\?html\?"' "$opf_file" 2>/dev/null | sed 's/href="//;s/"$//' | sort)
                
                if [[ -z "$content_files" ]]; then
                    # Try an alternative approach to find HTML files
                    content_files=$(find "$epub_dir" -name "*.html" -o -name "*.xhtml" | sort)
                fi
                
                if [[ -n "$content_files" ]]; then
                    echo "# $(basename "${input_file%.*}")" > "$output_file"
                    echo >> "$output_file"
                    echo "*Extracted from EPUB file: $(basename "$input_file")*" >> "$output_file"
                    echo >> "$output_file"
                    
                    # Extract text from HTML files
                    for html_file in $content_files; do
                        if [[ -f "$html_file" ]]; then
                            local file_to_process="$html_file"
                        else
                            # Path might be relative to OPF directory
                            local opf_dir=$(dirname "$opf_file")
                            local file_to_process="$opf_dir/$html_file"
                        fi
                        
                        # If the file exists, extract text
                        if [[ -f "$file_to_process" ]]; then
                            # Use lynx or w3m to convert HTML to text
                            if command -v lynx &> /dev/null; then
                                lynx -dump -nolist "$file_to_process" >> "$output_file"
                            elif command -v w3m &> /dev/null; then
                                w3m -dump "$file_to_process" >> "$output_file"
                            else
                                # Last resort: crude HTML tag removal
                                sed -e 's/<[^>]*>//g' "$file_to_process" >> "$output_file"
                            fi
                            echo >> "$output_file"
                            echo "---" >> "$output_file"
                            echo >> "$output_file"
                        fi
                    done
                    
                    # If we succeeded in extracting something
                    if [[ -s "$output_file" ]]; then
                        echo "Successfully extracted content directly from EPUB."
                    else
                        echo "Error: Failed to extract readable content from EPUB."
                        rm -rf "$temp_dir"
                        return 1
                    fi
                else
                    echo "Error: No content files found in EPUB."
                    rm -rf "$temp_dir"
                    return 1
                fi
            else
                echo "Error: Could not find OPF file in EPUB."
                rm -rf "$temp_dir"
                return 1
            fi
        else
            echo "Error: Failed to unzip EPUB file."
            rm -rf "$temp_dir"
            return 1
        fi
    else
        echo "Error: No conversion tools available. Please install pandoc, pdftotext, or pdf2txt.py."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Verify conversion worked
    if [[ ! -s "$output_file" ]]; then
        echo "Error: Conversion produced an empty file."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Add document metadata - prepend to the converted file
    local temp_output="${temp_dir}/output.md"
    
    {
        echo "---"
        echo "title: $(basename "${input_file%.*}")"
        echo "source_file: $(basename "$input_file")"
        echo "source_format: ${input_file##*.}"
        echo "converted_on: $(date +"%Y-%m-%d %H:%M:%S")"
        echo "---"
        echo
        cat "$output_file"
    } > "$temp_output"
    
    # Replace output file with enhanced version
    mv "$temp_output" "$output_file"
    
    # Clean up temp directory
    rm -rf "$temp_dir"
    
    echo "Document conversion complete: $output_file"
    return 0
}

# Function to process document content (ebook/PDF/office)
process_document_content() {
    local input_file="$1"
    local output_file="$2"
    local filename_base="$3"
    
    echo "Processing document: $input_file"
    
    # Create temp directory for processing
    local temp_dir=$(mktemp -d /tmp/sbi-document-XXXXXX)
    local md_file="${temp_dir}/content.md"
    local doc_type="${input_file##*.}"
    
    # Convert document to markdown
    if ! convert_document_to_markdown "$input_file" "$md_file"; then
        echo "Error: Document conversion failed."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Generate AI summary
    echo "Generating AI summary of document content..."
    local ai_summary="${temp_dir}/summary.norg"
    
    if command -v ai_summary_as_neorg &> /dev/null; then
        if ! cat "$md_file" | ai_summary_as_neorg > "$ai_summary"; then
            echo "Warning: AI summary generation failed. Creating basic summary."
            {
                echo "AI summary generation failed for this document."
                echo "Please refer to the original file for content."
            } > "$ai_summary"
        fi
    else
        echo "Warning: 'ai_summary_as_neorg' not found. Creating basic structure."
        {
            echo "AI summary tool not available."
            echo "Please refer to the original file for content."
        } > "$ai_summary"
    fi
    
    # Get document title from markdown metadata or filename
    local doc_title=$(grep -m 1 "^title: " "$md_file" | sed 's/^title: //' || echo "$filename_base")
    
    # Create content preview (first section or few pages)
    head -n 50 "$md_file" > "${temp_dir}/preview.md"
    
    # Create the final neorg file with document summary and metadata
    {
        # Document title and metadata
        echo "* Document Summary: ${doc_title}"
        echo
        echo "Source: ${doc_type} document"
        echo "Filename: $(basename "$input_file")"
        echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
        echo
        
        # AI Summary section
        echo "* AI Summary"
        echo
        cat "$ai_summary"
        echo
        
        # Preview section
        echo "* Content Preview"
        echo
        echo "This is just a preview of the document. The original file contains more content."
        echo
        
        # Convert preview to neorg if mton is available
        if command -v mton &> /dev/null; then
            mton < "${temp_dir}/preview.md" || {
                # Fallback if mton fails
                echo "@code markdown"
                cat "${temp_dir}/preview.md"
                echo "@end"
            }
        else
            # Fallback if mton is not available
            echo "@code markdown"
            cat "${temp_dir}/preview.md"
            echo "@end"
        fi
        
        # Reference to original document
        echo
        echo "* Original Document"
        echo
        echo "The original document is located at:"
        echo "@code bash"
        realpath "$input_file"
        echo "@end"
        
    } > "$output_file"
    
    # Clean up
    rm -rf "$temp_dir"
    
    echo "Document processing complete."
    return 0
}

# Function to process web content from URL
process_web_content() {
    local input_file="$1"
    local output_file="$2"
    local filename_base="$3"
    
    echo "Processing web content: $input_file"
    
    # Create temp directory for processing
    local temp_dir=$(mktemp -d /tmp/sbi-web-XXXXXX)
    local url=""
    local page_title=""
    
    # Check if URL metadata exists
    if [[ -f "${input_file}.url" ]]; then
        url=$(cat "${input_file}.url")
    fi
    
    # Check if title metadata exists
    if [[ -f "${input_file}.title" ]]; then
        page_title=$(cat "${input_file}.title")
    fi
    
    # Generate AI summary of the web content
    echo "Generating AI summary of web content..."
    local ai_summary=$(mktemp "${temp_dir}/ai_summary.XXXXXX")
    
    if command -v ai_summary_as_neorg &> /dev/null; then
        # Create AI summary in neorg format
        if ! cat "$input_file" | ai_summary_as_neorg > "$ai_summary"; then
            echo "Warning: AI summary generation failed. Will create a basic summary."
            # Create a minimal summary as fallback
            {
                echo "AI summary generation failed for this web content."
                echo "Please see the full content below."
            } > "$ai_summary"
        fi
    else
        echo "Warning: 'ai_summary_as_neorg' not found. Creating basic structure instead."
        # Create a minimal note as fallback
        {
            echo "AI summary tool not available."
            echo "Please see the full content below."
        } > "$ai_summary"
    fi
    
    # Create the final neorg file with proper structure
    local full_content=$(mktemp "${temp_dir}/full_content.XXXXXX")
    
    # Get just a snippet of the content for a preview
    head -n 20 "$input_file" > "${temp_dir}/preview.md"
    
    # Convert the preview to neorg if mton is available
    if command -v mton &> /dev/null; then
        mton < "${temp_dir}/preview.md" > "${temp_dir}/preview.norg" 2>/dev/null || true
    else
        # Fallback to code block
        {
            echo "@code markdown"
            cat "${temp_dir}/preview.md"
            echo "@end"
        } > "${temp_dir}/preview.norg"
    fi
    
    # Create the final document with the structure we want
    {
        # Document title and metadata
        echo "* Web Content: ${filename_base}"
        echo
        echo "Source: Web page"
        if [[ -n "$page_title" ]]; then
            echo "Title: ${page_title}"
        fi
        if [[ -n "$url" ]]; then
            echo "URL: ${url}"
        fi
        echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
        echo
        
        # AI Summary section
        echo "* AI Summary"
        echo 
        cat "$ai_summary"
        echo
        
        # Content Preview
        echo "* Content Preview"
        echo
        echo "This is just a preview. See the full content section for complete text."
        echo
        cat "${temp_dir}/preview.norg"
        echo
        
        # Reference to original markdown
        echo "* Full Content"
        echo
        echo "The complete content is stored as markdown and can be viewed at:"
        echo "@code bash"
        echo "cat \"$input_file\""
        echo "@end"
        
    } > "$output_file"
    
    # Clean up
    rm -rf "$temp_dir"
    
    echo "Web content processing complete."
    return 0
}

# Function to process video files (strip audio, transcribe, and summarize)
process_video_file() {
    local input_file="$1"
    local output_file="$2"
    local filename_base="$3"
    
    echo "Processing video file: $input_file"
    
    # Create temp directory for processing
    local temp_dir=$(mktemp -d /tmp/sbi-video-XXXXXX)
    
    # Strip audio from video
    echo "Extracting audio from video..."
    local audio_file="${temp_dir}/audio.ogg"
    if ! strip_audio "$input_file" "$audio_file"; then
        echo "Error: Audio extraction failed."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Transcribe audio
    echo "Transcribing audio..."
    local transcript_file="${temp_dir}/transcript.txt"
    if ! transcribe_audio "$audio_file" > /dev/null; then
        echo "Error: Transcription failed."
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Check if transcript was generated
    if [[ ! -f "${audio_file}.txt" ]]; then
        echo "Error: Expected transcript file not found at ${audio_file}.txt"
        rm -rf "$temp_dir"
        return 1
    fi
    
    # Move the transcript to our intended location
    mv "${audio_file}.txt" "$transcript_file"
    
    # Generate summary in neorg format
    echo "Generating summary..."
    ai_summary_as_neorg < "$transcript_file" > "$output_file"
    
    # Add source information to the beginning of the file
    local temp_output="${temp_dir}/output.norg"
    
    # Check if the original audio came from a YouTube URL
    # (This would happen if a YouTube URL was processed and the audio file 
    # was passed to process_video_file by mistake instead of process_audio_file)
    local youtube_url=""
    if [[ -f "${audio_file}.yturl" ]]; then
        youtube_url=$(cat "${audio_file}.yturl")
    elif [[ -f "${input_file}.yturl" ]]; then
        youtube_url=$(cat "${input_file}.yturl")
    fi
    
    {
        echo "* Video Summary: ${filename_base}"
        echo
        if [[ -n "$youtube_url" ]]; then
            echo "Source: YouTube video"
            echo "URL: ${youtube_url}"
        else
            echo "Source video: ${input_file}"
        fi
        echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
        echo
        echo "* Summary"
        echo
        cat "$output_file"
    } > "$temp_output"
    
    # Replace output file with our enhanced version
    mv "$temp_output" "$output_file"
    
    # Clean up
    rm -rf "$temp_dir"
    
    echo "Video processing complete."
    return 0
}

# Parse arguments
PARA_TYPE="inbox"
CATEGORY=""
FILES=()
URLS=()          # Array for YouTube URLs to process
WEB_URLS=()      # Array for generic web URLs to process
LIST_FLAG=false
LIST_FILES_FLAG=false
FULL_PATH_FLAG=false
STDIN_MODE=false
TEMP_FILE=""
STDIN_FORMAT=""  # Format for stdin content
EDIT_FLAG=false  # Flag to enable editing
NAME_SEED=""     # Custom filename seed for stdin content

while [[ $# -gt 0 ]]; do
    case "$1" in
        -h|--help)
            show_help
            ;;
        -l|--list)
            # Capture the list flag - we'll process it after parsing all arguments
            LIST_FLAG=true
            shift
            ;;
        -L|--list-files)
            # Capture the list-files flag - we'll process it after parsing all arguments
            LIST_FILES_FLAG=true
            shift
            ;;
        -f|--full-path)
            # Capture the full-path flag
            FULL_PATH_FLAG=true
            shift
            ;;
        --format)
            if [[ -z "$2" || "$2" == -* ]]; then
                echo "Error: --format requires an argument"
                exit 1
            fi
            STDIN_FORMAT="$2"
            shift 2
            ;;
        --name-seed)
            if [[ -z "$2" || "$2" == -* ]]; then
                echo "Error: --name-seed requires an argument"
                exit 1
            fi
            NAME_SEED="$2"
            shift 2
            ;;
        -e|--edit)
            EDIT_FLAG=true
            shift
            ;;
        -p|--para)
            if [[ -z "$2" || "$2" == -* ]]; then
                echo "Error: --para requires an argument"
                exit 1
            fi
            case "$2" in
                inbox|project|area|resource|archive|detect)
                    PARA_TYPE="$2"
                    ;;
                *)
                    echo "Error: Invalid PARA type. Must be one of: inbox, project, area, resource, archive, detect"
                    exit 1
                    ;;
            esac
            shift 2
            ;;
        -c|--category)
            if [[ -z "$2" || "$2" == -* ]]; then
                echo "Error: --category requires an argument"
                exit 1
            fi
            CATEGORY="$2"
            shift 2
            ;;
        *)
            # Check if it's a URL
            if is_url "$1"; then
                # Process URL
                if is_youtube_url "$1"; then
                    # This is a YouTube URL - add to a special URL array for audio processing
                    echo "Detected YouTube URL: $1"
                    URLS+=("$1")
                else
                    # For other URLs, process as web content
                    echo "Detected generic URL: $1"
                    # Store in a different array for web content processing
                    WEB_URLS+=("$1")
                    # Don't fall through to the file check, we know it's a URL
                fi
            elif [[ -f "$1" ]]; then
                # It's a valid file
                FILES+=("$1")
            else
                echo "Error: '$1' is not a valid file or URL!"
                exit 1
            fi
            shift
            ;;
    esac
done

# Process list flags if set
if [[ "$LIST_FLAG" == true || "$LIST_FILES_FLAG" == true ]]; then
    # Determine include_files value based on which flag was used
    include_files="false"
    if [[ "$LIST_FILES_FLAG" == true ]]; then
        include_files="true"
    fi
    
    # Convert PARA_TYPE to format expected by list_structure
    if [[ -n "$PARA_TYPE" && "$PARA_TYPE" != "detect" && "$PARA_TYPE" != "inbox" ]]; then
        # Use specified PARA type
        list_structure "$PARA_TYPE" "$CATEGORY" "$include_files" "$FULL_PATH_FLAG"
    else
        # If para type is not specified, is "detect", or is the default "inbox",
        # show all PARA folders (full listing)
        list_structure "" "" "$include_files" "$FULL_PATH_FLAG"
    fi
fi

# Process YouTube URLs if any
if [[ ${#URLS[@]} -gt 0 ]]; then
    echo "Processing ${#URLS[@]} YouTube URL(s)..."
    
    # Create temp directory for downloads
    YT_TEMP_DIR=$(mktemp -d /tmp/sbi-youtube-XXXXXX)
    
    # Process each URL
    for url in "${URLS[@]}"; do
        # Generate a unique filename for this URL
        url_hash=$(echo "$url" | md5sum | cut -d' ' -f1)
        audio_file="${YT_TEMP_DIR}/${url_hash}"  # Extension will be added by yt-dlp
        
        # Download audio from YouTube
        if download_youtube_audio "$url" "$audio_file"; then
            # Store YouTube URL in a metadata file that will be used during processing
            echo "$url" > "${audio_file}.yturl"
            
            # Mark this as a direct audio file (not needing audio extraction)
            # This will be used later to skip the audio extraction step
            touch "${audio_file}.direct_audio"
            
            # Add audio file to the FILES array for processing
            FILES+=("$audio_file")
            
            # Get and store YouTube title, but don't override custom name-seed
            # Try to get video title using yt-dlp
            title=$(yt-dlp --get-title "$url" 2>/dev/null)
            if [[ -n "$title" ]]; then
                # Always store the title in a metadata file for the specific URL
                echo "$title" > "${audio_file}.title"
                
                # Only set NAME_SEED if it wasn't provided by the user
                if [[ -z "$NAME_SEED" ]]; then
                    echo "Using YouTube video title as filename: $title"
                else
                    echo "Using custom name-seed instead of YouTube title: $NAME_SEED"
                fi
            fi
        else
            echo "Warning: Failed to process YouTube URL: $url"
        fi
    done
fi

# Process generic web URLs if any
if [[ ${#WEB_URLS[@]} -gt 0 ]]; then
    echo "Processing ${#WEB_URLS[@]} web URL(s)..."
    
    # Create temp directory for downloads
    WEB_TEMP_DIR=$(mktemp -d /tmp/sbi-web-XXXXXX)
    
    # Process each URL
    for url in "${WEB_URLS[@]}"; do
        # Generate a unique filename for this URL
        url_hash=$(echo "$url" | md5sum | cut -d' ' -f1)
        md_file="${WEB_TEMP_DIR}/${url_hash}.md"
        
        # Download and convert web page to markdown
        if download_url_as_markdown "$url" "$md_file"; then
            # Add markdown file to the FILES array for processing
            FILES+=("$md_file")
            
            # Mark this as a web content file for special processing
            touch "${md_file}.web_content"
            
            # Get filename from title if available and name seed wasn't provided
            if [[ -z "$NAME_SEED" && -f "${md_file}.title" ]]; then
                # Use page title as filename base
                web_title=$(cat "${md_file}.title")
                if [[ -n "$web_title" ]]; then
                    echo "Using web page title as filename: $web_title"
                fi
            elif [[ -n "$NAME_SEED" ]]; then
                echo "Using custom name-seed for web content: $NAME_SEED"
            fi
        else
            echo "Warning: Failed to process web URL: $url"
        fi
    done
fi

# Check if at least one file is provided or if we have stdin input, only if we're not listing
if [[ ${#FILES[@]} -eq 0 && "$LIST_FLAG" == false && "$LIST_FILES_FLAG" == false ]]; then
    # Check if there's data on stdin (not a terminal)
    if [ -t 0 ]; then
        # No stdin input
        echo "Error: No input files specified and no content provided via stdin"
        show_help
    else
        # We have stdin input; create a temporary file
        TEMP_FILE=$(mktemp /tmp/sbi-stdin-XXXXXX)
        
        # Handle different formats first
        if [[ -n "$STDIN_FORMAT" ]]; then
            # If format is specified, create a code block with that format
            {
                echo "@code $STDIN_FORMAT"
                cat
                echo "@end"
            } > "$TEMP_FILE"
        else
            # Default: assume content is already in neorg format
            cat > "$TEMP_FILE"
        fi
        
        # If edit is requested, let the user edit directly with their editor
        if [[ "$EDIT_FLAG" == true ]]; then
            # Rather than using vipe, use the editor directly on the temp file
            ${EDITOR:-vi} "$TEMP_FILE"
        fi
        
        FILES=("$TEMP_FILE")
        # Flag to indicate this file should be removed after processing
        STDIN_MODE=true
    fi
else
    STDIN_MODE=false
fi

# Process each file
for file in "${FILES[@]}"; do
    if [[ ! -f "$file" ]]; then
        echo "Warning: File does not exist or is not a regular file: $file"
        continue
    fi
    
    # Generate filename - prioritize name-seed for all content types
    if [[ -n "$NAME_SEED" ]]; then
        # Always prioritize user-specified name seed for ALL content types
        echo "Using custom name seed for filename: $NAME_SEED"
        filename="$NAME_SEED"
        filename_no_ext="$filename"
    elif [[ "$STDIN_MODE" == true && "$file" == "$TEMP_FILE" ]]; then
        # For stdin content with no name seed, use just the date as filename
        current_date=$(date +"%Y-%m-%d")
        filename="${current_date}"
        filename_no_ext="$filename"
    # Check if this is a YouTube file (has a title metadata file)
    elif [[ -f "${file}.title" ]]; then
        # Use the YouTube video title as filename
        filename=$(cat "${file}.title")
        filename_no_ext="$filename"
        echo "Using saved YouTube title for filename: $filename"
    else
        # Default case - use original filename
        filename=$(basename "$file")
        filename_no_ext="${filename%.*}"
    fi
    
    # Convert filename to under_score_case
    filename_underscored=$(echo "$filename_no_ext" | tr ' -' '_' | tr '[:upper:]' '[:lower:]')
    
    # Determine PARA category folder
    TARGET_PARA="00_inbox"  # Default value
    if [[ "$PARA_TYPE" == "detect" ]]; then
        detected=$(detect_para_category "$file")
        echo "Detected category: ${detected}"
        case "$detected" in
            *project*)
                TARGET_PARA="01_projects"
                ;;
            *area*)
                TARGET_PARA="02_areas"
                ;;
            *resource*)
                TARGET_PARA="03_resources"
                ;;
            *archive*)
                TARGET_PARA="04_archives"
                ;;
            *)
                TARGET_PARA="00_inbox"
                ;;
        esac
        echo "Using folder: ${TARGET_PARA}"
    else
        case "$PARA_TYPE" in
            inbox)
                TARGET_PARA="00_inbox"
                ;;
            project)
                TARGET_PARA="01_projects"
                ;;
            area)
                TARGET_PARA="02_areas"
                ;;
            resource)
                TARGET_PARA="03_resources"
                ;;
            archive)
                TARGET_PARA="04_archives"
                ;;
        esac
    fi
    
    # Build target directory path
    if [[ -n "$CATEGORY" ]]; then
        TARGET_DIR="${NOTES_DIR}/${TARGET_PARA}/${CATEGORY}"
    else
        TARGET_DIR="${NOTES_DIR}/${TARGET_PARA}"
    fi
    
    # Create target directory if it doesn't exist
    mkdir -p "$TARGET_DIR"
    
    # Process file based on type
    TARGET_FILE="${TARGET_DIR}/${filename_underscored}.norg"
    
    # Check if the target file already exists
    if [[ -f "$TARGET_FILE" ]]; then
        # File exists - append to it
        if is_neorg_file "$file"; then
            if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                # Only for non-stdin files
                # Create temp file with content to append
                EDIT_TEMP=$(mktemp /tmp/sbi-edit-XXXXXX)
                echo -e "* Appended on $(date +"%Y-%m-%d %H:%M:%S")\n" > "$EDIT_TEMP"
                cat "$file" >> "$EDIT_TEMP"
                
                # Edit the content directly with the editor
                ${EDITOR:-vi} "$EDIT_TEMP"
                
                # Append the edited content
                echo -e "\n" >> "$TARGET_FILE"
                cat "$EDIT_TEMP" >> "$TARGET_FILE"
                
                # Clean up
                rm -f "$EDIT_TEMP"
                echo "Edited and appended to: $TARGET_FILE"
            else
                # If source is already a neorg file, append its content with a separator
                echo -e "\n* Appended on $(date +"%Y-%m-%d %H:%M:%S")\n" >> "$TARGET_FILE"
                cat "$file" >> "$TARGET_FILE"
                echo "Appended Neorg file to: $TARGET_FILE"
            fi
        else
            if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                # Only for non-stdin files
                # Convert to neorg first
                CONVERT_TEMP=$(mktemp /tmp/sbi-convert-XXXXXX)
                convert_to_neorg "$file" "$CONVERT_TEMP"
                
                # Add header to content
                EDIT_TEMP=$(mktemp /tmp/sbi-edit-XXXXXX)
                echo -e "* Appended on $(date +"%Y-%m-%d %H:%M:%S")\n" > "$EDIT_TEMP"
                cat "$CONVERT_TEMP" >> "$EDIT_TEMP"
                
                # Edit directly with editor
                ${EDITOR:-vi} "$EDIT_TEMP"
                
                # Append the edited content
                echo -e "\n" >> "$TARGET_FILE"
                cat "$EDIT_TEMP" >> "$TARGET_FILE"
                
                # Clean up
                rm -f "$CONVERT_TEMP" "$EDIT_TEMP"
                echo "Edited, converted and appended to: $TARGET_FILE"
            else
                # Convert to neorg and append with a separator
                echo -e "\n* Appended on $(date +"%Y-%m-%d %H:%M:%S")\n" >> "$TARGET_FILE"
                
                # For non-neorg files, create a temporary file for conversion
                APPEND_TEMP=$(mktemp /tmp/sbi-append-XXXXXX)
                convert_to_neorg "$file" "$APPEND_TEMP"
                cat "$APPEND_TEMP" >> "$TARGET_FILE"
                rm -f "$APPEND_TEMP"
                
                echo "Converted and appended to: $TARGET_FILE"
            fi
        fi
    else
        # New file
        if is_neorg_file "$file"; then
            if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                # Only edit non-stdin files here (stdin is already edited if needed)
                # Use the editor directly on a temp copy
                EDIT_TEMP=$(mktemp /tmp/sbi-edit-XXXXXX)
                cp "$file" "$EDIT_TEMP"
                ${EDITOR:-vi} "$EDIT_TEMP"
                cp "$EDIT_TEMP" "$TARGET_FILE"
                rm -f "$EDIT_TEMP"
                echo "Edited and copied Neorg file to: $TARGET_FILE"
            else
                # Just copy
                cp "$file" "$TARGET_FILE"
                echo "Copied Neorg file to: $TARGET_FILE"
            fi
        elif [[ -f "${file}.web_content" ]]; then
            # Process web content
            echo "Detected web content. Processing..."
            TEMP_NEORG=$(mktemp /tmp/sbi-web-neorg-XXXXXX)
            
            if process_web_content "$file" "$TEMP_NEORG" "$filename_no_ext"; then
                # If processing succeeded, copy to target
                cp "$TEMP_NEORG" "$TARGET_FILE"
                echo "Web content processed and ingested to: $TARGET_FILE"
                
                # Edit if requested
                if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                    ${EDITOR:-vi} "$TARGET_FILE"
                    echo "Edited web content in: $TARGET_FILE"
                fi
            else
                # If processing failed, fall back to normal conversion
                echo "Web content processing failed, falling back to standard conversion."
                convert_to_neorg "$file" "$TARGET_FILE"
                echo "Converted and ingested to: $TARGET_FILE"
            fi
            
            # Clean up
            rm -f "$TEMP_NEORG"
            
        elif is_audio_file "$file"; then
            # Process audio file - transcribe and summarize
            echo "Detected audio file. Processing..."
            TEMP_NEORG=$(mktemp /tmp/sbi-audio-neorg-XXXXXX)
            
            if process_audio_file "$file" "$TEMP_NEORG" "$filename_no_ext"; then
                # If processing succeeded, copy to target
                cp "$TEMP_NEORG" "$TARGET_FILE"
                echo "Audio processed and ingested to: $TARGET_FILE"
                
                # Edit if requested
                if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                    ${EDITOR:-vi} "$TARGET_FILE"
                    echo "Edited audio summary in: $TARGET_FILE"
                fi
            else
                # If processing failed, fall back to normal conversion
                echo "Audio processing failed, falling back to standard conversion."
                convert_to_neorg "$file" "$TARGET_FILE"
                echo "Converted and ingested to: $TARGET_FILE"
            fi
            
            # Clean up
            rm -f "$TEMP_NEORG"
            
        elif is_ebook_file "$file" || is_pdf_file "$file" || is_office_file "$file"; then
            # Process ebook or PDF document
            echo "Detected document file ($(basename "$file")). Processing..."
            TEMP_NEORG=$(mktemp /tmp/sbi-document-neorg-XXXXXX)
            
            if process_document_content "$file" "$TEMP_NEORG" "$filename_no_ext"; then
                # If processing succeeded, copy to target
                cp "$TEMP_NEORG" "$TARGET_FILE"
                echo "Document processed and ingested to: $TARGET_FILE"
                
                # Edit if requested
                if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                    ${EDITOR:-vi} "$TARGET_FILE"
                    echo "Edited document summary in: $TARGET_FILE"
                fi
            else
                # If processing failed, fall back to normal conversion
                echo "Document processing failed, falling back to standard conversion."
                convert_to_neorg "$file" "$TARGET_FILE"
                echo "Converted and ingested to: $TARGET_FILE"
            fi
            
            # Clean up
            rm -f "$TEMP_NEORG"
            
        elif is_video_file "$file" || [[ -f "${file}.direct_audio" ]]; then
            # Process video file or direct audio from YouTube
            if [[ -f "${file}.direct_audio" ]]; then
                echo "Detected direct audio from YouTube. Processing..."
                # For direct audio from YouTube, we skip the audio extraction step
                TEMP_NEORG=$(mktemp /tmp/sbi-audio-neorg-XXXXXX)
                
                echo "Processing YouTube audio: $file"
                
                # Create temp files for processing
                TRANSCRIPT_FILE=$(mktemp /tmp/sbi-transcript-XXXXXX)
                SUMMARY_FILE=$(mktemp /tmp/sbi-summary-XXXXXX)
                
                # Check if the audio file exists and has non-zero size
                if [[ ! -f "$file" || ! -s "$file" ]]; then
                    echo "Error: Audio file is missing or empty: $file"
                    echo "Creating a placeholder note instead."
                    {
                        echo "* YouTube Download Failure: ${filename_no_ext}"
                        echo
                        echo "Source: YouTube video"
                        if [[ -f "${file}.yturl" ]]; then
                            echo "URL: $(cat "${file}.yturl")"
                        fi
                        echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
                        echo
                        echo "* Note"
                        echo
                        echo "There was an error downloading or processing this YouTube video."
                        echo "Please try again or manually download the content."
                    } > "$TEMP_NEORG"
                    cp "$TEMP_NEORG" "$TARGET_FILE"
                    echo "Created placeholder note at: $TARGET_FILE"
                    continue
                fi
                
                echo "Audio file exists and has content. File size: $(du -h "$file" | cut -f1)"
                echo "File type: $(file -b "$file")"
                
                # Try to transcribe the audio directly
                echo "Running transcribe_audio on: $file"
                transcribe_audio "$file" || true  # Continue even if transcription fails
                
                echo "Checking for transcript file: ${file}.txt"
                if [[ -f "${file}.txt" ]]; then
                    echo "Transcript file found, moving to: $TRANSCRIPT_FILE"
                    # Transcription succeeded, move transcript to our temp file
                    cp "${file}.txt" "$TRANSCRIPT_FILE"
                    
                    # Check if transcript has content
                    if [[ -s "$TRANSCRIPT_FILE" ]]; then
                        echo "Transcript has content. Generating summary..."
                        # Generate the summary
                        ai_summary_as_neorg < "$TRANSCRIPT_FILE" > "$SUMMARY_FILE"
                        
                        # Check if summary was generated successfully
                        if [[ -s "$SUMMARY_FILE" ]]; then
                            echo "Summary generated successfully."
                            
                            # Create the final file with proper headers
                            {
                                echo "* YouTube Summary: ${filename_no_ext}"
                                echo
                                echo "Source: YouTube video"
                                # Add YouTube URL if available
                                if [[ -f "${file}.yturl" ]]; then
                                    echo "URL: $(cat "${file}.yturl")"
                                fi
                                echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
                                echo
                                echo "* Summary"
                                echo
                                cat "$SUMMARY_FILE"
                            } > "$TEMP_NEORG"
                            
                            # Handle existing target file (append or create new)
                            if [[ -f "$TARGET_FILE" ]]; then
                                # If target exists, append with a separator
                                echo -e "\n* Appended on $(date +"%Y-%m-%d %H:%M:%S")\n" >> "$TARGET_FILE"
                                cat "$TEMP_NEORG" >> "$TARGET_FILE"
                                echo "YouTube summary appended to existing file: $TARGET_FILE"
                            else
                                # New file
                                cp "$TEMP_NEORG" "$TARGET_FILE"
                                echo "YouTube audio processed and saved to: $TARGET_FILE"
                            fi
                        else
                            echo "Summary generation failed. Creating placeholder with transcript."
                            # Create a simple note with the transcript
                            {
                                echo "* YouTube Transcript: ${filename_no_ext}"
                                echo
                                echo "Source: YouTube video"
                                # Add YouTube URL if available
                                if [[ -f "${file}.yturl" ]]; then
                                    echo "URL: $(cat "${file}.yturl")"
                                fi
                                echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
                                echo
                                echo "* Transcript"
                                echo
                                cat "$TRANSCRIPT_FILE"
                            } > "$TEMP_NEORG"
                            
                            # Save it
                            cp "$TEMP_NEORG" "$TARGET_FILE"
                            echo "Transcript saved to: $TARGET_FILE"
                        fi
                    else
                        echo "Transcript file is empty. Creating placeholder note."
                        # Create a simple note indicating failure
                        {
                            echo "* YouTube Processing Issue: ${filename_no_ext}"
                            echo
                            echo "Source: YouTube video"
                            # Add YouTube URL if available
                            if [[ -f "${file}.yturl" ]]; then
                                echo "URL: $(cat "${file}.yturl")"
                            fi
                            echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
                            echo
                            echo "* Note"
                            echo
                            echo "The audio was downloaded, but transcription failed to produce content."
                            echo "The downloaded audio file is located at: $file"
                        } > "$TEMP_NEORG"
                        
                        # Save it
                        cp "$TEMP_NEORG" "$TARGET_FILE"
                        echo "Created placeholder note at: $TARGET_FILE"
                    fi
                    
                    # Clean up
                    rm -f "$TRANSCRIPT_FILE" "$SUMMARY_FILE"
                else
                    # No transcript file found
                    echo "No transcript file found. Creating placeholder note."
                    {
                        echo "* YouTube Processing Issue: ${filename_no_ext}"
                        echo
                        echo "Source: YouTube video"
                        # Add YouTube URL if available
                        if [[ -f "${file}.yturl" ]]; then
                            echo "URL: $(cat "${file}.yturl")"
                        fi
                        echo "Processed on: $(date +"%Y-%m-%d %H:%M:%S")"
                        echo
                        echo "* Note"
                        echo
                        echo "The audio was downloaded successfully, but the transcription process failed."
                        echo "The downloaded audio file is located at: $file"
                        echo 
                        echo "You can try to manually transcribe this file by running:"
                        echo "@code bash"
                        echo "transcribe_audio \"$file\""
                        echo "@end"
                    } > "$TEMP_NEORG"
                    
                    # Save it
                    cp "$TEMP_NEORG" "$TARGET_FILE"
                    echo "Created placeholder note at: $TARGET_FILE"
                fi
                
                # Edit if requested
                if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                    ${EDITOR:-vi} "$TARGET_FILE"
                    echo "Edited YouTube audio summary in: $TARGET_FILE"
                fi
                
                # Clean up
                rm -f "$TEMP_NEORG"
            else
                # Regular video file - strip audio, transcribe, and summarize
                echo "Detected video file. Processing..."
                TEMP_NEORG=$(mktemp /tmp/sbi-video-neorg-XXXXXX)
                
                if process_video_file "$file" "$TEMP_NEORG" "$filename_no_ext"; then
                    # If processing succeeded, copy to target
                    cp "$TEMP_NEORG" "$TARGET_FILE"
                    echo "Video processed and ingested to: $TARGET_FILE"
                    
                    # Edit if requested
                    if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                        ${EDITOR:-vi} "$TARGET_FILE"
                        echo "Edited video summary in: $TARGET_FILE"
                    fi
                else
                    # If processing failed, fall back to normal conversion
                    echo "Video processing failed, falling back to standard conversion."
                    convert_to_neorg "$file" "$TARGET_FILE"
                    echo "Converted and ingested to: $TARGET_FILE"
                fi
                
                # Clean up
                rm -f "$TEMP_NEORG"
            fi
            
        else
            # Standard conversion for other file types
            convert_to_neorg "$file" "$TARGET_FILE"
            
            # Edit non-stdin files after conversion if requested
            if [[ "$EDIT_FLAG" == true && "$STDIN_MODE" == false ]]; then
                ${EDITOR:-vi} "$TARGET_FILE"
                echo "Converted, edited and ingested to: $TARGET_FILE"
            else
                echo "Converted and ingested to: $TARGET_FILE"
            fi
        fi
    fi
done

# Clean up temporary file if we used stdin mode
if [[ "$STDIN_MODE" == true && -n "$TEMP_FILE" && -f "$TEMP_FILE" ]]; then
    rm -f "$TEMP_FILE"
fi

# Clean up YouTube temporary directory if it exists
if [[ -n "${YT_TEMP_DIR:-}" && -d "${YT_TEMP_DIR}" ]]; then
    # Remove all files, including any metadata files (*.yturl)
    rm -rf "${YT_TEMP_DIR}"
fi

# Clean up web content temporary directory if it exists
if [[ -n "${WEB_TEMP_DIR:-}" && -d "${WEB_TEMP_DIR}" ]]; then
    # Remove all files, including any metadata files (*.url, *.title)
    rm -rf "${WEB_TEMP_DIR}"
fi
