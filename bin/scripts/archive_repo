#!/usr/bin/python3

# dotfiles - Personal configuration files and scripts
# Copyright (C) 2025  Zach Podbielniak
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

import argparse
import json
import os
import re
import subprocess
import sys
import time
from urllib.parse import urlparse
import traceback
import select
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# Gitea server configuration - CHANGE THIS TO YOUR GITEA INSTANCE
GITEA_SERVER_URL = 'https://gitea.podbielniak.com'

# Gitea API base URL (constructed from server URL)
GITEA_API_BASE = f'{GITEA_SERVER_URL}/api/v1'

# Personal account URLs - Add your personal git accounts here
PERSONAL_ACCOUNTS = [
    'https://gitlab.com/zachpodbielniak',
    'https://github.com/zachpodbielniak'
]

# Thread-safe printing
print_lock = threading.Lock()

# Service type mappings
SERVICE_TYPES = {
    'github': 'github',
    'gitlab': 'gitlab',
    'gitea': 'gitea',
    'forgejo': 'forgejo',
    'gogs': 'gogs',
    'onedev': 'onedev',
    'gitbucket': 'gitbucket',
    'codebase': 'codebase',
    'git': 'git'
}

def debug_log(message, debug=False):
    """Print debug messages if debug mode is enabled."""
    if debug:
        with print_lock:
            print(f"[DEBUG] {message}", file=sys.stderr)

def dry_run_log(message):
    """Print dry-run messages."""
    with print_lock:
        print(f"[DRY-RUN] {message}")

def safe_print(message, file=None):
    """Thread-safe print function."""
    with print_lock:
        if file:
            print(message, file=file)
        else:
            print(message)

def run_curl(url, method='GET', data=None, token=None, debug=False, dry_run=False):
    """Run curl command and return response."""
    cmd = ['curl', '-s']
    
    if debug:
        cmd.extend(['-v'])
    
    cmd.extend(['-X', method])
    
    if token:
        cmd.extend(['-H', f'Authorization: token {token}'])
    
    if data:
        cmd.extend(['-H', 'Content-Type: application/json'])
        cmd.extend(['-d', json.dumps(data)])
    
    cmd.append(url)
    
    # Create debug command with masked token
    debug_cmd = cmd.copy()
    for i, arg in enumerate(debug_cmd):
        if i > 0 and debug_cmd[i-1] == '-H' and 'Authorization: token' in arg:
            # Mask the token in the authorization header
            token_match = re.search(r'token (.+)', arg)
            if token_match:
                token_val = token_match.group(1)
                masked_token = f"{token_val[:4]}...{token_val[-4:]}" if len(token_val) > 8 else "***"
                debug_cmd[i] = f'Authorization: token {masked_token}'
    
    if dry_run or debug:
        print(f"[DRY-RUN] Would run: {' '.join(debug_cmd)}")
    
    if dry_run:
        return '{"dry_run": true}'  # Return dummy JSON for dry run
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            debug_log(f"Curl failed with code {result.returncode}: {result.stderr}", debug)
            return None
        
        if result.stdout:
            try:
                return json.loads(result.stdout)
            except json.JSONDecodeError:
                debug_log(f"Failed to parse JSON response: {result.stdout}", debug)
                return None
        return {}
    except Exception as e:
        debug_log(f"Error running curl: {e}", debug)
        return None

def detect_service(url, debug=False):
    """Detect the git service from URL."""
    parsed = urlparse(url)
    hostname = parsed.hostname or parsed.path
    
    debug_log(f"Detecting service for hostname: {hostname}", debug)
    
    if 'github.com' in hostname:
        return 'github'
    elif 'gitlab.com' in hostname:
        return 'gitlab'
    elif 'gitea' in hostname:
        return 'gitea'
    elif 'gogs' in hostname:
        return 'gogs'
    elif 'bitbucket' in hostname:
        return 'gitbucket'
    elif 'codeberg.org' in hostname:
        return 'forgejo'
    else:
        # For unknown git servers, use generic 'git' service type
        debug_log(f"Unknown hostname '{hostname}', using generic 'git' service", debug)
        return 'git'

def is_org_or_user_url(url, debug=False):
    """Check if URL points to an org/user rather than a specific repo."""
    # Remove trailing slash
    url = url.rstrip('/')
    
    # Count path segments after domain
    parsed = urlparse(url)
    path = parsed.path.strip('/')
    
    if not path:
        return False
    
    segments = path.split('/')
    
    # Org/user URLs typically have 1 segment, repo URLs have 2+
    is_org = len(segments) == 1
    debug_log(f"URL segments: {segments}, is_org/user: {is_org}", debug)
    return is_org

def list_github_repos(owner, debug=False):
    """List all repositories for a GitHub user/org."""
    repos = []
    page = 1
    per_page = 100
    
    while True:
        # Try user endpoint first
        url = f"https://api.github.com/users/{owner}/repos?per_page={per_page}&page={page}"
        debug_log(f"Fetching GitHub repos from: {url}", debug)
        
        response = run_curl(url, debug=debug)
        
        if response is None:
            # Try org endpoint
            url = f"https://api.github.com/orgs/{owner}/repos?per_page={per_page}&page={page}"
            debug_log(f"Trying org endpoint: {url}", debug)
            response = run_curl(url, debug=debug)
        
        if response is None or not isinstance(response, list):
            break
        
        if len(response) == 0:
            break
        
        for repo in response:
            if isinstance(repo, dict) and 'clone_url' in repo:
                repos.append(repo['clone_url'])
                debug_log(f"Found repo: {repo['clone_url']}", debug)
        
        if len(response) < per_page:
            break
        
        page += 1
    
    return repos

def list_gitlab_repos(owner, debug=False):
    """List all repositories for a GitLab user/group."""
    repos = []
    page = 1
    per_page = 100
    
    # Try user projects
    url = f"https://gitlab.com/api/v4/users/{owner}/projects?per_page={per_page}&page={page}"
    debug_log(f"Fetching GitLab repos from: {url}", debug)
    
    response = run_curl(url, debug=debug)
    
    if response and isinstance(response, list):
        for repo in response:
            if isinstance(repo, dict) and 'http_url_to_repo' in repo:
                repos.append(repo['http_url_to_repo'])
                debug_log(f"Found repo: {repo['http_url_to_repo']}", debug)
    else:
        # Try group projects
        url = f"https://gitlab.com/api/v4/groups/{owner}/projects?per_page={per_page}&page={page}"
        debug_log(f"Trying group endpoint: {url}", debug)
        response = run_curl(url, debug=debug)
        
        if response and isinstance(response, list):
            for repo in response:
                if isinstance(repo, dict) and 'http_url_to_repo' in repo:
                    repos.append(repo['http_url_to_repo'])
                    debug_log(f"Found repo: {repo['http_url_to_repo']}", debug)
    
    return repos

def list_gitea_repos(base_url, owner, debug=False):
    """List all repositories for a Gitea/Forgejo/Gogs user/org."""
    repos = []
    page = 1
    per_page = 50
    
    while True:
        # Try user repos first
        url = f"{base_url}/api/v1/users/{owner}/repos?page={page}&limit={per_page}"
        debug_log(f"Fetching Gitea repos from: {url}", debug)
        
        response = run_curl(url, debug=debug)
        
        if response is None or not isinstance(response, list):
            # Try org repos
            url = f"{base_url}/api/v1/orgs/{owner}/repos?page={page}&limit={per_page}"
            debug_log(f"Trying org endpoint: {url}", debug)
            response = run_curl(url, debug=debug)
        
        if response is None or not isinstance(response, list):
            break
        
        if len(response) == 0:
            break
        
        for repo in response:
            if isinstance(repo, dict) and 'clone_url' in repo:
                repos.append(repo['clone_url'])
                debug_log(f"Found repo: {repo['clone_url']}", debug)
        
        if len(response) < per_page:
            break
        
        page += 1
    
    return repos

def list_codeberg_repos(owner, debug=False):
    """List all repositories for a Codeberg (Forgejo) user/org."""
    # Codeberg uses Forgejo, which has the same API as Gitea
    return list_gitea_repos("https://codeberg.org", owner, debug)

def get_base_url_from_repo_url(url, debug=False):
    """Extract base URL from a repository URL."""
    parsed = urlparse(url)
    base_url = f"{parsed.scheme}://{parsed.netloc}"
    debug_log(f"Extracted base URL: {base_url} from {url}", debug)
    return base_url

def construct_org_url(repo_url, org_name, service, debug=False):
    """Construct the organization URL from a repository URL."""
    parsed = urlparse(repo_url)
    base_url = f"{parsed.scheme}://{parsed.netloc}"
    
    # For known services, construct the proper org URL
    if 'github.com' in parsed.netloc:
        org_url = f"https://github.com/{org_name}"
    elif 'gitlab.com' in parsed.netloc:
        org_url = f"https://gitlab.com/{org_name}"
    elif 'codeberg.org' in parsed.netloc:
        org_url = f"https://codeberg.org/{org_name}"
    else:
        # For other services, construct a generic URL
        org_url = f"{base_url}/{org_name}"
    
    debug_log(f"Constructed org URL: {org_url} for {org_name}", debug)
    return org_url

def list_repos_for_service(service_url, service, owner, debug=False):
    """List all repositories for a given service and owner."""
    debug_log(f"Listing repos for {service}:{owner}", debug)
    
    if service == 'github':
        return list_github_repos(owner, debug)
    elif service == 'gitlab':
        return list_gitlab_repos(owner, debug)
    elif service in ['gitea', 'forgejo', 'gogs']:
        # These all use similar APIs
        base_url = get_base_url_from_repo_url(service_url, debug)
        return list_gitea_repos(base_url, owner, debug)
    elif service == 'forgejo' and 'codeberg.org' in service_url:
        # Special case for Codeberg
        return list_codeberg_repos(owner, debug)
    else:
        debug_log(f"Repository listing not implemented for service: {service}", debug)
        return []

def is_user_not_org(service, owner, debug=False):
    """Check if the owner is a user (not an organization) on the given service."""
    if service == 'github':
        # Check GitHub API to determine if it's a user or org
        url = f"https://api.github.com/users/{owner}"
        response = run_curl(url, debug=debug)
        if response and 'type' in response:
            is_user = response['type'] == 'User'
            debug_log(f"GitHub {owner} type: {response['type']}, is_user: {is_user}", debug)
            return is_user
    elif service == 'gitlab':
        # For GitLab, check if it's a user by trying the user endpoint
        url = f"https://gitlab.com/api/v4/users?username={owner}"
        response = run_curl(url, debug=debug)
        if response and isinstance(response, list) and len(response) > 0:
            debug_log(f"GitLab {owner} found as user", debug)
            return True
    
    # Default to treating as org if we can't determine
    debug_log(f"Could not determine if {owner} is user or org, defaulting to org", debug)
    return False

def parse_repo_info(url, debug=False):
    """Extract repo owner and name from URL."""
    # Remove .git suffix if present (as a complete suffix, not individual chars)
    if url.endswith('.git'):
        url = url[:-4]
    
    # Handle various URL formats
    patterns = [
        r'(?:https?://|git@)(?:[^/:]+(?::\d+)?)[:/]([^/]+)/([^/]+)/?$',
        r'(?:ssh://)?git@([^:]+):([^/]+)/([^/]+)$',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            if len(match.groups()) == 3:
                # SSH format with host
                owner = match.group(2)
                repo = match.group(3)
            else:
                # HTTPS format
                owner = match.group(1)
                repo = match.group(2)
            
            debug_log(f"Parsed repo info - owner: {owner}, repo: {repo}", debug)
            return owner, repo
    
    debug_log(f"Failed to parse repo info from URL: {url}", debug)
    return None, None

def parse_repo_from_delete_arg(repo_arg, debug=False):
    """Parse repository info from --delete-repo argument (URL or org/repo format)."""
    # Check if it's an org/repo format
    if '/' in repo_arg and not repo_arg.startswith('http') and not repo_arg.startswith('git@'):
        parts = repo_arg.split('/', 1)
        if len(parts) == 2:
            owner, repo = parts
            debug_log(f"Parsed org/repo format - owner: {owner}, repo: {repo}", debug)
            return owner, repo
    
    # Try to parse as URL
    return parse_repo_info(repo_arg, debug)

def get_current_user(token, debug=False):
    """Get the current authenticated user from Gitea."""
    url = f"{GITEA_API_BASE}/user"
    debug_log(f"Fetching current user from: {url}", debug)
    
    response = run_curl(url, token=token, debug=debug)
    if response and 'username' in response:
        debug_log(f"Current user: {response['username']}", debug)
        return response['username']
    
    return None

def get_organizations(token, debug=False):
    """Get list of organizations from Gitea."""
    url = f"{GITEA_API_BASE}/user/orgs"
    debug_log(f"Fetching organizations from: {url}", debug)
    
    response = run_curl(url, token=token, debug=debug)
    if response is None:
        return []
    
    if isinstance(response, list):
        org_names = [org.get('username', '') for org in response]
        debug_log(f"Found organizations: {org_names}", debug)
        return org_names
    
    return []

def check_user_exists(username, token, debug=False):
    """Check if a user exists in Gitea."""
    url = f"{GITEA_API_BASE}/users/{username}"
    debug_log(f"Checking if user exists: {username}", debug)
    
    response = run_curl(url, token=token, debug=debug)
    if response and 'id' in response:
        debug_log(f"User '{username}' exists in Gitea", debug)
        return True
    
    return False

def owner_exists_in_gitea(owner_name, token, debug=False):
    """Check if owner exists as either user or organization in Gitea."""
    # First check if it's an organization
    orgs = get_organizations(token, debug)
    if owner_name in orgs:
        debug_log(f"'{owner_name}' exists as an organization", debug)
        return True, 'org'
    
    # Then check if it's a user
    if check_user_exists(owner_name, token, debug):
        debug_log(f"'{owner_name}' exists as a user", debug)
        return True, 'user'
    
    debug_log(f"'{owner_name}' does not exist in Gitea", debug)
    return False, None

def create_organization(org_name, token, website=None, debug=False, dry_run=False):
    """Create a new organization in Gitea."""
    url = f"{GITEA_API_BASE}/orgs"
    data = {
        'username': org_name,
        'full_name': org_name,
        'description': f'Archived repositories from {org_name}',
        'visibility': 'public'
    }
    
    # Add website if provided
    if website:
        data['website'] = website
        debug_log(f"Setting organization website to: {website}", debug)
    
    if dry_run:
        dry_run_log(f"Would create organization: {org_name}")
        if website:
            dry_run_log(f"Would set organization website to: {website}")
        return True
    
    debug_log(f"Creating organization: {org_name}", debug)
    response = run_curl(url, method='POST', data=data, token=token, debug=debug, dry_run=dry_run)
    
    if response and 'id' in response:
        debug_log(f"Successfully created organization: {org_name}", debug)
        return True
    
    debug_log(f"Failed to create organization: {response}", debug)
    return False

def check_repository_exists(repo_owner, repo_name, token, debug=False, dry_run=False):
    """Check if a repository already exists in Gitea."""
    url = f"{GITEA_API_BASE}/repos/{repo_owner}/{repo_name}"
    debug_log(f"Checking if repository exists: {repo_owner}/{repo_name}", debug)
    
    if dry_run:
        dry_run_log(f"Would check if repository exists: {repo_owner}/{repo_name}")
        return True  # Assume exists for dry run
    
    response = run_curl(url, token=token, debug=debug, dry_run=dry_run)
    
    if response and 'id' in response:
        debug_log(f"Repository already exists: {repo_owner}/{repo_name}", debug)
        return True
    
    return False

def migrate_repository_worker(args_tuple):
    """Worker function for parallel repository migration."""
    repo_url, service, repo_owner, repo_name, token, debug, delay, dry_run = args_tuple
    
    try:
        # Check if owner exists, create if needed
        exists, owner_type = owner_exists_in_gitea(repo_owner, token, debug)
        if not exists:
            # Owner doesn't exist, create as organization
            org_website = construct_org_url(repo_url, repo_owner, service, debug)
            debug_log(f"Creating organization: {repo_owner} with website: {org_website}", debug)
            if not create_organization(repo_owner, token, website=org_website, debug=debug, dry_run=dry_run):
                debug_log(f"Failed to create organization: {repo_owner}", debug)
                return False, repo_url, f"Failed to create organization: {repo_owner}"
        
        # Migrate the repository
        success = migrate_repository(repo_url, service, repo_owner, repo_name, token, debug, delay, dry_run)
        
        if success:
            safe_print(f"✓ Migrated: {repo_owner}/{repo_name}", file=sys.stderr)
            return True, repo_url, None
        else:
            return False, repo_url, f"Migration failed for {repo_owner}/{repo_name}"
    
    except Exception as e:
        error_msg = f"Exception migrating {repo_owner}/{repo_name}: {str(e)}"
        debug_log(error_msg, debug)
        return False, repo_url, error_msg

def migrate_repository(repo_url, service, repo_owner, repo_name, token, debug=False, delay=0, dry_run=False):
    """Migrate a repository to Gitea."""
    # First check if repository already exists
    if check_repository_exists(repo_owner, repo_name, token, debug):
        debug_log(f"Repository {repo_owner}/{repo_name} already exists, skipping migration", debug)
        return True  # Success - already exists
    
    url = f"{GITEA_API_BASE}/repos/migrate"
    
    data = {
        'clone_addr': repo_url,
        'repo_name': repo_name,
        'repo_owner': repo_owner,
        'service': service,
        'mirror': True,
        'private': False,
        'issues': True,
        'labels': True,
        'milestones': True,
        'pull_requests': True,
        'releases': True,
        'wiki': True
    }
    
    # Add authentication token for GitHub or GitLab if available
    if service == 'github':
        github_token = os.environ.get('GITHUB_TOKEN')
        if github_token:
            data['auth_token'] = github_token
            debug_log("Using GITHUB_TOKEN for authentication", debug)
    elif service == 'gitlab':
        gitlab_token = os.environ.get('GITLAB_TOKEN')
        if gitlab_token:
            data['auth_token'] = gitlab_token
            debug_log("Using GITLAB_TOKEN for authentication", debug)
    
    if dry_run:
        dry_run_log(f"Would migrate repository: {repo_url} -> {repo_owner}/{repo_name}")
        dry_run_log(f"Would create mirror with service type: {service}")
        if 'auth_token' in data:
            dry_run_log("Would use authentication token for private repository access")
        if delay > 0:
            dry_run_log(f"Would delay {delay} seconds after migration")
        return True
    
    debug_log(f"Migrating repository: {repo_url} -> {repo_owner}/{repo_name}", debug)
    # Don't log auth_token in debug output
    debug_data = data.copy()
    if 'auth_token' in debug_data:
        debug_data['auth_token'] = '***REDACTED***'
    debug_log(f"Migration data: {json.dumps(debug_data, indent=2)}", debug)
    
    response = run_curl(url, method='POST', data=data, token=token, debug=debug, dry_run=dry_run)
    
    if response and 'id' in response:
        debug_log(f"Successfully migrated repository: {response.get('full_name')}", debug)
        
        # Apply delay if specified
        if delay > 0:
            debug_log(f"Waiting {delay} seconds before next operation...", debug)
            time.sleep(delay)
        
        return True
    
    if response and 'message' in response:
        error_msg = response['message']
        debug_log(f"Migration failed: {error_msg}", debug)
        
        # Check if it's a duplicate error (shouldn't happen now but keep as fallback)
        if 'already exists' in error_msg.lower():
            debug_log("Repository already exists in Gitea (caught in error)", debug)
            return True  # Consider it a success if already archived
    
    debug_log(f"Migration failed with response: {response}", debug)
    return False

def list_org_repositories(org_name, token, debug=False):
    """List all repositories in a Gitea organization."""
    repos = []
    page = 1
    per_page = 50
    
    while True:
        url = f"{GITEA_API_BASE}/orgs/{org_name}/repos?page={page}&limit={per_page}"
        debug_log(f"Fetching org repos from: {url}", debug)
        
        response = run_curl(url, token=token, debug=debug)
        
        if response is None or not isinstance(response, list):
            break
        
        if len(response) == 0:
            break
        
        for repo in response:
            if isinstance(repo, dict) and 'name' in repo:
                repos.append(repo)
                debug_log(f"Found repo: {repo['name']}", debug)
        
        if len(response) < per_page:
            break
        
        page += 1
    
    return repos

def delete_repository(owner, repo_name, token, debug=False, dry_run=False):
    """Delete a repository from Gitea."""
    url = f"{GITEA_API_BASE}/repos/{owner}/{repo_name}"
    debug_log(f"Deleting repository: {owner}/{repo_name}", debug)
    
    if dry_run:
        dry_run_log(f"Would delete repository: {owner}/{repo_name}")
        return True
    
    response = run_curl(url, method='DELETE', token=token, debug=debug, dry_run=dry_run)
    
    # A successful deletion returns 204 No Content (empty response)
    if response is None or response == {}:
        debug_log(f"Successfully deleted repository: {owner}/{repo_name}", debug)
        return True
    
    if response and 'message' in response:
        debug_log(f"Failed to delete repository: {response['message']}", debug)
        return False
    
    debug_log(f"Delete repository response: {response}", debug)
    return False

def delete_organization(org_name, token, debug=False):
    """Delete an organization from Gitea."""
    url = f"{GITEA_API_BASE}/orgs/{org_name}"
    debug_log(f"Deleting organization: {org_name}", debug)
    
    response = run_curl(url, method='DELETE', token=token, debug=debug)
    
    # A successful deletion returns 204 No Content (empty response)
    if response is None or response == {}:
        debug_log(f"Successfully deleted organization: {org_name}", debug)
        return True
    
    if response and 'message' in response:
        debug_log(f"Failed to delete organization: {response['message']}", debug)
        return False
    
    debug_log(f"Delete organization response: {response}", debug)
    return False

def get_all_organizations(token, debug=False):
    """Get all organizations from Gitea."""
    orgs = []
    page = 1
    per_page = 50
    
    while True:
        url = f"{GITEA_API_BASE}/orgs?page={page}&limit={per_page}"
        debug_log(f"Fetching organizations from: {url}", debug)
        
        response = run_curl(url, token=token, debug=debug)
        
        if response is None or not isinstance(response, list):
            break
        
        if len(response) == 0:
            break
        
        for org in response:
            if isinstance(org, dict) and 'username' in org:
                orgs.append(org['username'])
                debug_log(f"Found organization: {org['username']}", debug)
        
        if len(response) < per_page:
            break
        
        page += 1
    
    return orgs

def check_stuck_mirrors_in_org(org_name, token, debug=False):
    """Check for stuck mirrors in an organization."""
    stuck_mirrors = []
    
    # Get all repositories in the organization
    repos = list_org_repositories(org_name, token, debug)
    
    for repo in repos:
        repo_name = repo.get('name')
        if not repo_name:
            continue
        
        # Get detailed repo info
        url = f"{GITEA_API_BASE}/repos/{org_name}/{repo_name}"
        debug_log(f"Checking repository: {org_name}/{repo_name}", debug)
        
        response = run_curl(url, token=token, debug=debug)
        
        if response:
            # Check if it's a mirror, empty, and has size 0
            is_mirror = response.get('mirror', False)
            is_empty = response.get('empty', False)
            size = response.get('size', -1)
            
            debug_log(f"  - mirror: {is_mirror}, empty: {is_empty}, size: {size}", debug)
            
            if is_mirror and is_empty and size == 0:
                stuck_mirrors.append({
                    'owner': org_name,
                    'name': repo_name,
                    'original_url': response.get('original_url', ''),
                    'clone_url': response.get('clone_url', '')
                })
                debug_log(f"  -> Stuck mirror detected: {org_name}/{repo_name}", debug)
    
    return stuck_mirrors

def get_all_accessible_gitlab_repos(base_url, token, debug=False):
    """Get all repositories accessible with GitLab token (including private repos)."""
    repos = []
    page = 1
    per_page = 100
    
    while True:
        # Use membership=true to get all projects the user is a member of
        url = f"{base_url}/api/v4/projects?membership=true&per_page={per_page}&page={page}"
        debug_log(f"Fetching accessible GitLab repos from: {url}", debug)
        
        # Use curl with authorization header
        cmd = ['curl', '-s', '-H', f'Authorization: Bearer {token}', url]
        
        # Create debug command with masked token
        if debug:
            masked_token = f"{token[:4]}...{token[-4:]}" if len(token) > 8 else "***"
            debug_cmd = ['curl', '-s', '-H', f'Authorization: Bearer {masked_token}', url]
            debug_log(f"Running: {' '.join(debug_cmd)}", debug)
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                debug_log(f"Curl failed: {result.stderr}", debug)
                break
            
            response = json.loads(result.stdout) if result.stdout else []
        except (json.JSONDecodeError, Exception) as e:
            debug_log(f"Error fetching GitLab repos: {e}", debug)
            break
        
        if not isinstance(response, list) or len(response) == 0:
            break
        
        for repo in response:
            if isinstance(repo, dict):
                repo_info = {
                    'clone_url': repo.get('http_url_to_repo', ''),
                    'ssh_url': repo.get('ssh_url_to_repo', ''),
                    'name': repo.get('path', ''),
                    'full_name': repo.get('path_with_namespace', ''),
                    'owner': repo.get('namespace', {}).get('path', ''),
                    'owner_type': repo.get('namespace', {}).get('kind', 'user'),  # user or group
                    'private': repo.get('visibility', 'public') == 'private',
                    'description': repo.get('description', ''),
                    'web_url': repo.get('web_url', '')
                }
                repos.append(repo_info)
                debug_log(f"Found repo: {repo_info['full_name']} (private: {repo_info['private']})", debug)
        
        if len(response) < per_page:
            break
        
        page += 1
    
    return repos

def get_all_accessible_github_repos(token, debug=False):
    """Get all repositories accessible with GitHub token (including private repos and org repos)."""
    repos = []
    page = 1
    per_page = 100
    
    # First get user's own repos
    while True:
        url = f"https://api.github.com/user/repos?per_page={per_page}&page={page}&type=all"
        debug_log(f"Fetching accessible GitHub repos from: {url}", debug)
        
        # Use curl with authorization header
        cmd = ['curl', '-s', '-H', f'Authorization: token {token}', url]
        
        # Create debug command with masked token
        if debug:
            masked_token = f"{token[:4]}...{token[-4:]}" if len(token) > 8 else "***"
            debug_cmd = ['curl', '-s', '-H', f'Authorization: token {masked_token}', url]
            debug_log(f"Running: {' '.join(debug_cmd)}", debug)
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                debug_log(f"Curl failed: {result.stderr}", debug)
                break
            
            response = json.loads(result.stdout) if result.stdout else []
        except (json.JSONDecodeError, Exception) as e:
            debug_log(f"Error fetching GitHub repos: {e}", debug)
            break
        
        if not isinstance(response, list) or len(response) == 0:
            break
        
        for repo in response:
            if isinstance(repo, dict):
                repo_info = {
                    'clone_url': repo.get('clone_url', ''),
                    'ssh_url': repo.get('ssh_url', ''),
                    'name': repo.get('name', ''),
                    'full_name': repo.get('full_name', ''),
                    'owner': repo.get('owner', {}).get('login', ''),
                    'owner_type': repo.get('owner', {}).get('type', 'User'),  # User or Organization
                    'private': repo.get('private', False),
                    'description': repo.get('description', ''),
                    'web_url': repo.get('html_url', '')
                }
                repos.append(repo_info)
                debug_log(f"Found repo: {repo_info['full_name']} (private: {repo_info['private']})", debug)
        
        if len(response) < per_page:
            break
        
        page += 1
    
    return repos

def has_stdin_data():
    """Check if there's data available on stdin"""
    return not sys.stdin.isatty()

def read_urls_from_stdin():
    """Read URLs from stdin, one per line"""
    urls = []
    try:
        for line in sys.stdin:
            line = line.strip()
            if line and not line.startswith('#'):  # Skip empty lines and comments
                urls.append(line)
    except KeyboardInterrupt:
        pass
    return urls

def main():
    parser = argparse.ArgumentParser(
        description='Archive remote git repositories to local Gitea instance or delete organizations. Can read URLs from stdin.',
        epilog='''Examples:
  # Archive a single repository
  archive_repo https://github.com/user/repo.git
  
  # Archive all repositories from a user/org
  archive_repo https://github.com/torvalds
  archive_repo https://gitlab.com/gitlab-org
  archive_repo https://codeberg.org/forgejo
  archive_repo https://gitea.example.com/myorg
  
  # Archive multiple URLs in one command (mix of repos and orgs)
  archive_repo https://github.com/user/project1 https://github.com/org1 https://gitlab.com/user2
  archive_repo https://github.com/torvalds/linux https://github.com/git/git https://gitlab.com/gitlab-org
  
  # Specify service explicitly
  archive_repo https://git.example.com/user --service gitea
  archive_repo https://git.example.com/user --service gogs
  
  # Override organization in Gitea
  archive_repo https://github.com/user/repo.git --org my-archives
  
  # Delete a single repository from Gitea
  archive_repo --delete-repo torvalds/linux
  archive_repo --delete-repo http://nas-main:3000/torvalds/linux
  archive_repo --delete-repo my-org/my-repo --debug
  
  # Delete multiple repositories (with stdin)
  echo -e "torvalds/linux\ngit/git" | archive_repo --delete-repo org/repo
  cat repos-to-delete.txt | archive_repo --delete-repo first-repo
  
  # Delete an organization and all its repositories from Gitea
  archive_repo --delete-org torvalds
  archive_repo --delete-org my-archives --debug
  
  # Make direct API calls to Gitea
  archive_repo --api-call /api/v1/user
  archive_repo --api-call /api/v1/repos/torvalds/linux
  archive_repo --api-call /orgs --method GET
  archive_repo --api-call /api/v1/orgs --method POST --data '{"username":"neworg","full_name":"New Org"}'
  archive_repo --api-call /repos/owner/repo --method DELETE
  
  # Check for stuck mirrors (empty repos with size 0)
  archive_repo --check-for-stuck-mirrors
  archive_repo --check-for-stuck-mirrors-and-fix
  archive_repo --check-for-stuck-mirrors-and-fix --no-confirm
  
  # Use delay between mirror operations to avoid rate limiting
  archive_repo https://github.com/torvalds --delay 120
  archive_repo --check-for-stuck-mirrors-and-fix --delay 60
  
  # Mirror all private repos from personal accounts
  archive_repo --mirror-personal-repos
  
  # Use parallel processing for faster archiving
  archive_repo https://github.com/torvalds --parallel 4
  archive_repo https://github.com/kubernetes --parallel 8 --delay 5
  
  # Read URLs from stdin
  cat urls.txt | archive_repo
  extract_git_links README.md | archive_repo
  
  # Combine stdin with command-line URLs
  echo "https://github.com/git/git" | archive_repo https://github.com/torvalds/linux
  archive_repo --mirror-personal-repos --delay 30 --no-confirm
  
  # Debug mode
  archive_repo https://github.com/user --debug

Supported services for bulk archiving: github, gitlab, gitea, forgejo, gogs, codeberg

Environment variables:
  GITEA_TOKEN    - Required: API token for your Gitea instance
  GITHUB_TOKEN   - Optional: GitHub personal access token (helps avoid rate limits)
  GITLAB_TOKEN   - Optional: GitLab personal access token (helps avoid rate limits)

Configuration:
  Edit PERSONAL_ACCOUNTS in the script to add your personal git accounts for --mirror-personal-repos

Exit codes:
  0 - All operations succeeded
  1 - All operations failed
  2 - Partial success (some succeeded, some failed)
''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('urls', nargs='*', help='URL(s) of repositories, users, or organizations to archive')
    parser.add_argument('--service', choices=list(SERVICE_TYPES.keys()),
                      help='Git service type (auto-detected if not specified)')
    parser.add_argument('--org', help='Override organization/owner name in Gitea')
    parser.add_argument('--debug', action='store_true', help='Enable debug output')
    parser.add_argument('--delete-org', metavar='ORG_NAME',
                      help='Delete an organization and all its repositories from Gitea')
    parser.add_argument('--delete-repo', metavar='REPO', nargs='?', const='',
                      help='Delete repository(ies) from Gitea (format: org/repo or full URL). Can read from stdin.')
    parser.add_argument('--api-call', metavar='ENDPOINT',
                      help='Make a direct API call to Gitea (e.g., /api/v1/user)')
    parser.add_argument('--method', default='GET', choices=['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
                      help='HTTP method for --api-call (default: GET)')
    parser.add_argument('--data', metavar='JSON',
                      help='JSON data for POST/PUT/PATCH requests with --api-call')
    parser.add_argument('--check-for-stuck-mirrors', action='store_true',
                      help='Check all organizations for stuck mirrors (empty repos with size 0)')
    parser.add_argument('--check-for-stuck-mirrors-and-fix', action='store_true',
                      help='Check for stuck mirrors and fix them by deleting and re-mirroring')
    parser.add_argument('--no-confirm', action='store_true',
                      help='Skip confirmation prompts (use with caution)')
    parser.add_argument('--delay', type=int, default=0, metavar='SECONDS',
                      help='Delay in seconds between mirror operations (helps with rate limiting)')
    parser.add_argument('--mirror-personal-repos', action='store_true',
                      help='Mirror all private repos you have access to from accounts in PERSONAL_ACCOUNTS')
    parser.add_argument('--dry-run', action='store_true',
                      help='Show what would be done without actually doing it')
    parser.add_argument('--parallel', type=int, default=1, metavar='N',
                      help='Number of parallel migration requests (default: 1)')
    
    args = parser.parse_args()
    
    # Check for API token
    token = os.environ.get('GITEA_TOKEN')
    if not token:
        if not args.debug:
            sys.exit(1)
        print("Error: GITEA_TOKEN environment variable not set", file=sys.stderr)
        sys.exit(1)
    
    # Handle --mirror-personal-repos
    if args.mirror_personal_repos:
        debug_log("Mirroring all accessible personal repositories...", args.debug)
        
        if not PERSONAL_ACCOUNTS:
            print("Error: No personal accounts configured in PERSONAL_ACCOUNTS", file=sys.stderr)
            print("Edit the script and add your accounts to the PERSONAL_ACCOUNTS list", file=sys.stderr)
            sys.exit(1)
        
        all_repos = []
        
        # Process each personal account
        for account_url in PERSONAL_ACCOUNTS:
            debug_log(f"\nProcessing personal account: {account_url}", args.debug)
            
            # Detect service
            service = detect_service(account_url, args.debug)
            if not service:
                print(f"Warning: Cannot detect service for {account_url}, skipping", file=sys.stderr)
                continue
            
            # Get repositories based on service
            if service == 'gitlab':
                gitlab_token = os.environ.get('GITLAB_TOKEN')
                if not gitlab_token:
                    print(f"Warning: GITLAB_TOKEN not set, skipping GitLab account {account_url}", file=sys.stderr)
                    continue
                
                parsed = urlparse(account_url)
                base_url = f"{parsed.scheme}://{parsed.netloc}"
                repos = get_all_accessible_gitlab_repos(base_url, gitlab_token, args.debug)
                
                # Add service info to each repo
                for repo in repos:
                    repo['service'] = service
                    repo['base_url'] = base_url
                    all_repos.append(repo)
                    
            elif service == 'github':
                github_token = os.environ.get('GITHUB_TOKEN')
                if not github_token:
                    print(f"Warning: GITHUB_TOKEN not set, skipping GitHub account {account_url}", file=sys.stderr)
                    continue
                
                repos = get_all_accessible_github_repos(github_token, args.debug)
                
                # Add service info to each repo
                for repo in repos:
                    repo['service'] = service
                    repo['base_url'] = 'https://github.com'
                    all_repos.append(repo)
            else:
                print(f"Warning: Personal repo mirroring not implemented for {service}", file=sys.stderr)
                continue
        
        if not all_repos:
            print("No accessible repositories found.", file=sys.stderr)
            sys.exit(0)
        
        # Group repos by owner
        repos_by_owner = {}
        for repo in all_repos:
            owner = repo['owner']
            if owner not in repos_by_owner:
                repos_by_owner[owner] = []
            repos_by_owner[owner].append(repo)
        
        print(f"\nFound {len(all_repos)} accessible repositories across {len(repos_by_owner)} owners:", file=sys.stderr)
        for owner, owner_repos in repos_by_owner.items():
            private_count = sum(1 for r in owner_repos if r['private'])
            public_count = len(owner_repos) - private_count
            print(f"  {owner}: {len(owner_repos)} repos ({private_count} private, {public_count} public)", file=sys.stderr)
        
        # Confirm before proceeding
        if not args.no_confirm:
            response = input("\nProceed with mirroring all repositories? (yes/no): ")
            if response.lower() != 'yes':
                print("Operation cancelled.", file=sys.stderr)
                sys.exit(0)
        
        # Mirror all repositories
        total_success = 0
        total_failed = 0
        failed_repos = []
        
        for owner, owner_repos in repos_by_owner.items():
            debug_log(f"\nProcessing repositories for owner: {owner}", args.debug)
            
            # Check if owner exists, create if needed
            gitea_token = token  # token is the GITEA_TOKEN
            exists, owner_type = owner_exists_in_gitea(owner, gitea_token, args.debug)
            if not exists:
                # Determine the website URL based on the first repo's base URL
                first_repo = owner_repos[0]
                if first_repo['owner_type'].lower() in ['group', 'organization']:
                    website_url = f"{first_repo['base_url']}/{owner}"
                else:
                    website_url = f"{first_repo['base_url']}/{owner}"
                
                debug_log(f"Creating organization: {owner} with website: {website_url}", args.debug)
                if not create_organization(owner, gitea_token, website=website_url, debug=args.debug, dry_run=args.dry_run):
                    print(f"Failed to create organization: {owner}, skipping its repos", file=sys.stderr)
                    failed_repos.extend([r['full_name'] for r in owner_repos])
                    total_failed += len(owner_repos)
                    continue
            
            # Mirror each repository
            if args.parallel > 1 and len(owner_repos) > 1:
                # Parallel processing
                safe_print(f"Processing {len(owner_repos)} repositories for {owner} with {args.parallel} parallel workers...", file=sys.stderr)
                
                # Prepare work items
                work_items = []
                for repo in owner_repos:
                    work_items.append((repo['clone_url'], repo['service'], owner, repo['name'], 
                                     gitea_token, args.debug, args.delay, args.dry_run))
                
                # Process in parallel
                with ThreadPoolExecutor(max_workers=args.parallel) as executor:
                    future_to_repo = {executor.submit(migrate_repository_worker, item): item[3] for item in work_items}
                    
                    for future in as_completed(future_to_repo):
                        success, _, error_msg = future.result()
                        if success:
                            total_success += 1
                        else:
                            total_failed += 1
                            repo_name = future_to_repo[future]
                            failed_repos.append(f"{owner}/{repo_name}")
                            if error_msg:
                                safe_print(f"✗ Failed: {error_msg}", file=sys.stderr)
            else:
                # Sequential processing
                for i, repo in enumerate(owner_repos):
                    repo_name = repo['name']
                    clone_url = repo['clone_url']
                    service = repo['service']
                    
                    print(f"[{i+1}/{len(owner_repos)}] Mirroring {owner}/{repo_name} (private: {repo['private']})...", file=sys.stderr)
                    
                    if migrate_repository(clone_url, service, owner, repo_name, gitea_token, args.debug, args.delay, args.dry_run):
                        total_success += 1
                        debug_log(f"Successfully mirrored: {owner}/{repo_name}", args.debug)
                    else:
                        total_failed += 1
                        failed_repos.append(f"{owner}/{repo_name}")
                        print(f"Failed to mirror: {owner}/{repo_name}", file=sys.stderr)
        
        # Summary
        print(f"\n{'='*60}", file=sys.stderr)
        print(f"PERSONAL REPOS MIRROR SUMMARY", file=sys.stderr)
        print(f"{'='*60}", file=sys.stderr)
        print(f"Total repositories processed: {len(all_repos)}", file=sys.stderr)
        print(f"Successfully mirrored: {total_success}", file=sys.stderr)
        print(f"Failed: {total_failed}", file=sys.stderr)
        
        if failed_repos:
            print(f"\nFailed repositories:", file=sys.stderr)
            for repo in failed_repos:
                print(f"  - {repo}", file=sys.stderr)
        
        # Exit with appropriate code
        if total_success == 0 and total_failed > 0:
            sys.exit(1)  # All failed
        elif total_failed > 0:
            sys.exit(2)  # Partial success
        else:
            sys.exit(0)  # All succeeded
    
    # Handle --check-for-stuck-mirrors or --check-for-stuck-mirrors-and-fix
    if args.check_for_stuck_mirrors or args.check_for_stuck_mirrors_and_fix:
        debug_log("Checking for stuck mirrors in all organizations...", args.debug)
        
        # Get all organizations
        orgs = get_all_organizations(token, args.debug)
        
        if not orgs:
            print("No organizations found in Gitea.", file=sys.stderr)
            sys.exit(0)
        
        all_stuck_mirrors = []
        
        # Check each organization
        for org in orgs:
            debug_log(f"\nChecking organization: {org}", args.debug)
            stuck = check_stuck_mirrors_in_org(org, token, args.debug)
            all_stuck_mirrors.extend(stuck)
        
        if not all_stuck_mirrors:
            print("No stuck mirrors found.", file=sys.stderr)
            sys.exit(0)
        
        # Display stuck mirrors
        print(f"\nFound {len(all_stuck_mirrors)} stuck mirrors:", file=sys.stderr)
        for mirror in all_stuck_mirrors:
            print(f"{mirror['owner']}/{mirror['name']}")
        
        # If we're just checking, exit here
        if args.check_for_stuck_mirrors:
            sys.exit(0)
        
        # Fix mode - confirm before proceeding
        if not args.no_confirm:
            print(f"\nThis will delete and re-mirror {len(all_stuck_mirrors)} repositories.", file=sys.stderr)
            response = input("Are you sure you want to proceed? (yes/no): ")
            
            if response.lower() != 'yes':
                print("Operation cancelled.", file=sys.stderr)
                sys.exit(0)
        
        # Fix each stuck mirror
        fixed_count = 0
        failed_fixes = []
        
        for i, mirror in enumerate(all_stuck_mirrors):
            owner = mirror['owner']
            name = mirror['name']
            original_url = mirror['original_url']
            
            print(f"\n[{i+1}/{len(all_stuck_mirrors)}] Fixing {owner}/{name}...", file=sys.stderr)
            
            # Delete the repository
            if not delete_repository(owner, name, token, args.debug):
                print(f"  Failed to delete {owner}/{name}", file=sys.stderr)
                failed_fixes.append(f"{owner}/{name}")
                continue
            
            debug_log(f"  Deleted {owner}/{name}", args.debug)
            
            # Parse repo info from original URL to get service type
            service = detect_service(original_url, args.debug)
            if not service:
                print(f"  Failed to detect service type for {original_url}", file=sys.stderr)
                failed_fixes.append(f"{owner}/{name}")
                continue
            
            # Re-mirror the repository
            if migrate_repository(original_url, service, owner, name, token, args.debug, args.delay, args.dry_run):
                fixed_count += 1
                print(f"  Successfully re-mirrored {owner}/{name}", file=sys.stderr)
            else:
                print(f"  Failed to re-mirror {owner}/{name}", file=sys.stderr)
                failed_fixes.append(f"{owner}/{name}")
        
        # Summary
        print(f"\nFixed {fixed_count} out of {len(all_stuck_mirrors)} stuck mirrors.", file=sys.stderr)
        if failed_fixes:
            print(f"\nFailed to fix:", file=sys.stderr)
            for failed in failed_fixes:
                print(f"  - {failed}", file=sys.stderr)
            sys.exit(1)
        
        sys.exit(0)
    
    # Handle --api-call option
    if args.api_call:
        endpoint = args.api_call
        method = args.method
        data = args.data
        
        debug_log(f"API call mode: {method} {endpoint}", args.debug)
        
        # Ensure endpoint starts with /
        if not endpoint.startswith('/'):
            endpoint = '/' + endpoint
        
        # Construct full URL
        if endpoint.startswith('/api/v1/'):
            url = f"{GITEA_SERVER_URL}{endpoint}"
        else:
            # Assume it's an API v1 endpoint if not specified
            if not endpoint.startswith('/api/'):
                endpoint = f"/api/v1{endpoint}"
            url = f"{GITEA_SERVER_URL}{endpoint}"
        
        debug_log(f"Full URL: {url}", args.debug)
        
        # Parse JSON data if provided
        json_data = None
        if data:
            try:
                json_data = json.loads(data)
                debug_log(f"Parsed JSON data: {json.dumps(json_data, indent=2)}", args.debug)
            except json.JSONDecodeError as e:
                print(f"Error: Invalid JSON data: {e}", file=sys.stderr)
                sys.exit(1)
        
        # Make the API call
        response = run_curl(url, method=method, data=json_data, token=token, debug=args.debug)
        
        # Handle response
        if response is None:
            # For DELETE operations, empty response might be success
            if method == 'DELETE':
                print("Success: No content returned (typical for DELETE operations)")
            else:
                print("Error: No response or empty response from API", file=sys.stderr)
                sys.exit(1)
        elif isinstance(response, dict) and 'message' in response and 'errors' in response:
            # Likely an error response
            print(f"Error: {response.get('message', 'Unknown error')}", file=sys.stderr)
            if response.get('errors'):
                print(f"Details: {json.dumps(response['errors'], indent=2)}", file=sys.stderr)
            sys.exit(1)
        else:
            # Success - pretty print the response
            print(json.dumps(response, indent=2))
        
        sys.exit(0)
    
    # Handle --delete-repo option
    if args.delete_repo is not None:
        # Collect repositories to delete from both argument and stdin
        repos_to_delete = []
        
        # Add repository from command line argument (if not empty)
        if args.delete_repo:
            repos_to_delete.append(args.delete_repo)
        
        # Check for additional repositories from stdin
        if has_stdin_data():
            stdin_repos = read_urls_from_stdin()
            if stdin_repos:
                debug_log(f"Read {len(stdin_repos)} repository identifiers from stdin", args.debug)
                repos_to_delete.extend(stdin_repos)
        
        if not repos_to_delete:
            print("Error: No repositories to delete provided", file=sys.stderr)
            sys.exit(1)
        
        debug_log(f"Delete repository mode: {len(repos_to_delete)} repositories", args.debug)
        
        # Parse and validate all repositories first
        parsed_repos = []
        invalid_repos = []
        
        for repo_arg in repos_to_delete:
            owner, repo_name = parse_repo_from_delete_arg(repo_arg, args.debug)
            
            if not owner or not repo_name:
                debug_log(f"Invalid repository format: {repo_arg}", args.debug)
                invalid_repos.append(repo_arg)
                continue
            
            # Check if repository exists
            if not check_repository_exists(owner, repo_name, token, args.debug, dry_run=args.dry_run):
                debug_log(f"Repository '{owner}/{repo_name}' does not exist in Gitea", args.debug)
                invalid_repos.append(f"{owner}/{repo_name} (not found)")
                continue
            
            parsed_repos.append((owner, repo_name, repo_arg))
        
        if invalid_repos:
            print(f"Error: Invalid or non-existent repositories:", file=sys.stderr)
            for repo in invalid_repos:
                print(f"  - {repo}", file=sys.stderr)
            print("Use format: org/repo or full repository URL", file=sys.stderr)
            sys.exit(1)
        
        if not parsed_repos:
            print("Error: No valid repositories to delete", file=sys.stderr)
            sys.exit(1)
        
        # Show what will be deleted
        print(f"This will permanently delete {len(parsed_repos)} repositories:", file=sys.stderr)
        for owner, repo_name, _ in parsed_repos:
            print(f"  - {owner}/{repo_name}", file=sys.stderr)
        
        if args.dry_run:
            print("[DRY-RUN] Would delete the above repositories", file=sys.stderr)
            for owner, repo_name, _ in parsed_repos:
                dry_run_log(f"Would delete repository: {owner}/{repo_name}")
            sys.exit(0)
        
        # Confirm deletion (unless --no-confirm)
        if not args.no_confirm:
            response = input("Are you sure you want to proceed? (yes/no): ")
            
            if response.lower() != 'yes':
                print("Deletion cancelled.", file=sys.stderr)
                sys.exit(0)
        
        # Delete repositories
        deleted_count = 0
        failed_repos = []
        
        for owner, repo_name, repo_arg in parsed_repos:
            debug_log(f"Deleting repository: {owner}/{repo_name}", args.debug)
            
            if delete_repository(owner, repo_name, token, args.debug, dry_run=args.dry_run):
                print(f"Successfully deleted repository '{owner}/{repo_name}'.", file=sys.stderr)
                deleted_count += 1
            else:
                print(f"Error: Failed to delete repository '{owner}/{repo_name}'", file=sys.stderr)
                failed_repos.append(f"{owner}/{repo_name}")
        
        # Summary
        print(f"\nDeletion Summary:", file=sys.stderr)
        print(f"Successfully deleted: {deleted_count}", file=sys.stderr)
        print(f"Failed: {len(failed_repos)}", file=sys.stderr)
        
        if failed_repos:
            print("Failed repositories:", file=sys.stderr)
            for repo in failed_repos:
                print(f"  - {repo}", file=sys.stderr)
            sys.exit(1)
        
        sys.exit(0)
    
    # Handle --delete-org option
    if args.delete_org:
        org_name = args.delete_org
        debug_log(f"Delete organization mode: {org_name}", args.debug)
        
        # Check if organization exists
        exists, owner_type = owner_exists_in_gitea(org_name, token, args.debug)
        
        if not exists:
            print(f"Error: Organization '{org_name}' does not exist in Gitea", file=sys.stderr)
            sys.exit(1)
        
        if owner_type != 'org':
            print(f"Error: '{org_name}' is a user, not an organization", file=sys.stderr)
            sys.exit(1)
        
        # List all repositories in the organization
        repos = list_org_repositories(org_name, token, args.debug)
        
        if repos:
            print(f"Found {len(repos)} repositories in organization '{org_name}':", file=sys.stderr)
            for repo in repos:
                print(f"  - {repo['name']}", file=sys.stderr)
            
            # Confirm deletion
            print(f"\nThis will permanently delete the organization '{org_name}' and all {len(repos)} repositories.", file=sys.stderr)
            response = input("Are you sure you want to proceed? (yes/no): ")
            
            if response.lower() != 'yes':
                print("Deletion cancelled.", file=sys.stderr)
                sys.exit(0)
        else:
            print(f"Organization '{org_name}' has no repositories.", file=sys.stderr)
            # Confirm deletion of empty org
            response = input(f"Delete empty organization '{org_name}'? (yes/no): ")
            
            if response.lower() != 'yes':
                print("Deletion cancelled.", file=sys.stderr)
                sys.exit(0)
        
        # Delete all repositories
        deleted_repos = 0
        failed_repos = []
        
        for repo in repos:
            repo_name = repo['name']
            if delete_repository(org_name, repo_name, token, args.debug):
                deleted_repos += 1
                debug_log(f"Deleted repository: {org_name}/{repo_name}", args.debug)
            else:
                failed_repos.append(repo_name)
                print(f"Failed to delete repository: {org_name}/{repo_name}", file=sys.stderr)
        
        if failed_repos:
            print(f"\nWarning: Failed to delete {len(failed_repos)} repositories:", file=sys.stderr)
            for repo in failed_repos:
                print(f"  - {repo}", file=sys.stderr)
            print(f"Cannot delete organization with remaining repositories.", file=sys.stderr)
            sys.exit(1)
        
        # Delete the organization
        if delete_organization(org_name, token, args.debug):
            print(f"\nSuccessfully deleted organization '{org_name}' and {deleted_repos} repositories.", file=sys.stderr)
            sys.exit(0)
        else:
            print(f"\nError: Failed to delete organization '{org_name}'", file=sys.stderr)
            sys.exit(1)
    
    # Collect URLs from both stdin and command line
    all_urls = list(args.urls)  # Copy the command line URLs
    
    # Check for stdin data
    if has_stdin_data():
        stdin_urls = read_urls_from_stdin()
        if stdin_urls:
            debug_log(f"Read {len(stdin_urls)} URLs from stdin", args.debug)
            all_urls.extend(stdin_urls)
    
    # Validate that URLs were provided for archive mode
    if not all_urls:
        parser.error("No URLs provided. Use --delete-org to delete an organization, --delete-repo to delete a repository, --api-call to make API requests, or provide URLs to archive.")
    
    try:
        # Track overall statistics
        total_success = 0
        total_failed = 0
        all_failed_items = []
        
        # Collect all individual repos for potential parallel processing
        individual_repos = []
        
        # Process each URL
        for url in all_urls:
            debug_log(f"\n{'='*60}", args.debug)
            debug_log(f"Processing URL: {url}", args.debug)
            debug_log(f"{'='*60}", args.debug)
            
            # Detect or validate service type for this URL
            if args.service:
                service = SERVICE_TYPES[args.service]
                debug_log(f"Using specified service: {service}", args.debug)
            else:
                service = detect_service(url, args.debug)
                if not service:
                    print(f"Error: Cannot detect service type from URL: {url}. Please specify with --service", file=sys.stderr)
                    total_failed += 1
                    all_failed_items.append(url)
                    continue
                debug_log(f"Auto-detected service: {service}", args.debug)
            
            # Determine if this is an org/user URL or a specific repo
            if is_org_or_user_url(url, args.debug):
                # Extract owner from URL
                parsed = urlparse(url)
                owner = parsed.path.strip('/').split('/')[0]
                
                if not owner:
                    print(f"Error: Cannot extract owner from URL: {url}", file=sys.stderr)
                    total_failed += 1
                    all_failed_items.append(url)
                    continue
                
                debug_log(f"Detected org/user URL for: {owner}", args.debug)
                
                # List all repositories
                repo_urls = list_repos_for_service(url, service, owner, args.debug)
                
                if not repo_urls:
                    print(f"Warning: No repositories found for {owner}", file=sys.stderr)
                    continue
                
                debug_log(f"Found {len(repo_urls)} repositories to archive", args.debug)
                
                # Archive each repository
                success_count = 0
                failed_repos = []
                
                if args.parallel > 1:
                    # Parallel processing
                    safe_print(f"Processing {len(repo_urls)} repositories with {args.parallel} parallel workers...", file=sys.stderr)
                    
                    # Prepare work items
                    work_items = []
                    for repo_url in repo_urls:
                        default_owner, repo_name = parse_repo_info(repo_url, args.debug)
                        if not repo_name:
                            debug_log(f"Skipping invalid repo URL: {repo_url}", args.debug)
                            failed_repos.append(repo_url)
                            continue
                        
                        # Determine repo owner for Gitea
                        repo_owner = args.org if args.org else default_owner
                        
                        work_items.append((repo_url, service, repo_owner, repo_name, token, args.debug, args.delay, args.dry_run))
                    
                    # Process in parallel
                    with ThreadPoolExecutor(max_workers=args.parallel) as executor:
                        future_to_url = {executor.submit(migrate_repository_worker, item): item[0] for item in work_items}
                        
                        for future in as_completed(future_to_url):
                            success, repo_url, error_msg = future.result()
                            if success:
                                success_count += 1
                            else:
                                failed_repos.append(repo_url)
                                if error_msg:
                                    safe_print(f"✗ Failed: {error_msg}", file=sys.stderr)
                else:
                    # Sequential processing (original behavior)
                    for repo_url in repo_urls:
                        default_owner, repo_name = parse_repo_info(repo_url, args.debug)
                        if not repo_name:
                            debug_log(f"Skipping invalid repo URL: {repo_url}", args.debug)
                            continue
                        
                        # Determine repo owner for Gitea
                        repo_owner = args.org if args.org else default_owner
                        
                        debug_log(f"Archiving {repo_owner}/{repo_name} from {repo_url}", args.debug)
                        
                        # Check if owner exists as user or org
                        exists, owner_type = owner_exists_in_gitea(repo_owner, token, args.debug)
                        if not exists:
                            # Owner doesn't exist, create as organization
                            org_website = construct_org_url(repo_url, repo_owner, service, args.debug)
                            debug_log(f"Creating organization: {repo_owner} with website: {org_website}", args.debug)
                            if not create_organization(repo_owner, token, website=org_website, debug=args.debug, dry_run=args.dry_run):
                                debug_log(f"Failed to create organization: {repo_owner}", args.debug)
                                failed_repos.append(repo_url)
                                continue
                        
                        # Migrate the repository
                        if migrate_repository(repo_url, service, repo_owner, repo_name, token, args.debug, args.delay, args.dry_run):
                            success_count += 1
                            debug_log(f"Successfully archived: {repo_owner}/{repo_name}", args.debug)
                        else:
                            failed_repos.append(repo_url)
                            debug_log(f"Failed to archive: {repo_owner}/{repo_name}", args.debug)
                
                # Update totals
                total_success += success_count
                total_failed += len(failed_repos)
                all_failed_items.extend(failed_repos)
                
                # Report results for this org/user
                if args.debug:
                    print(f"\nOrg/User {owner}: {success_count}/{len(repo_urls)} repositories archived successfully", file=sys.stderr)
                    if failed_repos:
                        print(f"Failed repositories:", file=sys.stderr)
                        for repo in failed_repos:
                            print(f"  - {repo}", file=sys.stderr)
                
            else:
                # Single repository mode
                # Parse repository information
                default_owner, repo_name = parse_repo_info(url, args.debug)
                if not repo_name:
                    print(f"Error: Cannot parse repository name from URL: {url}", file=sys.stderr)
                    total_failed += 1
                    all_failed_items.append(url)
                    continue
                
                # Determine repo owner
                repo_owner = args.org if args.org else default_owner
                if not repo_owner:
                    print(f"Error: Cannot determine repository owner for {url}. Please specify with --org", file=sys.stderr)
                    total_failed += 1
                    all_failed_items.append(url)
                    continue
                
                debug_log(f"Repository details - Service: {service}, Owner: {repo_owner}, Name: {repo_name}", args.debug)
                
                # Check if owner exists as user or org
                exists, owner_type = owner_exists_in_gitea(repo_owner, token, args.debug)
                if not exists:
                    # Owner doesn't exist, create as organization
                    org_website = construct_org_url(url, repo_owner, service, args.debug)
                    debug_log(f"Owner '{repo_owner}' not found, creating as organization with website: {org_website}", args.debug)
                    if not create_organization(repo_owner, token, website=org_website, debug=args.debug, dry_run=args.dry_run):
                        print(f"Error: Failed to create organization: {repo_owner}", file=sys.stderr)
                        total_failed += 1
                        all_failed_items.append(url)
                        continue
                else:
                    debug_log(f"Owner '{repo_owner}' already exists as {owner_type}", args.debug)
                
                # Migrate the repository
                success = migrate_repository(url, service, repo_owner, repo_name, token, args.debug, args.delay, args.dry_run)
                
                if success:
                    debug_log("Repository archived successfully", args.debug)
                    total_success += 1
                else:
                    print(f"Error: Failed to migrate repository: {url}", file=sys.stderr)
                    total_failed += 1
                    all_failed_items.append(url)
        
        # Final summary for all URLs
        if len(args.urls) > 1 or args.debug:
            print(f"\n{'='*60}", file=sys.stderr)
            print(f"FINAL SUMMARY", file=sys.stderr)
            print(f"{'='*60}", file=sys.stderr)
            print(f"Total repositories archived: {total_success}", file=sys.stderr)
            print(f"Total failed: {total_failed}", file=sys.stderr)
            if all_failed_items:
                print(f"\nFailed items:", file=sys.stderr)
                for item in all_failed_items:
                    print(f"  - {item}", file=sys.stderr)
        
        # Exit with appropriate code
        if total_success == 0 and total_failed > 0:
            sys.exit(1)  # All failed
        elif total_failed > 0:
            sys.exit(2)  # Partial success
        else:
            sys.exit(0)  # All succeeded
            
    except Exception as e:
        if args.debug:
            print(f"Error: {e}", file=sys.stderr)
            traceback.print_exc()
        else:
            print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
