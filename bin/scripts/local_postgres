#!/bin/bash
set -euo pipefail

# local_postgres - Universal PostgreSQL management script for local dotfiles
# First implementation: Transcription storage
# Designed to be extended with additional schemas and functionality

# Sync configuration - add databases and hosts to sync here
SYNC_DATABASES=(
    "transcriptions"
    "ai_chats"
    "postgres"  # For pgvector/second_brain_vectors table
)

# Tailscale hostnames/IPs to sync with
SYNC_HOSTS=(
    # Add your other devices here, e.g.:
    # "laptop.tailnet-name.ts.net"
    # "desktop.tailnet-name.ts.net"
    # "100.64.0.2"
)

# Configuration file path
CONFIG_FILE="${HOME}/.config/transcription_db/config.yaml"

# Load configuration from YAML if available
if [[ -f "$CONFIG_FILE" ]] && command -v yq &> /dev/null; then
    CONFIG_DB_HOST=$(yq eval '.database.host // "127.0.0.1"' "$CONFIG_FILE")
    CONFIG_DB_PORT=$(yq eval '.database.port // 5432' "$CONFIG_FILE")
    CONFIG_DB_NAME=$(yq eval '.database.name // "transcriptions"' "$CONFIG_FILE")
    CONFIG_DB_USER=$(yq eval '.database.user // "postgres"' "$CONFIG_FILE")
    CONFIG_DB_PASSWORD=$(yq eval '.database.password // ""' "$CONFIG_FILE")
else
    CONFIG_DB_HOST="127.0.0.1"
    CONFIG_DB_PORT="5432"
    CONFIG_DB_NAME="transcriptions"
    CONFIG_DB_USER="postgres"
    CONFIG_DB_PASSWORD=""
fi

# Default configuration (environment variables override config file)
DEFAULT_DB_HOST="${LOCAL_DB_HOST:-${TRANSCRIPTION_DB_HOST:-$CONFIG_DB_HOST}}"
DEFAULT_DB_PORT="${LOCAL_DB_PORT:-${TRANSCRIPTION_DB_PORT:-$CONFIG_DB_PORT}}"
DEFAULT_DB_NAME="${LOCAL_DB_NAME:-${TRANSCRIPTION_DB_NAME:-$CONFIG_DB_NAME}}"
DEFAULT_DB_USER="${LOCAL_DB_USER:-${TRANSCRIPTION_DB_USER:-$CONFIG_DB_USER}}"
DEFAULT_DB_PASSWORD="${LOCAL_DB_PASSWORD:-${TRANSCRIPTION_DB_PASSWORD:-$CONFIG_DB_PASSWORD}}"

# Script variables
SCRIPT_NAME="$(basename "$0")"
ACTION=""
VERBOSE=false
TARGET_DATABASE=""

# Database connection string
get_connection_string() {
    local host="${1:-$DEFAULT_DB_HOST}"
    local port="${2:-$DEFAULT_DB_PORT}"
    local dbname="${3:-$DEFAULT_DB_NAME}"
    local user="${4:-$DEFAULT_DB_USER}"
    local password="${5:-$DEFAULT_DB_PASSWORD}"
    
    local conn="postgresql://${user}"
    [[ -n "$password" ]] && conn="${conn}:${password}"
    conn="${conn}@${host}:${port}/${dbname}"
    echo "$conn"
}

# Execute SQL with error handling
execute_sql() {
    local sql="$1"
    local db="${2:-$DEFAULT_DB_NAME}"
    
    if [[ "$VERBOSE" == true ]]; then
        echo "Executing SQL on database '$db':"
        echo "$sql"
    fi
    
    psql -d "$(get_connection_string "" "" "$db")" -c "$sql" 2>&1 || {
        echo "Error executing SQL: $?" >&2
        return 1
    }
}

# Check if database exists
database_exists() {
    local dbname="${1:-$DEFAULT_DB_NAME}"
    psql -d "$(get_connection_string "" "" "postgres")" -tAc "SELECT 1 FROM pg_database WHERE datname='$dbname'" 2>/dev/null | grep -q 1
}

# Create database if it doesn't exist
create_database() {
    local dbname="${DEFAULT_DB_NAME}"
    
    if database_exists "$dbname"; then
        echo "Database '$dbname' already exists"
        return 0
    fi
    
    echo "Creating database '$dbname'..."
    execute_sql "CREATE DATABASE $dbname" "postgres" || return 1
    echo "Database created successfully"
}

# Initialize transcriptions schema
init_transcriptions_schema() {
    echo "Initializing transcriptions schema..."
    
    # Create main transcriptions table
    execute_sql "
    CREATE TABLE IF NOT EXISTS transcriptions (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        filename VARCHAR(512) NOT NULL,
        file_path TEXT,
        file_hash VARCHAR(64) NOT NULL,
        transcribed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        duration_seconds INTEGER,
        model_used VARCHAR(100),
        language VARCHAR(10),
        metadata JSONB DEFAULT '{}',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(file_hash)
    );" || return 1
    
    # Create chunks table
    execute_sql "
    CREATE TABLE IF NOT EXISTS transcription_chunks (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        transcription_id UUID NOT NULL REFERENCES transcriptions(id) ON DELETE CASCADE,
        chunk_number INTEGER NOT NULL,
        content TEXT NOT NULL,
        content_vector tsvector GENERATED ALWAYS AS (to_tsvector('english', content)) STORED,
        character_count INTEGER NOT NULL,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(transcription_id, chunk_number)
    );" || return 1
    
    # Create indexes
    echo "Creating indexes..."
    execute_sql "CREATE INDEX IF NOT EXISTS idx_transcription_chunks_content_vector ON transcription_chunks USING GIN(content_vector);" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_transcription_chunks_transcription_id ON transcription_chunks(transcription_id);" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_transcriptions_file_hash ON transcriptions(file_hash);" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_transcriptions_metadata ON transcriptions USING GIN(metadata);" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_transcriptions_type ON transcriptions((metadata->>'type'));" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_transcriptions_tags ON transcriptions USING GIN((metadata->'tags'));" || return 1
    
    # Create update trigger function
    execute_sql "
    CREATE OR REPLACE FUNCTION update_updated_at_column()
    RETURNS TRIGGER AS \$\$
    BEGIN
        NEW.updated_at = CURRENT_TIMESTAMP;
        RETURN NEW;
    END;
    \$\$ language 'plpgsql';" || return 1
    
    # Create trigger
    execute_sql "
    DO \$\$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_transcriptions_updated_at') THEN
            CREATE TRIGGER update_transcriptions_updated_at 
            BEFORE UPDATE ON transcriptions
            FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
        END IF;
    END
    \$\$;" || return 1
    
    echo "Transcriptions schema initialized successfully"
}

# Initialize ai_chats schema
init_ai_chats_schema() {
    echo "Initializing ai_chats schema..."
    
    # Create ai_chats database if it doesn't exist
    if ! database_exists "ai_chats"; then
        echo "Creating ai_chats database..."
        execute_sql "CREATE DATABASE ai_chats" "postgres" || return 1
    fi
    
    # Create update trigger function in ai_chats database
    execute_sql "
    CREATE OR REPLACE FUNCTION update_updated_at_column()
    RETURNS TRIGGER AS \$\$
    BEGIN
        NEW.updated_at = CURRENT_TIMESTAMP;
        RETURN NEW;
    END;
    \$\$ language 'plpgsql';" "ai_chats" || return 1
    
    # Add tags column if it doesn't exist
    execute_sql "ALTER TABLE ai_chats ADD COLUMN IF NOT EXISTS tags TEXT[];" "ai_chats" || return 1
    
    # Create main ai_chats table
    execute_sql "
    CREATE TABLE IF NOT EXISTS ai_chats (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        prompt TEXT NOT NULL,
        response TEXT NOT NULL,
        provider VARCHAR(50) NOT NULL,
        model VARCHAR(200) NOT NULL,
        request_timestamp TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        response_timestamp TIMESTAMP WITH TIME ZONE,
        duration_ms INTEGER,
        tokens_input INTEGER,
        tokens_output INTEGER,
        cost_input_usd DECIMAL(10,6),
        cost_output_usd DECIMAL(10,6),
        cost_total_usd DECIMAL(10,6),
        prompt_hash VARCHAR(64),
        response_hash VARCHAR(64),
        tags TEXT[],
        metadata JSONB DEFAULT '{}',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );" "ai_chats" || return 1
    
    # Create indexes for ai_chats
    echo "Creating ai_chats indexes..."
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_request_timestamp ON ai_chats(request_timestamp DESC);" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_provider ON ai_chats(provider);" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_model ON ai_chats(model);" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_prompt_hash ON ai_chats(prompt_hash);" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_metadata ON ai_chats USING GIN(metadata);" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_cost ON ai_chats(cost_total_usd);" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_tags ON ai_chats USING GIN(tags);" "ai_chats" || return 1
    
    # Create text search index for prompts and responses
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_prompt_text ON ai_chats USING GIN(to_tsvector('english', prompt));" "ai_chats" || return 1
    execute_sql "CREATE INDEX IF NOT EXISTS idx_ai_chats_response_text ON ai_chats USING GIN(to_tsvector('english', response));" "ai_chats" || return 1
    
    # Create trigger for updated_at
    execute_sql "
    DO \$\$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_ai_chats_updated_at') THEN
            CREATE TRIGGER update_ai_chats_updated_at 
            BEFORE UPDATE ON ai_chats
            FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
        END IF;
    END
    \$\$;" "ai_chats" || return 1
    
    echo "AI chats schema initialized successfully"
}

# Initialize all schemas
init_all_schemas() {
    create_database || return 1
    init_transcriptions_schema || return 1
    init_ai_chats_schema || return 1
    echo "All schemas initialized successfully"
}

# Setup all schemas (alias for backward compatibility)
setup_all() {
    init_all_schemas
}

# Maintenance operations
perform_maintenance() {
    local db="${1:-$DEFAULT_DB_NAME}"
    echo "Performing database maintenance on '$db'..."
    
    case "$db" in
        "transcriptions")
            # Vacuum and analyze transcription tables
            execute_sql "VACUUM ANALYZE transcriptions;" "$db" || echo "Warning: Failed to vacuum transcriptions table"
            execute_sql "VACUUM ANALYZE transcription_chunks;" "$db" || echo "Warning: Failed to vacuum transcription_chunks table"
            
            # Reindex transcription tables
            execute_sql "REINDEX TABLE transcriptions;" "$db" || echo "Warning: Failed to reindex transcriptions table"
            execute_sql "REINDEX TABLE transcription_chunks;" "$db" || echo "Warning: Failed to reindex transcription_chunks table"
            
            # Clean up orphaned chunks
            execute_sql "DELETE FROM transcription_chunks WHERE transcription_id NOT IN (SELECT id FROM transcriptions);" "$db" || echo "Warning: Failed to clean orphaned chunks"
            ;;
        "ai_chats")
            # Vacuum and analyze ai_chats table
            execute_sql "VACUUM ANALYZE ai_chats;" "$db" || echo "Warning: Failed to vacuum ai_chats table"
            
            # Reindex ai_chats table
            execute_sql "REINDEX TABLE ai_chats;" "$db" || echo "Warning: Failed to reindex ai_chats table"
            ;;
        "postgres")
            # Vacuum and analyze vector table if it exists
            execute_sql "VACUUM ANALYZE second_brain_vectors;" "$db" || echo "Warning: Failed to vacuum second_brain_vectors table (may not exist)"
            execute_sql "REINDEX TABLE second_brain_vectors;" "$db" || echo "Warning: Failed to reindex second_brain_vectors table (may not exist)"
            ;;
        *)
            # Generic maintenance for unknown databases
            echo "Performing generic maintenance on database '$db'..."
            execute_sql "VACUUM ANALYZE;" "$db" || echo "Warning: Failed to vacuum database"
            execute_sql "REINDEX DATABASE $db;" "postgres" || echo "Warning: Failed to reindex database"
            ;;
    esac
    
    echo "Maintenance completed on '$db'"
}

# Database statistics
show_stats() {
    local db="${1:-$DEFAULT_DB_NAME}"
    echo "Database Statistics for '$db':"
    echo "==================="
    
    # Overall database size
    execute_sql "
    SELECT pg_database.datname as database_name,
           pg_size_pretty(pg_database_size(pg_database.datname)) as size
    FROM pg_database
    WHERE datname = '$db';" "postgres" || return 1
    
    echo -e "\nTable Sizes:"
    execute_sql "
    SELECT schemaname || '.' || tablename AS table,
           pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
    FROM pg_tables
    WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;" "$db" || return 1
    
    case "$db" in
        "transcriptions")
            echo -e "\nTranscription Statistics:"
            execute_sql "
            SELECT 
                COUNT(DISTINCT t.id) as total_transcriptions,
                COUNT(tc.id) as total_chunks,
                COALESCE(SUM(tc.character_count), 0) as total_characters
            FROM transcriptions t
            LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id;" "$db" || return 1
            ;;
        "ai_chats")
            echo -e "\nAI Chat Statistics:"
            execute_sql "
            SELECT 
                COUNT(*) as total_chats,
                COUNT(DISTINCT provider) as unique_providers,
                COUNT(DISTINCT model) as unique_models,
                COALESCE(SUM(tokens_input), 0) as total_input_tokens,
                COALESCE(SUM(tokens_output), 0) as total_output_tokens,
                COALESCE(SUM(cost_total_usd), 0) as total_cost_usd
            FROM ai_chats;" "$db" || return 1
            
            echo -e "\nTop Providers:"
            execute_sql "
            SELECT provider, COUNT(*) as chat_count 
            FROM ai_chats 
            GROUP BY provider 
            ORDER BY chat_count DESC 
            LIMIT 5;" "$db" || return 1
            
            echo -e "\nTop Models:"
            execute_sql "
            SELECT model, COUNT(*) as chat_count 
            FROM ai_chats 
            GROUP BY model 
            ORDER BY chat_count DESC 
            LIMIT 5;" "$db" || return 1
            ;;
        "postgres")
            echo -e "\nVector Database Statistics:"
            execute_sql "
            SELECT 
                COUNT(*) as total_vectors,
                COUNT(DISTINCT provider) as unique_providers,
                COUNT(DISTINCT model) as unique_models
            FROM second_brain_vectors;" "$db" 2>/dev/null || echo "No second_brain_vectors table found"
            ;;
        *)
            echo -e "\nGeneric table count:"
            execute_sql "
            SELECT schemaname, tablename, n_tup_ins as inserts, n_tup_upd as updates, n_tup_del as deletes
            FROM pg_stat_user_tables 
            ORDER BY n_tup_ins DESC;" "$db" || return 1
            ;;
    esac
}

# Show statistics for all databases
show_all_stats() {
    echo "PostgreSQL Database Statistics - All Databases"
    echo "=============================================="
    
    # Check which databases exist
    local available_dbs=()
    
    # Check for transcriptions database
    if database_exists "transcriptions"; then
        available_dbs+=("transcriptions")
    fi
    
    # Check for ai_chats database
    if database_exists "ai_chats"; then
        available_dbs+=("ai_chats")
    fi
    
    # Check for postgres database (always exists)
    available_dbs+=("postgres")
    
    echo "Found databases: ${available_dbs[*]}"
    echo ""
    
    # Show stats for each available database
    for db in "${available_dbs[@]}"; do
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        show_stats "$db"
        echo ""
    done
    
    # Overall summary
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "Overall Summary:"
    echo "================"
    
    # Total size across all databases
    execute_sql "
    SELECT 
        COUNT(*) as total_databases,
        pg_size_pretty(SUM(pg_database_size(datname))) as total_size
    FROM pg_database 
    WHERE datname IN ('transcriptions', 'ai_chats', 'postgres');" "postgres" || return 1
    
    echo ""
    echo "Individual database sizes:"
    execute_sql "
    SELECT 
        datname as database,
        pg_size_pretty(pg_database_size(datname)) as size
    FROM pg_database 
    WHERE datname IN ('transcriptions', 'ai_chats', 'postgres')
    ORDER BY pg_database_size(datname) DESC;" "postgres" || return 1
}

# Export data
export_data() {
    local db="${1}"
    local output_file="${2:-${db}_export_$(date +%Y%m%d_%H%M%S).json}"
    
    echo "Exporting data from database '$db' to $output_file..."
    
    case "$db" in
        "transcriptions")
            psql -d "$(get_connection_string "" "" "$db")" -t -A -c "
            SELECT json_agg(row_to_json(t))
            FROM (
                SELECT t.*, 
                       array_agg(
                           json_build_object(
                               'chunk_number', tc.chunk_number,
                               'content', tc.content,
                               'character_count', tc.character_count
                           ) ORDER BY tc.chunk_number
                       ) as chunks
                FROM transcriptions t
                LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id
                GROUP BY t.id
            ) t;" > "$output_file" || {
                echo "Error exporting transcriptions" >&2
                return 1
            }
            ;;
        "ai_chats")
            psql -d "$(get_connection_string "" "" "$db")" -t -A -c "
            SELECT json_agg(row_to_json(t))
            FROM ai_chats t
            ORDER BY request_timestamp;" > "$output_file" || {
                echo "Error exporting ai_chats" >&2
                return 1
            }
            ;;
        "postgres")
            psql -d "$(get_connection_string "" "" "$db")" -t -A -c "
            SELECT json_agg(row_to_json(t))
            FROM second_brain_vectors t;" > "$output_file" 2>/dev/null || {
                echo "Error exporting vectors (table may not exist)" >&2
                return 1
            }
            ;;
        *)
            echo "Error: Export not implemented for database '$db'" >&2
            echo "Supported databases: transcriptions, ai_chats, postgres" >&2
            return 1
            ;;
    esac
    
    echo "Export completed: $output_file"
}

# Archive old data
archive_old_data() {
    local db="${1}"
    local days="${2:-365}"
    local archive_file="${db}_archive_$(date +%Y%m%d_%H%M%S).json"
    
    echo "Archiving data from database '$db' older than $days days..."
    
    case "$db" in
        "transcriptions")
            # First export old transcriptions
            psql -d "$(get_connection_string "" "" "$db")" -t -A -c "
            SELECT json_agg(row_to_json(t))
            FROM (
                SELECT t.*, 
                       array_agg(
                           json_build_object(
                               'chunk_number', tc.chunk_number,
                               'content', tc.content,
                               'character_count', tc.character_count
                           ) ORDER BY tc.chunk_number
                       ) as chunks
                FROM transcriptions t
                LEFT JOIN transcription_chunks tc ON t.id = tc.transcription_id
                WHERE t.created_at < CURRENT_DATE - INTERVAL '$days days'
                GROUP BY t.id
            ) t;" > "$archive_file" || {
                echo "Error archiving transcriptions" >&2
                return 1
            }
            
            # Delete archived transcriptions
            execute_sql "DELETE FROM transcriptions WHERE created_at < CURRENT_DATE - INTERVAL '$days days';" "$db" || {
                echo "Error deleting old transcriptions" >&2
                return 1
            }
            ;;
        "ai_chats")
            # First export old ai_chats
            psql -d "$(get_connection_string "" "" "$db")" -t -A -c "
            SELECT json_agg(row_to_json(t))
            FROM ai_chats t
            WHERE created_at < CURRENT_DATE - INTERVAL '$days days'
            ORDER BY request_timestamp;" > "$archive_file" || {
                echo "Error archiving ai_chats" >&2
                return 1
            }
            
            # Delete archived ai_chats
            execute_sql "DELETE FROM ai_chats WHERE created_at < CURRENT_DATE - INTERVAL '$days days';" "$db" || {
                echo "Error deleting old ai_chats" >&2
                return 1
            }
            ;;
        "postgres")
            echo "Archiving not implemented for postgres database (vectors are typically persistent)"
            return 1
            ;;
        *)
            echo "Error: Archive not implemented for database '$db'" >&2
            echo "Supported databases: transcriptions, ai_chats" >&2
            return 1
            ;;
    esac
    
    echo "Archived to: $archive_file"
}

# Get current host information
get_host_info() {
    local hostname=$(hostname)
    local tailscale_ip=""
    
    # Try to get Tailscale IP
    if command -v tailscale &> /dev/null; then
        tailscale_ip=$(tailscale ip -4 2>/dev/null || echo "")
    fi
    
    echo "${hostname}:${tailscale_ip}"
}

# Check if a host is the current host
is_current_host() {
    local host="$1"
    local current_hostname=$(hostname)
    local current_tailscale_ip=""
    
    # Get current Tailscale IP if available
    if command -v tailscale &> /dev/null; then
        current_tailscale_ip=$(tailscale ip -4 2>/dev/null || echo "")
    fi
    
    # Check if the host matches current hostname
    if [[ "$host" == "$current_hostname" ]] || [[ "$host" == "${current_hostname}."* ]]; then
        return 0
    fi
    
    # Check if the host matches current Tailscale IP
    if [[ -n "$current_tailscale_ip" ]] && [[ "$host" == "$current_tailscale_ip" ]]; then
        return 0
    fi
    
    return 1
}

# Check if a remote host is reachable
check_host_reachable() {
    local host="$1"
    local port="${2:-5432}"
    
    # Use timeout command to prevent hanging
    if timeout 3 bash -c "echo > /dev/tcp/${host}/${port}" 2>/dev/null; then
        return 0
    else
        return 1
    fi
}

# Get table schema information
get_table_info() {
    local db="$1"
    local table="$2"
    
    psql -d "$(get_connection_string "" "" "$db")" -tAc "
    SELECT column_name, data_type, is_nullable 
    FROM information_schema.columns 
    WHERE table_name = '$table' 
    ORDER BY ordinal_position;" 2>/dev/null
}

# Check if table has timestamp columns
table_has_timestamps() {
    local db="$1"
    local table="$2"
    
    local schema_info=$(get_table_info "$db" "$table")
    if echo "$schema_info" | grep -q "timestamp"; then
        return 0
    else
        return 1
    fi
}

# Add timestamps to pgvector table if missing
ensure_vector_table_timestamps() {
    local has_timestamps=$(psql -d "$(get_connection_string "" "" "postgres")" -tAc "
    SELECT COUNT(*) FROM information_schema.columns 
    WHERE table_name = 'second_brain_vectors' 
    AND column_name IN ('created_at', 'updated_at');" 2>/dev/null || echo "0")
    
    if [[ "$has_timestamps" -lt 2 ]]; then
        echo "Adding timestamp columns to second_brain_vectors table..."
        execute_sql "
        ALTER TABLE second_brain_vectors 
        ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP;" "postgres" || {
            echo "Warning: Could not add timestamps to vector table"
        }
    fi
}

# Perform merge-based sync for a single table
merge_sync_table() {
    local source_host="$1"
    local db="$2"
    local table="$3"
    
    echo "      → Syncing table: $table"
    
    # Create temporary table for remote data
    local temp_table="${table}_remote_sync_$$"
    
    # Copy table structure
    execute_sql "CREATE TEMP TABLE $temp_table (LIKE $table INCLUDING ALL);" "$db" >/dev/null 2>&1 || {
        echo "        ✗ Failed to create temporary table"
        return 1
    }
    
    # Copy data from remote host
    if PGPASSWORD="$DEFAULT_DB_PASSWORD" psql \
        -h "$source_host" \
        -p "$DEFAULT_DB_PORT" \
        -U "$DEFAULT_DB_USER" \
        -d "$db" \
        -c "\\COPY $table TO STDOUT" 2>/dev/null | \
        PGPASSWORD="$DEFAULT_DB_PASSWORD" psql \
        -h "$DEFAULT_DB_HOST" \
        -p "$DEFAULT_DB_PORT" \
        -U "$DEFAULT_DB_USER" \
        -d "$db" \
        -c "\\COPY $temp_table FROM STDIN" 2>/dev/null; then
        
        # Perform the merge based on table type
        case "$table" in
            "transcriptions")
                # Merge using UUID and updated_at timestamp
                execute_sql "
                INSERT INTO $table 
                SELECT * FROM $temp_table
                ON CONFLICT (id) DO UPDATE SET
                    filename = EXCLUDED.filename,
                    file_path = EXCLUDED.file_path,
                    file_hash = EXCLUDED.file_hash,
                    transcribed_at = EXCLUDED.transcribed_at,
                    duration_seconds = EXCLUDED.duration_seconds,
                    model_used = EXCLUDED.model_used,
                    language = EXCLUDED.language,
                    metadata = EXCLUDED.metadata,
                    updated_at = GREATEST($table.updated_at, EXCLUDED.updated_at)
                WHERE $table.updated_at < EXCLUDED.updated_at;" "$db" >/dev/null 2>&1
                ;;
            
            "transcription_chunks")
                # Merge chunks - only insert if not exists (they shouldn't change)
                execute_sql "
                INSERT INTO $table 
                SELECT * FROM $temp_table
                ON CONFLICT (transcription_id, chunk_number) DO NOTHING;" "$db" >/dev/null 2>&1
                ;;
            
            "ai_chats")
                # Merge AI chats using UUID and updated_at timestamp
                execute_sql "
                INSERT INTO $table 
                SELECT * FROM $temp_table
                ON CONFLICT (id) DO UPDATE SET
                    prompt = EXCLUDED.prompt,
                    response = EXCLUDED.response,
                    provider = EXCLUDED.provider,
                    model = EXCLUDED.model,
                    request_timestamp = EXCLUDED.request_timestamp,
                    response_timestamp = EXCLUDED.response_timestamp,
                    duration_ms = EXCLUDED.duration_ms,
                    tokens_input = EXCLUDED.tokens_input,
                    tokens_output = EXCLUDED.tokens_output,
                    cost_input_usd = EXCLUDED.cost_input_usd,
                    cost_output_usd = EXCLUDED.cost_output_usd,
                    cost_total_usd = EXCLUDED.cost_total_usd,
                    prompt_hash = EXCLUDED.prompt_hash,
                    response_hash = EXCLUDED.response_hash,
                    tags = EXCLUDED.tags,
                    metadata = EXCLUDED.metadata,
                    updated_at = GREATEST($table.updated_at, EXCLUDED.updated_at)
                WHERE $table.updated_at < EXCLUDED.updated_at;" "$db" >/dev/null 2>&1
                ;;
            
            "second_brain_vectors")
                # For vectors, use file path as key and update if remote is newer
                if table_has_timestamps "$db" "$table"; then
                    execute_sql "
                    INSERT INTO $table 
                    SELECT * FROM $temp_table
                    ON CONFLICT (id) DO UPDATE SET
                        embedding = EXCLUDED.embedding,
                        path = EXCLUDED.path,
                        content_snippet = EXCLUDED.content_snippet,
                        provider = EXCLUDED.provider,
                        model = EXCLUDED.model,
                        metadata = EXCLUDED.metadata,
                        updated_at = GREATEST($table.updated_at, EXCLUDED.updated_at)
                    WHERE $table.updated_at < EXCLUDED.updated_at;" "$db" >/dev/null 2>&1
                else
                    # No timestamps, just insert new records
                    execute_sql "
                    INSERT INTO $table 
                    SELECT * FROM $temp_table
                    ON CONFLICT (id) DO NOTHING;" "$db" >/dev/null 2>&1
                fi
                ;;
            
            *)
                # Generic merge - insert only if not exists
                execute_sql "
                INSERT INTO $table 
                SELECT * FROM $temp_table
                ON CONFLICT DO NOTHING;" "$db" >/dev/null 2>&1
                ;;
        esac
        
        # Drop temporary table
        execute_sql "DROP TABLE IF EXISTS $temp_table;" "$db" >/dev/null 2>&1
        
        echo "        ✓ Merged successfully"
        return 0
    else
        echo "        ✗ Failed to copy data from remote"
        return 1
    fi
}

# Sync databases with remote hosts
sync_databases() {
    echo "Starting database synchronization (merge mode)..."
    echo "Current host: $(get_host_info)"
    echo ""
    
    # Check if any hosts are configured
    if [[ ${#SYNC_HOSTS[@]} -eq 0 ]]; then
        echo "No sync hosts configured. Add hosts to SYNC_HOSTS array in the script."
        return 0
    fi
    
    # Check if any databases are configured
    if [[ ${#SYNC_DATABASES[@]} -eq 0 ]]; then
        echo "No databases configured for sync. Add databases to SYNC_DATABASES array in the script."
        return 0
    fi
    
    # Ensure vector table has timestamps if it exists
    if database_exists "postgres"; then
        ensure_vector_table_timestamps
    fi
    
    local sync_success=0
    local sync_failed=0
    local sync_skipped=0
    
    # Iterate through each configured host
    for host in "${SYNC_HOSTS[@]}"; do
        echo "Processing host: $host"
        
        # Skip if this is the current host
        if is_current_host "$host"; then
            echo "  → Skipping (current host)"
            ((sync_skipped++))
            continue
        fi
        
        # Check if host is reachable
        if ! check_host_reachable "$host"; then
            echo "  → Host unreachable (soft fail)"
            ((sync_skipped++))
            continue
        fi
        
        echo "  → Host is reachable, syncing databases..."
        
        # Sync each configured database
        for db in "${SYNC_DATABASES[@]}"; do
            echo "    Syncing database: $db"
            
            # Ensure database exists locally
            if ! database_exists "$db"; then
                echo "      → Creating local database..."
                if [[ "$db" == "transcriptions" ]]; then
                    create_database
                elif [[ "$db" == "ai_chats" ]]; then
                    init_ai_chats_schema
                else
                    execute_sql "CREATE DATABASE $db" "postgres" >/dev/null 2>&1
                fi
            fi
            
            # Get list of tables to sync based on database
            local tables_to_sync=()
            case "$db" in
                "transcriptions")
                    tables_to_sync=("transcriptions" "transcription_chunks")
                    ;;
                "ai_chats")
                    tables_to_sync=("ai_chats")
                    ;;
                "postgres")
                    # For postgres db, sync the vector table if it exists
                    if psql -d "$(get_connection_string "" "" "$db")" -tAc "SELECT 1 FROM information_schema.tables WHERE table_name='second_brain_vectors'" 2>/dev/null | grep -q 1; then
                        tables_to_sync=("second_brain_vectors")
                    else
                        echo "      → No second_brain_vectors table found, skipping"
                        continue
                    fi
                    ;;
                *)
                    echo "      → Unknown database type, skipping"
                    continue
                    ;;
            esac
            
            # Sync each table
            local db_sync_success=true
            for table in "${tables_to_sync[@]}"; do
                if merge_sync_table "$host" "$db" "$table"; then
                    ((sync_success++))
                else
                    ((sync_failed++))
                    db_sync_success=false
                fi
            done
            
            if [[ "$db_sync_success" == true ]]; then
                echo "      ✓ Database sync completed"
            else
                echo "      ✗ Database sync had errors"
            fi
        done
        
        echo ""
    done
    
    # Print summary
    echo "Synchronization complete:"
    echo "  - Successful syncs: $sync_success"
    echo "  - Failed syncs: $sync_failed"
    echo "  - Skipped operations: $sync_skipped"
    
    # Return non-zero if all operations failed
    if [[ $sync_success -eq 0 ]] && [[ $sync_failed -gt 0 ]]; then
        return 1
    fi
    
    return 0
}

# Usage help
usage() {
    cat << EOF
Usage: $SCRIPT_NAME [OPTIONS] COMMAND

Universal PostgreSQL management script for local dotfiles.
Supports multiple databases: transcriptions, ai_chats, postgres.

COMMANDS:
    setup               Setup database and all schemas (alias for init)
    init                Initialize all schemas (transcriptions + ai_chats)
    init-transcripts    Initialize transcriptions schema only
    init-ai             Initialize ai_chats schema only
    maintain            Perform maintenance operations (vacuum, reindex, cleanup)
    stats               Show database statistics
    export [FILE]       Export data to JSON file
    archive [DAYS]      Archive data older than DAYS (default: 365)
    sync                Sync databases from configured remote hosts
    
OPTIONS:
    -h, --help          Show this help message
    -v, --verbose       Enable verbose output
    -d, --database DB   Specify target database (required for maintain/export/archive)
                        Available: transcriptions, ai_chats, postgres
                        Optional for stats (shows all databases if not specified)
    
ENVIRONMENT VARIABLES:
    LOCAL_DB_HOST             Database host (default: 127.0.0.1)
    LOCAL_DB_PORT             Database port (default: 5432)
    LOCAL_DB_NAME             Database name (default: transcriptions)
    LOCAL_DB_USER             Database user (default: postgres)
    LOCAL_DB_PASSWORD         Database password (default: none)
    
    Backward compatibility (deprecated):
    TRANSCRIPTION_DB_*        Legacy environment variables (still supported)

EXAMPLES:
    # Initial setup
    $SCRIPT_NAME setup
    
    # Perform maintenance on specific databases
    $SCRIPT_NAME --database transcriptions maintain
    $SCRIPT_NAME --database ai_chats maintain
    
    # Show statistics for specific databases
    $SCRIPT_NAME --database transcriptions stats
    $SCRIPT_NAME --database ai_chats stats
    
    # Show statistics for all databases
    $SCRIPT_NAME stats
    
    # Export data from specific databases
    $SCRIPT_NAME --database transcriptions export my_transcriptions.json
    $SCRIPT_NAME --database ai_chats export my_chats.json
    
    # Archive old data from specific databases
    $SCRIPT_NAME --database transcriptions archive 180
    $SCRIPT_NAME --database ai_chats archive 365
    
    # Sync databases from remote hosts
    $SCRIPT_NAME sync
    
SYNC CONFIGURATION:
    Edit SYNC_DATABASES and SYNC_HOSTS arrays at the top of this script
    to configure which databases and hosts to sync with.
EOF
}

# Parse command line arguments
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                usage
                exit 0
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            -d|--database)
                TARGET_DATABASE="$2"
                if [[ -z "$TARGET_DATABASE" ]]; then
                    echo "Error: --database requires a database name" >&2
                    exit 1
                fi
                shift 2
                ;;
            setup|init|init-transcripts|init-ai|maintain|stats|export|archive|sync)
                ACTION="$1"
                shift
                break
                ;;
            *)
                echo "Unknown option: $1" >&2
                usage
                exit 1
                ;;
        esac
    done
    
    # Store remaining arguments
    ARGS=("$@")
}

# Main execution
main() {
    parse_args "$@"
    
    if [[ -z "$ACTION" ]]; then
        echo "Error: No command specified" >&2
        usage
        exit 1
    fi
    
    # Check psql availability
    if ! command -v psql &> /dev/null; then
        echo "Error: psql command not found. Please install PostgreSQL client." >&2
        exit 1
    fi
    
    # Commands that require --database option
    case "$ACTION" in
        maintain|export|archive)
            if [[ -z "$TARGET_DATABASE" ]]; then
                echo "Error: Command '$ACTION' requires --database option" >&2
                echo "Available databases: transcriptions, ai_chats, postgres" >&2
                exit 1
            fi
            ;;
    esac
    
    case "$ACTION" in
        setup)
            setup_all
            ;;
        init)
            init_all_schemas
            ;;
        init-transcripts)
            init_transcriptions_schema
            ;;
        init-ai)
            init_ai_chats_schema
            ;;
        maintain)
            perform_maintenance "$TARGET_DATABASE"
            ;;
        stats)
            if [[ -n "$TARGET_DATABASE" ]]; then
                show_stats "$TARGET_DATABASE"
            else
                show_all_stats
            fi
            ;;
        export)
            export_data "$TARGET_DATABASE" "${ARGS[0]}"
            ;;
        archive)
            archive_old_data "$TARGET_DATABASE" "${ARGS[0]}"
            ;;
        sync)
            sync_databases
            ;;
        *)
            echo "Unknown command: $ACTION" >&2
            usage
            exit 1
            ;;
    esac
}

# Run main function
main "$@"
