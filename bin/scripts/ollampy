#!/usr/bin/python3

from os import environ
from subprocess import run
from sys import argv, exit, stdin, stderr
import argparse
import json
import requests
import sys


# Default configurations for Ollama
DEFAULT_MODEL = "llama3.1:8b"
DEFAULT_ENDPOINT = "http://localhost:11434"

ctr_id: str|None = ""

if ("CONTAINER_ID" in environ):
    ctr_id = environ.get("CONTAINER_ID")

# if we are not in the 'dev' distrobox re-exec the script
# inside of the 'dev' distrobox
if ("dev" != ctr_id):
    cmd: list[str] = [
        "distrobox",
        "enter",
        "dev",
        "--",
        *argv
    ]

    run(cmd)
    exit(0)

# Parse arguments
parser = argparse.ArgumentParser(description="Query Ollama API")
parser.add_argument("--prompt", help="Prompt to prepend to the input")
parser.add_argument("--model", default=DEFAULT_MODEL,
                    help=f"Model to use (default: {DEFAULT_MODEL}). Available models depend on your Ollama installation.")
parser.add_argument("--endpoint", default=DEFAULT_ENDPOINT,
                    help=f"Ollama API endpoint (default: {DEFAULT_ENDPOINT})")
parser.add_argument("--debug", action="store_true", help="Enable debug mode (shows request details)")
args = parser.parse_args()

# Since outside of the distrobox we may not have these modules
# quietly ignore the fact that they may not exist
try:
    # Read from standard input
    query = stdin.read()

    # Prepend prompt if provided
    if args.prompt:
        if query:
            query = f"{args.prompt}\n\n{query}"
        else:
            query = args.prompt

    # Set up API call
    headers = {
        "Content-Type": "application/json"
    }

    # Use the Ollama API endpoint
    url = f"{args.endpoint}/api/chat"

    data = {
        "model": args.model,
        "messages": [
            {
                "role": "user",
                "content": query
            }
        ],
        "stream": True
    }

    # Print debug info if requested
    if args.debug:
        print(f"Debug: API URL: {url}", file=sys.stderr)
        print(f"Debug: Headers: {headers}", file=sys.stderr)
        print(f"Debug: Data: {json.dumps(data)}", file=sys.stderr)

    # Send request to Ollama API with streaming
    response = requests.post(url, headers=headers, json=data, stream=True)

    if response.status_code != 200:
        print(f"Error: {response.status_code}")
        print(response.text)
        exit(1)
    
    # Process the streaming response
    for line in response.iter_lines():
        if line:
            try:
                event = json.loads(line.decode('utf-8'))
                # Extract content from the message
                if "message" in event and "content" in event["message"]:
                    print(event["message"]["content"], end="", flush=True)
                # Handle done message
                if event.get("done", False):
                    break
            except json.JSONDecodeError:
                continue

except (ImportError, Exception) as e:
    print(f"Error: {e}")
    exit(1)