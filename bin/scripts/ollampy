#!/usr/bin/python3

from os import environ
from subprocess import run
from sys import argv, exit, stdin, stderr
import argparse
import json
import requests
import sys


# Default configurations for Ollama
DEFAULT_ENDPOINT: str|None = ""
DEFAULT_MODEL: str|None = ""

if ("OLLAMPY_ENDPOINT" in environ):
    DEFAULT_ENDPOINT = environ.get("OLLAMPY_ENDPOINT")
else:
    DEFAULT_ENDPOINT = "http://localhost:11434"

if ("OLLAMPY_MODEL" in environ): 
    DEFAULT_MODEL = environ.get("OLLAMPY_MODEL")
else:
    DEFAULT_MODEL = "gemma3:4b"

# Container check
ctr_id: str|None = ""

if ("CONTAINER_ID" in environ):
    ctr_id = environ.get("CONTAINER_ID")

# if we are not in the 'dev' distrobox re-exec the script
# inside of the 'dev' distrobox
if ("dev" != ctr_id):
    cmd: list[str] = [
        "distrobox",
        "enter",
        "dev",
        "--",
        *argv
    ]

    run(cmd)
    exit(0)

# Parse arguments
parser = argparse.ArgumentParser(description="Query Ollama API")
parser.add_argument("--prompt", help="Prompt to prepend to the input")
parser.add_argument("--model", default=DEFAULT_MODEL,
                    help=f"Model to use (default: {DEFAULT_MODEL}). Available models depend on your Ollama installation.")
parser.add_argument("--endpoint", default=DEFAULT_ENDPOINT,
                    help=f"Ollama API endpoint (default: {DEFAULT_ENDPOINT})")
parser.add_argument("--debug", action="store_true", help="Enable debug mode (shows request details)")
parser.add_argument("--json", action="store_true", help="Return a clean JSON response without streaming")
parser.add_argument("-S", "--no-streaming", action="store_true", help="Disable streaming mode for cleaner output capture")
parser.add_argument("--embedding", action="store_true", help="Generate an embedding vector instead of a text response")
parser.add_argument("-f", "--file", action="append", dest="files",
                    help="Include file content in the context (can be specified multiple times)")
args = parser.parse_args()

# Since outside of the distrobox we may not have these modules
# quietly ignore the fact that they may not exist
try:
    # Read file contents if any files were specified
    file_contents = []
    if args.files:
        for file_path in args.files:
            try:
                with open(file_path, 'r') as f:
                    file_content = f.read()
                    file_contents.append(f"=== File: {file_path} ===\n{file_content}\n")
            except IOError as e:
                print(f"Warning: Could not read file {file_path}: {e}", file=stderr)
    
    # Read from standard input
    query = stdin.read()

    # Combine file contents with query
    combined_parts = []
    
    # Add file contents first if any
    if file_contents:
        combined_parts.extend(file_contents)
    
    # Add prompt if provided
    if args.prompt:
        combined_parts.append(args.prompt)
    
    # Add stdin content if any
    if query:
        combined_parts.append(query)
    
    # Combine all parts
    if combined_parts:
        query = "\n".join(combined_parts)
    else:
        query = ""

    # Set up API call
    headers = {
        "Content-Type": "application/json"
    }

    # Set the API endpoint based on the request type
    if args.embedding:
        # Use the embeddings endpoint for Ollama
        url = f"{args.endpoint}/api/embeddings"
        
        # For embeddings, we use a different request format
        data = {
            "model": args.model,
            "prompt": query  # Ollama uses "prompt" instead of "input" for embeddings
        }
    else:
        # Use the chat endpoint for regular requests
        url = f"{args.endpoint}/api/chat"
        
        data = {
            "model": args.model,
            "messages": [
                {
                    "role": "user",
                    "content": query
                }
            ],
            # Only stream if not in JSON mode or --no-streaming
            "stream": not (args.json or args.no_streaming)
        }

    # Print debug info if requested
    if args.debug:
        print(f"Debug: API URL: {url}", file=sys.stderr)
        print(f"Debug: Headers: {headers}", file=sys.stderr)
        print(f"Debug: Data: {json.dumps(data)}", file=sys.stderr)

    # Send request to Ollama API (streaming only if needed)
    response = requests.post(url, headers=headers, json=data, stream=data.get("stream", False))

    if response.status_code != 200:
        print(f"Error: {response.status_code}")
        print(response.text)
        exit(1)
    
    # Handle the response based on request type
    if args.embedding:
        # Process embeddings response (never streamed)
        response_data = response.json()
        if "embedding" in response_data:
            # Format the embedding as expected by semantic_search
            print(json.dumps({"embedding": response_data["embedding"]}))
        else:
            print(json.dumps(response_data))
    elif args.json or args.no_streaming:
        # Process standard JSON response (not streamed)
        response_data = response.json()
        if "message" in response_data and "content" in response_data["message"]:
            # Just return the content without any JSON formatting
            print(response_data["message"]["content"])
        else:
            # Just print the raw response as fallback
            if args.json:
                print(json.dumps(response_data))
            else:
                print(f"Unexpected response format: {json.dumps(response_data)}", file=sys.stderr)
    else:
        # Process the streaming response
        for line in response.iter_lines():
            if line:
                try:
                    event = json.loads(line.decode('utf-8'))
                    # Extract content from the message
                    if "message" in event and "content" in event["message"]:
                        print(event["message"]["content"], end="", flush=True)
                    # Handle done message
                    if event.get("done", False):
                        break
                except json.JSONDecodeError:
                    continue

except (ImportError, Exception) as e:
    print(f"Error: {e}")
    exit(1)
