#!/usr/bin/python3

from os import environ
from subprocess import run
from sys import argv, exit, stdin, stderr
import argparse
import json
import requests
import sys
import os
import base64
import mimetypes


# Default configurations for Ollama
DEFAULT_ENDPOINT: str|None = ""
DEFAULT_MODEL: str|None = ""

if ("OLLAMPY_ENDPOINT" in environ):
    DEFAULT_ENDPOINT = environ.get("OLLAMPY_ENDPOINT")
else:
    DEFAULT_ENDPOINT = "http://localhost:11434"

if ("OLLAMPY_MODEL" in environ): 
    DEFAULT_MODEL = environ.get("OLLAMPY_MODEL")
else:
    DEFAULT_MODEL = "gemma3:12b"

# Container check
ctr_id: str|None = ""

if ("CONTAINER_ID" in environ):
    ctr_id = environ.get("CONTAINER_ID")

# if we are not in the 'dev' distrobox re-exec the script
# inside of the 'dev' distrobox
if ("dev" != ctr_id):
    cmd: list[str] = [
        "distrobox",
        "enter",
        "dev",
        "--",
        *argv
    ]

    run(cmd)
    exit(0)

# Parse arguments
parser = argparse.ArgumentParser(description="Query Ollama API")
parser.add_argument("--prompt", help="Prompt to prepend to the input")
parser.add_argument("--model", default=DEFAULT_MODEL,
                    help=f"Model to use (default: {DEFAULT_MODEL}). Available models depend on your Ollama installation.")
parser.add_argument("--endpoint", default=DEFAULT_ENDPOINT,
                    help=f"Ollama API endpoint (default: {DEFAULT_ENDPOINT})")
parser.add_argument("--debug", action="store_true", help="Enable debug mode (shows request details)")
parser.add_argument("--json", action="store_true", help="Return a clean JSON response without streaming")
parser.add_argument("-S", "--no-streaming", action="store_true", help="Disable streaming mode for cleaner output capture")
parser.add_argument("--embedding", action="store_true", help="Generate an embedding vector instead of a text response")
parser.add_argument("-f", "--file", action="append", dest="files",
                    help="Include file content in the context (can be specified multiple times)")
parser.add_argument("-L", "--list-models", action="store_true",
                    help="List available models from the Ollama server")
parser.add_argument("--no-color", action="store_true",
                    help="Disable colored output")
parser.add_argument("--image-gen", action="store_true",
                    help="Generate an image instead of text response")
parser.add_argument("--output", help="Output filename for image generation (default: auto-numbered output-NNNN.png)")
parser.add_argument("--image", action="append", dest="images",
                    help="Include image file(s) for vision analysis (can be specified multiple times)")
args = parser.parse_args()

def get_auto_numbered_filename(base_name="output", extension=".png"):
    """Generate an auto-numbered filename that doesn't exist yet."""
    counter = 0
    while True:
        filename = f"{base_name}-{counter:04d}{extension}"
        if not os.path.exists(filename):
            return filename
        counter += 1

def encode_image_to_base64(image_path):
    """Encode an image file to base64 for Ollama API."""
    try:
        with open(image_path, 'rb') as image_file:
            image_data = image_file.read()
            encoded_string = base64.b64encode(image_data).decode('utf-8')
            return encoded_string
    except Exception as e:
        print(f"Error reading image {image_path}: {e}", file=sys.stderr)
        exit(1)

# Since outside of the distrobox we may not have these modules
# quietly ignore the fact that they may not exist
try:
    # Handle list-models option first
    if args.list_models:
        # Check if colors should be disabled
        use_colors = not args.no_color and environ.get("NO_COLOR", "").lower() not in ("1", "true")
        
        # Fetch available models from the Ollama API
        url = f"{args.endpoint}/api/tags"
        
        if args.debug:
            print(f"Debug: Listing models from {url}", file=sys.stderr)
        
        try:
            response = requests.get(url)
            if response.status_code != 200:
                print(f"Error fetching models: {response.status_code}", file=sys.stderr)
                print(response.text, file=sys.stderr)
                exit(1)
            
            models_data = response.json()
            if "models" in models_data:
                # ANSI color codes (conditionally set based on use_colors)
                class Colors:
                    HEADER = '\033[95m' if use_colors else ''
                    BLUE = '\033[94m' if use_colors else ''
                    CYAN = '\033[96m' if use_colors else ''
                    GREEN = '\033[92m' if use_colors else ''
                    YELLOW = '\033[93m' if use_colors else ''
                    RED = '\033[91m' if use_colors else ''
                    BOLD = '\033[1m' if use_colors else ''
                    UNDERLINE = '\033[4m' if use_colors else ''
                    END = '\033[0m' if use_colors else ''
                
                # Prepare data for table
                table_data = []
                for model in models_data["models"]:
                    name = model.get("name", "Unknown")
                    size = model.get("size", 0)
                    modified = model.get("modified_at", "Unknown")
                    
                    # Format size in human-readable format
                    if size > 0:
                        if size >= 1024**3:  # GB
                            size_str = f"{size / (1024**3):.1f}GB"
                        elif size >= 1024**2:  # MB
                            size_str = f"{size / (1024**2):.1f}MB"
                        else:  # Bytes
                            size_str = f"{size}B"
                    else:
                        size_str = "Unknown"
                    
                    # Format modified date
                    if modified != "Unknown":
                        try:
                            from datetime import datetime
                            # Parse ISO format and display human-readable
                            dt = datetime.fromisoformat(modified.replace('Z', '+00:00'))
                            modified_str = dt.strftime("%Y-%m-%d %H:%M")
                        except:
                            modified_str = modified
                    else:
                        modified_str = "Unknown"
                    
                    table_data.append([name, size_str, modified_str])
                
                # Calculate column widths
                if table_data:
                    max_name = max(len(row[0]) for row in table_data)
                    max_size = max(len(row[1]) for row in table_data)
                    max_date = max(len(row[2]) for row in table_data)
                    
                    # Ensure minimum widths
                    max_name = max(max_name, len("Model Name"))
                    max_size = max(max_size, len("Size"))
                    max_date = max(max_date, len("Modified"))
                    
                    # Print header
                    print(f"\n{Colors.BOLD}{Colors.CYAN}Available Ollama Models:{Colors.END}")
                    print(f"{Colors.BOLD}{'─' * (max_name + max_size + max_date + 6)}{Colors.END}")
                    
                    # Print table header
                    print(f"{Colors.BOLD}{Colors.HEADER}{'Model Name':<{max_name}} {'Size':<{max_size}} {'Modified':<{max_date}}{Colors.END}")
                    print(f"{Colors.BOLD}{'─' * max_name} {'─' * max_size} {'─' * max_date}{Colors.END}")
                    
                    # Print table rows
                    for i, (name, size_str, modified_str) in enumerate(table_data):
                        # Alternate row colors
                        color = Colors.CYAN if i % 2 == 0 else Colors.BLUE
                        size_color = Colors.GREEN if size_str != "Unknown" else Colors.YELLOW
                        date_color = Colors.GREEN if modified_str != "Unknown" else Colors.YELLOW
                        
                        print(f"{color}{name:<{max_name}}{Colors.END} "
                              f"{size_color}{size_str:<{max_size}}{Colors.END} "
                              f"{date_color}{modified_str:<{max_date}}{Colors.END}")
                    
                    print(f"{Colors.BOLD}{'─' * (max_name + max_size + max_date + 6)}{Colors.END}")
                    print(f"{Colors.BOLD}Total models: {Colors.GREEN}{len(table_data)}{Colors.END}\n")
                else:
                    print(f"{Colors.YELLOW}No models found{Colors.END}")
            else:
                print("No models found or unexpected response format")
                if args.debug:
                    print(f"Debug: Response: {json.dumps(models_data)}", file=sys.stderr)
            
        except requests.RequestException as e:
            print(f"Error connecting to Ollama server: {e}", file=sys.stderr)
            exit(1)
        
        exit(0)
    
    # Read file contents if any files were specified
    file_contents = []
    if args.files:
        for file_path in args.files:
            try:
                with open(file_path, 'r') as f:
                    file_content = f.read()
                    file_contents.append(f"=== File: {file_path} ===\n{file_content}\n")
            except IOError as e:
                print(f"Warning: Could not read file {file_path}: {e}", file=stderr)
    
    # Read from standard input
    query = stdin.read()

    # Combine file contents with query
    combined_parts = []
    
    # Add file contents first if any
    if file_contents:
        combined_parts.extend(file_contents)
    
    # Add prompt if provided
    if args.prompt:
        combined_parts.append(args.prompt)
    
    # Add stdin content if any
    if query:
        combined_parts.append(query)
    
    # Combine all parts
    if combined_parts:
        query = "\n".join(combined_parts)
    else:
        query = ""

    # Set up API call
    headers = {
        "Content-Type": "application/json"
    }

    # Set the API endpoint based on the request type
    if args.embedding:
        # Use the embeddings endpoint for Ollama
        url = f"{args.endpoint}/api/embeddings"
        
        # For embeddings, we use a different request format
        data = {
            "model": args.model,
            "prompt": query  # Ollama uses "prompt" instead of "input" for embeddings
        }
    elif args.image_gen:
        # Use the generate endpoint for image generation
        url = f"{args.endpoint}/api/generate"
        
        # For image generation, we use the generate endpoint with a special prompt
        data = {
            "model": args.model,
            "prompt": f"Generate an image: {query}",
            "stream": False,
            "images": True  # Request image output
        }
    else:
        # Use the chat endpoint for regular requests
        url = f"{args.endpoint}/api/chat"
        
        # Construct message content
        message_content = query
        images_list = []
        
        # Add image content if provided
        if args.images:
            for image_path in args.images:
                if not os.path.exists(image_path):
                    print(f"Error: Image file not found: {image_path}", file=sys.stderr)
                    exit(1)
                
                image_data = encode_image_to_base64(image_path)
                images_list.append(image_data)
        
        # Build the message
        message = {
            "role": "user",
            "content": message_content
        }
        
        # Add images if any
        if images_list:
            message["images"] = images_list
        
        data = {
            "model": args.model,
            "messages": [message],
            # Only stream if not in JSON mode or --no-streaming
            "stream": not (args.json or args.no_streaming)
        }

    # Print debug info if requested
    if args.debug:
        print(f"Debug: API URL: {url}", file=sys.stderr)
        print(f"Debug: Headers: {headers}", file=sys.stderr)
        print(f"Debug: Data: {json.dumps(data)}", file=sys.stderr)
        if args.image_gen:
            output_file = args.output if args.output else get_auto_numbered_filename()
            print(f"Debug: Image will be saved to: {output_file}", file=sys.stderr)
            print(f"Debug: Note - Image generation support depends on the selected model", file=sys.stderr)
        if args.images:
            print(f"Debug: Processing {len(args.images)} image(s): {', '.join(args.images)}", file=sys.stderr)
            print(f"Debug: Note - Vision support depends on the selected model", file=sys.stderr)

    # Send request to Ollama API (streaming only if needed)
    response = requests.post(url, headers=headers, json=data, stream=data.get("stream", False))

    if response.status_code != 200:
        print(f"Error: {response.status_code}")
        print(response.text)
        exit(1)
    
    # Handle the response based on request type
    if args.embedding:
        # Process embeddings response (never streamed)
        response_data = response.json()
        if "embedding" in response_data:
            # Format the embedding as expected by semantic_search
            print(json.dumps({"embedding": response_data["embedding"]}))
        else:
            print(json.dumps(response_data))
    elif args.image_gen:
        # Process image generation response
        response_data = response.json()
        if "images" in response_data and len(response_data["images"]) > 0:
            # Get the base64 image data (Ollama returns images as base64)
            image_data = response_data["images"][0]
            
            # Determine output filename
            if args.output:
                output_filename = args.output
            else:
                output_filename = get_auto_numbered_filename()
            
            # Decode and save the image
            try:
                image_bytes = base64.b64decode(image_data)
                with open(output_filename, 'wb') as f:
                    f.write(image_bytes)
                print(f"Image saved to: {output_filename}")
            except Exception as e:
                print(f"Error saving image: {e}", file=sys.stderr)
                exit(1)
        else:
            # Check if the model supports image generation
            if "error" in response_data:
                error_msg = response_data["error"]
                if "not found" in error_msg.lower() or "unsupported" in error_msg.lower():
                    print(f"Error: Model '{args.model}' does not support image generation.", file=sys.stderr)
                    print("Try using a model that supports image generation (e.g., dall-e, stable-diffusion variants)", file=sys.stderr)
                else:
                    print(f"Error: {error_msg}", file=sys.stderr)
            else:
                print(f"Error: No image data in response: {json.dumps(response_data)}", file=sys.stderr)
            exit(1)
    elif args.json or args.no_streaming:
        # Process standard JSON response (not streamed)
        response_data = response.json()
        if "message" in response_data and "content" in response_data["message"]:
            # Just return the content without any JSON formatting
            print(response_data["message"]["content"])
        else:
            # Just print the raw response as fallback
            if args.json:
                print(json.dumps(response_data))
            else:
                print(f"Unexpected response format: {json.dumps(response_data)}", file=sys.stderr)
    else:
        # Process the streaming response
        for line in response.iter_lines():
            if line:
                try:
                    event = json.loads(line.decode('utf-8'))
                    # Extract content from the message
                    if "message" in event and "content" in event["message"]:
                        print(event["message"]["content"], end="", flush=True)
                    # Handle done message
                    if event.get("done", False):
                        break
                except json.JSONDecodeError:
                    continue

except (ImportError, Exception) as e:
    print(f"Error: {e}")
    exit(1)
