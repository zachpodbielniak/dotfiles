#!/usr/bin/python3

# dotfiles - Personal configuration files and scripts
# Copyright (C) 2026  Zach Podbielniak
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.


import os
import sys
import subprocess

# Container check for distrobox - do this BEFORE any other imports
ctr_id: str = os.environ.get("CONTAINER_ID", "")
no_dbox_check: bool = os.environ.get("NO_DBOX_CHECK", "").lower() in ("1", "true")
if not no_dbox_check and ctr_id != "dev":
    cmd: list[str] = ["distrobox", "enter", "dev", "--", *sys.argv]
    subprocess.run(cmd)
    sys.exit(0)

# Standard library imports
import argparse
import asyncio
import json
import tempfile
import shutil
from datetime import datetime, date, timezone
from typing import Optional

# Third-party imports - may not be available outside dev container
try:
    import asyncpg
except ImportError as e:
    if ctr_id == "dev":
        print(f"Error: asyncpg is required but not installed", file=sys.stderr)
        print("Please install with: pip install asyncpg", file=sys.stderr)
    sys.exit(1)

try:
    import yaml
except ImportError:
    yaml = None


# =============================================================================
# Configuration
# =============================================================================

DB_CONFIG: dict[str, str | int] = {
    "host": os.environ.get("AGENT_MEMORIES_DB_HOST", "127.0.0.1"),
    "port": int(os.environ.get("AGENT_MEMORIES_DB_PORT", "5432")),
    "database": os.environ.get("AGENT_MEMORIES_DB_NAME", "agent_memories"),
    "user": os.environ.get("AGENT_MEMORIES_DB_USER", "postgres"),
    "password": os.environ.get("AGENT_MEMORIES_DB_PASSWORD", ""),
}

CATEGORIES: list[str] = [
    "general", "decision", "preference", "fact", "project",
    "learning", "insight", "todo", "relationship", "technical",
    "workflow", "debug", "research", "config", "personal",
]

IMPORTANCE_LEVELS: list[str] = ["low", "normal", "high", "critical"]

DEFAULT_COLUMNS: list[str] = [
    "id", "category", "importance", "summary", "tags", "created_at",
]

ALL_COLUMNS: list[str] = [
    "id", "content", "summary", "category", "subcategory", "importance",
    "source", "source_context", "conversation_id", "tags", "related_to",
    "is_archived", "is_pinned", "last_accessed_at", "access_count",
    "metadata", "created_at", "updated_at",
]

# ANSI color helpers
NO_COLOR: bool = os.environ.get("NO_COLOR", "") != ""


def _c(code: str, text: str) -> str:
    """Apply ANSI color code to text, respecting NO_COLOR."""
    if NO_COLOR:
        return text
    return f"\033[{code}m{text}\033[0m"


def _green(text: str) -> str:
    return _c("32", text)


def _red(text: str) -> str:
    return _c("31", text)


def _yellow(text: str) -> str:
    return _c("33", text)


def _cyan(text: str) -> str:
    return _c("36", text)


def _bold(text: str) -> str:
    return _c("1", text)


def _dim(text: str) -> str:
    return _c("2", text)


# =============================================================================
# MemoryManager - async database interface
# =============================================================================

class MemoryManager:
    """
    Async interface to the agent_memories PostgreSQL database.

    Provides full CRUD operations, search, fzf integration, and
    reporting on stored memories. Uses asyncpg for non-blocking I/O.
    """

    def __init__(self):
        self.pool: Optional[asyncpg.Pool] = None

    async def init_db(self) -> None:
        """Create the asyncpg connection pool."""
        dsn: str = (
            f"postgresql://{DB_CONFIG['user']}"
            f":{DB_CONFIG['password']}"
            f"@{DB_CONFIG['host']}"
            f":{DB_CONFIG['port']}"
            f"/{DB_CONFIG['database']}"
        )
        try:
            self.pool = await asyncpg.create_pool(dsn, min_size=1, max_size=5)
        except Exception as e:
            print(_red(f"Database connection failed: {e}"), file=sys.stderr)
            print("Run 'local_postgres init-agent-memories' to initialize the database.", file=sys.stderr)
            sys.exit(1)

    async def close_db(self) -> None:
        """Close the connection pool."""
        if self.pool:
            await self.pool.close()

    # -------------------------------------------------------------------------
    # UUID resolution
    # -------------------------------------------------------------------------

    async def _resolve_uuid(self, prefix: str) -> Optional[str]:
        """
        Resolve a short UUID prefix to a full UUID.

        Args:
            prefix: First N characters of a UUID

        Returns:
            Full UUID string or None if not found / ambiguous
        """
        rows = await self.pool.fetch(
            "SELECT id FROM memories WHERE id::text LIKE $1 || '%'",
            prefix,
        )
        if len(rows) == 1:
            return str(rows[0]["id"])
        if len(rows) > 1:
            print(_yellow(f"Ambiguous ID prefix '{prefix}' — matches {len(rows)} memories"), file=sys.stderr)
        return None

    # -------------------------------------------------------------------------
    # CRUD operations
    # -------------------------------------------------------------------------

    async def add_memory(
        self,
        content: str,
        summary: Optional[str] = None,
        category: str = "general",
        subcategory: Optional[str] = None,
        importance: str = "normal",
        source: Optional[str] = None,
        source_context: Optional[str] = None,
        conversation_id: Optional[str] = None,
        tags: Optional[list[str]] = None,
        related_to: Optional[str] = None,
        pinned: bool = False,
        metadata: Optional[dict] = None,
    ) -> str:
        """
        Store a new memory in the database.

        Args:
            content: The full memory content text
            summary: Short one-line summary (auto-truncated from content if omitted)
            category: Memory category (default: general)
            subcategory: Optional subcategory for finer classification
            importance: low / normal / high / critical
            source: Where this memory came from (e.g., "conversation", "heartbeat", "research")
            source_context: Additional context about the source
            conversation_id: Link to a specific conversation
            tags: List of tags for categorization
            related_to: UUID of a related memory
            pinned: Whether to pin this memory
            metadata: Arbitrary JSON metadata

        Returns:
            UUID of the new memory
        """
        if summary is None:
            summary = content[:200].split("\n")[0]

        related_uuid = None
        if related_to:
            related_uuid = await self._resolve_uuid(related_to)
            if not related_uuid:
                print(_yellow(f"Warning: related memory '{related_to}' not found, ignoring"), file=sys.stderr)

        row = await self.pool.fetchrow(
            """
            INSERT INTO memories (
                content, summary, category, subcategory, importance,
                source, source_context, conversation_id,
                tags, related_to, is_pinned, metadata
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
            RETURNING id
            """,
            content,
            summary,
            category,
            subcategory,
            importance,
            source,
            source_context,
            conversation_id,
            tags or [],
            related_uuid,
            pinned,
            json.dumps(metadata or {}),
        )
        return str(row["id"])

    async def get_memory(self, memory_id: str) -> Optional[dict]:
        """
        Fetch a single memory by ID (prefix or full UUID).

        Also increments the access_count and updates last_accessed_at.

        Args:
            memory_id: Full UUID or prefix

        Returns:
            Memory record as dict, or None
        """
        full_id: Optional[str] = await self._resolve_uuid(memory_id)
        if not full_id:
            return None

        # Touch access tracking
        await self.pool.execute(
            """
            UPDATE memories
            SET access_count = access_count + 1,
                last_accessed_at = CURRENT_TIMESTAMP
            WHERE id = $1
            """,
            full_id,
        )

        row = await self.pool.fetchrow(
            "SELECT * FROM memories WHERE id = $1", full_id
        )
        return dict(row) if row else None

    async def update_memory(self, memory_id: str, **kwargs) -> bool:
        """
        Update fields on an existing memory.

        Args:
            memory_id: Full UUID or prefix
            **kwargs: Field names and new values to set

        Returns:
            True if the update succeeded
        """
        full_id: Optional[str] = await self._resolve_uuid(memory_id)
        if not full_id:
            return False

        allowed: set[str] = {
            "content", "summary", "category", "subcategory", "importance",
            "source", "source_context", "conversation_id", "tags",
            "is_archived", "is_pinned", "metadata",
        }

        sets: list[str] = []
        vals: list = []
        idx: int = 2  # $1 is the id

        for key, val in kwargs.items():
            if key not in allowed:
                continue
            if key == "metadata" and isinstance(val, dict):
                val = json.dumps(val)
            sets.append(f"{key} = ${idx}")
            vals.append(val)
            idx += 1

        if not sets:
            return False

        query: str = f"UPDATE memories SET {', '.join(sets)} WHERE id = $1"
        await self.pool.execute(query, full_id, *vals)
        return True

    async def delete_memory(self, memory_id: str) -> bool:
        """
        Permanently delete a memory.

        Args:
            memory_id: Full UUID or prefix

        Returns:
            True if a row was deleted
        """
        full_id: Optional[str] = await self._resolve_uuid(memory_id)
        if not full_id:
            return False

        # Clear any related_to references pointing to this memory
        await self.pool.execute(
            "UPDATE memories SET related_to = NULL WHERE related_to = $1",
            full_id,
        )
        result: str = await self.pool.execute(
            "DELETE FROM memories WHERE id = $1", full_id
        )
        return result == "DELETE 1"

    # -------------------------------------------------------------------------
    # Listing and searching
    # -------------------------------------------------------------------------

    async def list_memories(
        self,
        category: Optional[str] = None,
        subcategory: Optional[str] = None,
        importance: Optional[str] = None,
        tag: Optional[list[str]] = None,
        source: Optional[str] = None,
        pinned: Optional[bool] = None,
        include_archived: bool = False,
        only_archived: bool = False,
        limit: int = 50,
        offset: int = 0,
        order_by: str = "created_at",
        descending: bool = True,
    ) -> list[dict]:
        """
        List memories with filtering and pagination.

        Args:
            category: Filter by category
            subcategory: Filter by subcategory
            importance: Filter by importance level
            tag: Filter by tags (all must match)
            source: Filter by source
            pinned: Filter by pinned status
            include_archived: Include archived memories
            only_archived: Show only archived memories
            limit: Max results (default 50)
            offset: Pagination offset
            order_by: Sort column
            descending: Sort direction

        Returns:
            List of memory dicts
        """
        conditions: list[str] = []
        params: list = []
        idx: int = 1

        if only_archived:
            conditions.append("is_archived = TRUE")
        elif not include_archived:
            conditions.append("is_archived = FALSE")

        if category:
            conditions.append(f"category = ${idx}")
            params.append(category)
            idx += 1

        if subcategory:
            conditions.append(f"subcategory = ${idx}")
            params.append(subcategory)
            idx += 1

        if importance:
            conditions.append(f"importance = ${idx}")
            params.append(importance)
            idx += 1

        if tag:
            conditions.append(f"tags @> ${idx}")
            params.append(tag)
            idx += 1

        if source:
            conditions.append(f"source = ${idx}")
            params.append(source)
            idx += 1

        if pinned is not None:
            conditions.append(f"is_pinned = ${idx}")
            params.append(pinned)
            idx += 1

        where: str = " AND ".join(conditions) if conditions else "TRUE"
        direction: str = "DESC" if descending else "ASC"

        # Validate order_by against known columns
        if order_by not in ALL_COLUMNS:
            order_by = "created_at"

        query: str = f"""
            SELECT * FROM memories
            WHERE {where}
            ORDER BY {order_by} {direction}
            LIMIT ${idx} OFFSET ${idx + 1}
        """
        params.extend([limit, offset])

        rows = await self.pool.fetch(query, *params)
        return [dict(r) for r in rows]

    async def search_memories(
        self,
        query: str,
        category: Optional[str] = None,
        include_archived: bool = False,
        limit: int = 25,
        exact: bool = False,
    ) -> list[dict]:
        """
        Hybrid search across memory content, summary, and tags.

        Default mode (fuzzy): Uses pg_trgm similarity for fuzzy matching
        with ILIKE fallback, plus tag search. Tolerates typos and partial
        matches. Results ranked by trigram similarity score.

        Exact mode (--exact): Uses PostgreSQL tsvector full-text search
        with stemming and boolean queries. Supports operators:
          - 'python async'  -> matches both terms (AND)
          - 'python | rust'  -> matches either term (OR)
          - '!docker'        -> excludes term (NOT)
          - 'deploy:*'       -> prefix match

        Args:
            query: Search string (plain text or tsquery operators in exact mode)
            category: Optional category filter
            include_archived: Include archived memories
            limit: Max results
            exact: Use tsvector full-text search instead of fuzzy trgm

        Returns:
            List of matching memory dicts, ranked by relevance
        """
        conditions: list[str] = []
        params: list = []
        idx: int = 1

        if exact:
            # tsvector full-text search with stemming and boolean operators
            conditions.append(f"search_vector @@ websearch_to_tsquery('english', ${idx})")
            rank_expr: str = f"ts_rank_cd(search_vector, websearch_to_tsquery('english', ${idx}))"
            params.append(query)
            idx += 1
        else:
            # Hybrid: pg_trgm fuzzy similarity + ILIKE fallback + tag search
            # $idx = ILIKE pattern, $idx+1 = raw query for similarity()
            like_idx: int = idx
            sim_idx: int = idx + 1
            search_pattern: str = f"%{query}%"
            conditions.append(
                f"(content ILIKE ${like_idx} OR summary ILIKE ${like_idx} "
                f"OR array_to_string(tags, ' ') ILIKE ${like_idx})"
            )
            params.append(search_pattern)
            # Rank by trigram similarity (best match across content/summary)
            rank_expr = (
                f"GREATEST("
                f"  COALESCE(similarity(summary, ${sim_idx}), 0) * 2.0,"
                f"  COALESCE(similarity(content, ${sim_idx}), 0),"
                f"  COALESCE(similarity(array_to_string(tags, ' '), ${sim_idx}), 0) * 1.5"
                f")"
            )
            params.append(query)
            idx += 2

        if not include_archived:
            conditions.append("is_archived = FALSE")

        if category:
            conditions.append(f"category = ${idx}")
            params.append(category)
            idx += 1

        where: str = " AND ".join(conditions)
        params.append(limit)

        sql: str = f"""
            SELECT *, {rank_expr} as relevance
            FROM memories
            WHERE {where}
            ORDER BY is_pinned DESC, relevance DESC, created_at DESC
            LIMIT ${idx}
        """

        rows = await self.pool.fetch(sql, *params)
        return [dict(r) for r in rows]

    async def get_stats(self) -> dict:
        """
        Get aggregate statistics about the memory store.

        Returns:
            Dict with counts by category, importance, totals, etc.
        """
        total = await self.pool.fetchval("SELECT COUNT(*) FROM memories")
        archived = await self.pool.fetchval(
            "SELECT COUNT(*) FROM memories WHERE is_archived = TRUE"
        )
        pinned = await self.pool.fetchval(
            "SELECT COUNT(*) FROM memories WHERE is_pinned = TRUE"
        )

        by_category = await self.pool.fetch(
            "SELECT category, COUNT(*) as count FROM memories "
            "WHERE is_archived = FALSE GROUP BY category ORDER BY count DESC"
        )
        by_importance = await self.pool.fetch(
            "SELECT importance, COUNT(*) as count FROM memories "
            "WHERE is_archived = FALSE GROUP BY importance ORDER BY count DESC"
        )

        top_tags = await self.pool.fetch(
            "SELECT unnest(tags) as tag, COUNT(*) as count FROM memories "
            "WHERE is_archived = FALSE GROUP BY tag ORDER BY count DESC LIMIT 20"
        )

        most_accessed = await self.pool.fetch(
            "SELECT id, summary, access_count FROM memories "
            "WHERE access_count > 0 ORDER BY access_count DESC LIMIT 10"
        )

        return {
            "total": total,
            "active": total - archived,
            "archived": archived,
            "pinned": pinned,
            "by_category": [dict(r) for r in by_category],
            "by_importance": [dict(r) for r in by_importance],
            "top_tags": [dict(r) for r in top_tags],
            "most_accessed": [dict(r) for r in most_accessed],
        }

    # -------------------------------------------------------------------------
    # FZF integration
    # -------------------------------------------------------------------------

    async def fzf_select_memory(
        self, header: str = "Select a memory", include_archived: bool = False
    ) -> Optional[str]:
        """
        Open an fzf picker to interactively select a memory.

        Shows a list of memories with preview pane showing full content.

        Args:
            header: Header text for the fzf prompt
            include_archived: Include archived memories in the list

        Returns:
            Full UUID of the selected memory, or None if cancelled
        """
        fzf_path: Optional[str] = shutil.which("fzf")
        if not fzf_path:
            print(_red("fzf not found. Please install fzf."), file=sys.stderr)
            return None

        where: str = "TRUE" if include_archived else "NOT is_archived"
        rows = await self.pool.fetch(
            f"""
            SELECT id, summary, category, importance, tags, is_pinned, created_at
            FROM memories WHERE {where}
            ORDER BY is_pinned DESC, created_at DESC
            """
        )

        if not rows:
            print(_yellow("No memories found."), file=sys.stderr)
            return None

        # Build fzf input lines
        lines: list[str] = []
        for row in rows:
            pin: str = "*" if row["is_pinned"] else " "
            short_id: str = str(row["id"])[:8]
            cat: str = (row["category"] or "")[:12]
            imp: str = (row["importance"] or "normal")[:8]
            summary: str = (row["summary"] or "")[:50]
            tags_str: str = ",".join(row["tags"][:3]) if row["tags"] else ""
            created: str = row["created_at"].strftime("%Y-%m-%d") if row["created_at"] else ""
            line: str = (
                f"{short_id} {pin} | {cat:<12} | {imp:<8} | "
                f"{summary:<50} | {tags_str:<20} | {created}"
            )
            lines.append(line)

        # Write to temp file
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as f:
            f.write("\n".join(lines))
            temp_file: str = f.name

        # Create preview script that queries the database
        password_env: str = f"PGPASSWORD='{DB_CONFIG['password']}'" if DB_CONFIG["password"] else ""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".sh", delete=False) as f:
            f.write(f"""#!/bin/bash
{password_env}
uuid="${{1%% *}}"
full_uuid=$(psql -h {DB_CONFIG['host']} -p {DB_CONFIG['port']} -d {DB_CONFIG['database']} -U {DB_CONFIG['user']} -t -c "SELECT id FROM memories WHERE id::text LIKE '$uuid%' LIMIT 1" 2>/dev/null | tr -d ' ')
[ -z "$full_uuid" ] && echo "Memory not found" && exit 1
psql -h {DB_CONFIG['host']} -p {DB_CONFIG['port']} -d {DB_CONFIG['database']} -U {DB_CONFIG['user']} -t -A -c "
SELECT
    '━━━ MEMORY ━━━' || E'\\n' ||
    'ID: ' || id || E'\\n' ||
    'Category: ' || COALESCE(category, '-') || '/' || COALESCE(subcategory, '-') || E'\\n' ||
    'Importance: ' || COALESCE(importance, 'normal') || E'\\n' ||
    'Source: ' || COALESCE(source, '-') || E'\\n' ||
    'Pinned: ' || CASE WHEN is_pinned THEN 'yes' ELSE 'no' END || E'\\n' ||
    'Tags: ' || COALESCE(array_to_string(tags, ', '), '-') || E'\\n' ||
    'Created: ' || to_char(created_at, 'YYYY-MM-DD HH24:MI') || E'\\n' ||
    'Accessed: ' || access_count || ' times' || E'\\n' ||
    '━━━ SUMMARY ━━━' || E'\\n' ||
    COALESCE(summary, '-') || E'\\n' ||
    '━━━ CONTENT ━━━' || E'\\n' ||
    COALESCE(content, '-')
FROM memories WHERE id = '$full_uuid'::uuid
" 2>/dev/null
""")
            preview_file: str = f.name
        os.chmod(preview_file, 0o755)

        try:
            fzf_cmd: list[str] = [
                fzf_path,
                "--preview", f"{preview_file} {{}}",
                "--preview-window", "down:60%:wrap",
                "--header", f"{header} (Ctrl-C to cancel)",
                "--bind", "ctrl-/:toggle-preview",
            ]

            result = subprocess.run(
                fzf_cmd,
                stdin=open(temp_file),
                capture_output=True,
                text=True,
            )

            if result.returncode == 0 and result.stdout.strip():
                selected: str = result.stdout.strip()
                short_uuid: str = selected.split(" ")[0].strip()

                # Resolve to full UUID
                full_id: Optional[str] = await self._resolve_uuid(short_uuid)
                return full_id

            return None
        finally:
            os.unlink(temp_file)
            os.unlink(preview_file)

    async def fzf_search(self, query: str = "") -> Optional[str]:
        """
        Open fzf with live search filtering across memories.

        Args:
            query: Initial search query

        Returns:
            Full UUID of selected memory, or None
        """
        fzf_path: Optional[str] = shutil.which("fzf")
        if not fzf_path:
            print(_red("fzf not found. Please install fzf."), file=sys.stderr)
            return None

        # Get all active memories for fzf filtering
        rows = await self.pool.fetch(
            """
            SELECT id, summary, category, importance, tags, content
            FROM memories WHERE NOT is_archived
            ORDER BY is_pinned DESC, created_at DESC
            """
        )

        if not rows:
            print(_yellow("No memories found."), file=sys.stderr)
            return None

        # Build searchable lines (include content snippet for matching)
        lines: list[str] = []
        for row in rows:
            short_id: str = str(row["id"])[:8]
            cat: str = (row["category"] or "")[:12]
            summary: str = (row["summary"] or "")[:60]
            content_snippet: str = (row["content"] or "")[:100].replace("\n", " ")
            tags_str: str = ",".join(row["tags"]) if row["tags"] else ""
            line: str = f"{short_id} | {cat:<12} | {summary:<60} | {tags_str} | {content_snippet}"
            lines.append(line)

        input_text: str = "\n".join(lines)

        fzf_cmd: list[str] = [
            fzf_path,
            "--header", "Search memories (type to filter)",
            "--query", query,
            "--preview-window", "down:40%:wrap",
        ]

        result = subprocess.run(
            fzf_cmd,
            input=input_text,
            capture_output=True,
            text=True,
        )

        if result.returncode == 0 and result.stdout.strip():
            short_uuid: str = result.stdout.strip().split(" ")[0].strip()
            return await self._resolve_uuid(short_uuid)

        return None


# =============================================================================
# Formatting helpers
# =============================================================================

def format_memory_detail(mem: dict) -> str:
    """
    Format a single memory for detailed display.

    Args:
        mem: Memory record dict

    Returns:
        Formatted string for terminal output
    """
    lines: list[str] = []
    lines.append(_bold(f"━━━ Memory: {str(mem['id'])[:8]} ━━━"))
    lines.append(f"  {_cyan('ID:')}          {mem['id']}")
    cat: str = mem.get('category') or '-'
    subcat: str = mem.get('subcategory') or '-'
    lines.append(f"  {_cyan('Category:')}    {cat}/{subcat}")
    lines.append(f"  {_cyan('Importance:')}  {mem.get('importance', 'normal')}")
    lines.append(f"  {_cyan('Source:')}      {mem.get('source', '-')}")

    if mem.get("source_context"):
        lines.append(f"  {_cyan('Context:')}     {mem['source_context']}")

    if mem.get("conversation_id"):
        lines.append(f"  {_cyan('Conv ID:')}     {mem['conversation_id']}")

    lines.append(f"  {_cyan('Pinned:')}      {'yes' if mem.get('is_pinned') else 'no'}")
    lines.append(f"  {_cyan('Archived:')}    {'yes' if mem.get('is_archived') else 'no'}")
    lines.append(f"  {_cyan('Accessed:')}    {mem.get('access_count', 0)} times")

    tags: list[str] = mem.get("tags", [])
    lines.append(f"  {_cyan('Tags:')}        {', '.join(tags) if tags else '-'}")

    if mem.get("related_to"):
        lines.append(f"  {_cyan('Related to:')}  {str(mem['related_to'])[:8]}")

    created: str = mem["created_at"].strftime("%Y-%m-%d %H:%M:%S") if mem.get("created_at") else "-"
    updated: str = mem["updated_at"].strftime("%Y-%m-%d %H:%M:%S") if mem.get("updated_at") else "-"
    last_access: str = mem["last_accessed_at"].strftime("%Y-%m-%d %H:%M:%S") if mem.get("last_accessed_at") else "never"
    lines.append(f"  {_cyan('Created:')}     {created}")
    lines.append(f"  {_cyan('Updated:')}     {updated}")
    lines.append(f"  {_cyan('Last access:')} {last_access}")

    lines.append("")
    lines.append(_bold("━━━ Summary ━━━"))
    lines.append(f"  {mem.get('summary', '-')}")
    lines.append("")
    lines.append(_bold("━━━ Content ━━━"))
    for line in (mem.get("content", "-") or "-").split("\n"):
        lines.append(f"  {line}")

    if mem.get("metadata") and mem["metadata"] != "{}":
        lines.append("")
        lines.append(_bold("━━━ Metadata ━━━"))
        try:
            meta = json.loads(mem["metadata"]) if isinstance(mem["metadata"], str) else mem["metadata"]
            lines.append(f"  {json.dumps(meta, indent=2)}")
        except (json.JSONDecodeError, TypeError):
            lines.append(f"  {mem['metadata']}")

    return "\n".join(lines)


def format_memory_table(memories: list[dict], columns: Optional[list[str]] = None) -> str:
    """
    Format a list of memories as an aligned table.

    Args:
        memories: List of memory dicts
        columns: Which columns to display (default: DEFAULT_COLUMNS)

    Returns:
        Formatted table string
    """
    if not memories:
        return _yellow("No memories found.")

    cols: list[str] = columns or DEFAULT_COLUMNS
    col_widths: dict[str, int] = {
        "id": 8, "category": 12, "subcategory": 12, "importance": 8,
        "summary": 50, "source": 15, "tags": 25, "created_at": 10,
        "updated_at": 10, "access_count": 6, "is_pinned": 3,
    }

    # Header
    header_parts: list[str] = []
    for col in cols:
        width: int = col_widths.get(col, 20)
        header_parts.append(f"{col.upper():<{width}}")
    header: str = _bold(" | ".join(header_parts))

    # Rows
    lines: list[str] = [header, "-" * len(header.replace("\033[1m", "").replace("\033[0m", ""))]

    for mem in memories:
        parts: list[str] = []
        for col in cols:
            width = col_widths.get(col, 20)
            val = mem.get(col, "")

            if col == "id":
                val = str(val)[:8]
            elif col == "tags":
                val = ",".join(val[:3]) if val else ""
            elif col in ("created_at", "updated_at"):
                val = val.strftime("%Y-%m-%d") if val else ""
            elif col == "is_pinned":
                val = "*" if val else " "
            elif col == "summary":
                val = (str(val) if val else "")[:width]
            else:
                val = str(val) if val is not None else ""

            parts.append(f"{str(val):<{width}}")

        lines.append(" | ".join(parts))

    return "\n".join(lines)


def format_as_json(data: list[dict] | dict) -> str:
    """Format data as JSON, handling datetime serialization."""
    def _serialize(obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        if hasattr(obj, "__str__"):
            return str(obj)
        raise TypeError(f"Object of type {type(obj)} is not JSON serializable")

    return json.dumps(data, indent=2, default=_serialize)


def format_as_yaml(data: list[dict] | dict) -> str:
    """Format data as YAML, handling datetime serialization."""
    if yaml is None:
        return format_as_json(data)

    def _convert(obj):
        if isinstance(obj, dict):
            return {k: _convert(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [_convert(v) for v in obj]
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        if hasattr(obj, "hex"):  # UUID
            return str(obj)
        return obj

    # use block scalar style (|) for multiline strings instead of backslash escaping
    def _str_representer(dumper, data):
        if "\n" in data:
            return dumper.represent_scalar("tag:yaml.org,2002:str", data, style="|")
        return dumper.represent_scalar("tag:yaml.org,2002:str", data)

    custom_dumper = type("CustomDumper", (yaml.Dumper,), {})
    custom_dumper.add_representer(str, _str_representer)
    return yaml.dump(_convert(data), Dumper=custom_dumper, default_flow_style=False, allow_unicode=True)


# =============================================================================
# Command handlers
# =============================================================================

async def cmd_add(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'add' subcommand — store a new memory."""
    content: str = args.content

    # If content is '-', read from stdin
    if content == "-":
        content = sys.stdin.read().strip()
        if not content:
            print(_red("No content provided via stdin"), file=sys.stderr)
            sys.exit(1)

    memory_id: str = await mgr.add_memory(
        content=content,
        summary=args.summary,
        category=args.category,
        subcategory=args.subcategory,
        importance=args.importance,
        source=args.source,
        source_context=args.source_context,
        conversation_id=args.conversation_id,
        tags=args.tag,
        related_to=args.related_to,
        pinned=args.pin,
        metadata=json.loads(args.metadata) if args.metadata else None,
    )
    print(_green(f"Memory created: {memory_id[:8]}"))


async def cmd_show(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'show' subcommand — display a single memory."""
    memory_id: Optional[str] = args.id

    if args.fzf or not memory_id:
        if args.fzf or (not memory_id and sys.stdin.isatty()):
            memory_id = await mgr.fzf_select_memory("Select memory to view")
            if not memory_id:
                return
        elif not memory_id:
            print(_red("Memory ID required (use --fzf for interactive selection)"), file=sys.stderr)
            return

    mem: Optional[dict] = await mgr.get_memory(memory_id)
    if not mem:
        print(_red(f"Memory not found: {memory_id}"), file=sys.stderr)
        return

    fmt: str = args.format
    if fmt == "json":
        print(format_as_json(mem))
    elif fmt in ("yaml", "yml"):
        print(format_as_yaml(mem))
    else:
        print(format_memory_detail(mem))


async def cmd_list(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'list' subcommand — list memories with filters."""
    memories: list[dict] = await mgr.list_memories(
        category=args.category,
        subcategory=args.subcategory,
        importance=args.importance,
        tag=args.tag,
        source=args.source,
        pinned=True if args.pinned else None,
        include_archived=args.include_archived,
        only_archived=args.only_archived,
        limit=args.limit,
        offset=args.offset,
        order_by=args.sort or "created_at",
        descending=not args.ascending,
    )

    columns: Optional[list[str]] = None
    if args.cols:
        columns = [c.strip() for c in args.cols.split(",")]

    fmt: str = args.format
    if fmt == "json":
        print(format_as_json(memories))
    elif fmt in ("yaml", "yml"):
        print(format_as_yaml(memories))
    elif fmt in ("markdown", "md"):
        for mem in memories:
            print(f"- **{str(mem['id'])[:8]}** [{mem.get('category', '')}] "
                  f"{mem.get('summary', '')}")
    else:
        print(format_memory_table(memories, columns))


async def cmd_search(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'search' subcommand — full-text search."""
    if args.fzf:
        selected: Optional[str] = await mgr.fzf_search(args.query or "")
        if selected:
            mem: Optional[dict] = await mgr.get_memory(selected)
            if mem:
                print(format_memory_detail(mem))
        return

    if not args.query:
        print(_red("Search query required"), file=sys.stderr)
        return

    results: list[dict] = await mgr.search_memories(
        query=args.query,
        category=args.category,
        include_archived=args.include_archived,
        limit=args.limit,
        exact=args.exact,
    )

    fmt: str = args.format
    if fmt == "json":
        print(format_as_json(results))
    elif fmt in ("yaml", "yml"):
        print(format_as_yaml(results))
    else:
        print(format_memory_table(results))


async def cmd_edit(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'edit' subcommand — edit memory in $EDITOR."""
    memory_id: Optional[str] = args.id

    if args.fzf or not memory_id:
        if args.fzf or (not memory_id and sys.stdin.isatty()):
            memory_id = await mgr.fzf_select_memory("Select memory to edit")
            if not memory_id:
                return
        elif not memory_id:
            print(_red("Memory ID required (use --fzf for interactive selection)"), file=sys.stderr)
            return

    mem: Optional[dict] = await mgr.get_memory(memory_id)
    if not mem:
        print(_red(f"Memory not found: {memory_id}"), file=sys.stderr)
        return

    # Build editable YAML representation
    editable: dict = {
        "summary": mem.get("summary", ""),
        "content": mem.get("content", ""),
        "category": mem.get("category", "general"),
        "subcategory": mem.get("subcategory", ""),
        "importance": mem.get("importance", "normal"),
        "source": mem.get("source", ""),
        "tags": mem.get("tags", []),
        "is_pinned": mem.get("is_pinned", False),
    }

    edit_text: str = format_as_yaml(editable)

    # Open in editor
    editor: str = os.environ.get("EDITOR", "vi")
    with tempfile.NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as f:
        f.write(f"# Editing memory {str(mem['id'])[:8]}\n")
        f.write("# Save and close to apply changes. Delete all content to cancel.\n\n")
        f.write(edit_text)
        temp_file: str = f.name

    try:
        subprocess.run([editor, temp_file])

        with open(temp_file, "r") as f:
            edited: str = f.read()

        # Strip comment lines
        clean_lines: list[str] = [
            line for line in edited.split("\n")
            if not line.strip().startswith("#")
        ]
        clean_text: str = "\n".join(clean_lines).strip()

        if not clean_text:
            print(_yellow("Edit cancelled (empty content)"))
            return

        if yaml is None:
            print(_red("PyYAML not available — cannot parse edited content"), file=sys.stderr)
            return

        new_data: dict = yaml.safe_load(clean_text)
        if not isinstance(new_data, dict):
            print(_red("Invalid YAML — expected a mapping"), file=sys.stderr)
            return

        # Apply changes
        updated: bool = await mgr.update_memory(str(mem["id"]), **new_data)
        if updated:
            print(_green(f"Memory {str(mem['id'])[:8]} updated"))
        else:
            print(_yellow("No changes applied"))

    finally:
        os.unlink(temp_file)


async def cmd_archive(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'archive' subcommand — archive or unarchive a memory."""
    memory_id: Optional[str] = args.id

    if args.fzf or not memory_id:
        if args.fzf or (not memory_id and sys.stdin.isatty()):
            include: bool = args.unarchive
            memory_id = await mgr.fzf_select_memory(
                "Select memory to " + ("unarchive" if args.unarchive else "archive"),
                include_archived=include,
            )
            if not memory_id:
                return
        elif not memory_id:
            print(_red("Memory ID required (use --fzf for interactive selection)"), file=sys.stderr)
            return

    value: bool = not args.unarchive
    updated: bool = await mgr.update_memory(memory_id, is_archived=value)
    if updated:
        action: str = "unarchived" if args.unarchive else "archived"
        print(_green(f"Memory {memory_id[:8]} {action}"))
    else:
        print(_red(f"Memory not found: {memory_id}"), file=sys.stderr)


async def cmd_pin(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'pin' subcommand — pin or unpin a memory."""
    memory_id: Optional[str] = args.id

    if args.fzf or not memory_id:
        if args.fzf or (not memory_id and sys.stdin.isatty()):
            memory_id = await mgr.fzf_select_memory(
                "Select memory to " + ("unpin" if args.unpin else "pin")
            )
            if not memory_id:
                return
        elif not memory_id:
            print(_red("Memory ID required (use --fzf for interactive selection)"), file=sys.stderr)
            return

    value: bool = not args.unpin
    updated: bool = await mgr.update_memory(memory_id, is_pinned=value)
    if updated:
        action: str = "unpinned" if args.unpin else "pinned"
        print(_green(f"Memory {memory_id[:8]} {action}"))
    else:
        print(_red(f"Memory not found: {memory_id}"), file=sys.stderr)


async def cmd_rm(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'rm' subcommand — permanently delete a memory."""
    memory_id: Optional[str] = args.id

    if args.fzf or not memory_id:
        if args.fzf or (not memory_id and sys.stdin.isatty()):
            memory_id = await mgr.fzf_select_memory("Select memory to DELETE")
            if not memory_id:
                return
        elif not memory_id:
            print(_red("Memory ID required (use --fzf for interactive selection)"), file=sys.stderr)
            return

    if not args.force:
        mem: Optional[dict] = await mgr.get_memory(memory_id)
        if mem:
            print(f"About to delete: {_bold(mem.get('summary', str(mem['id'])[:8]))}")
            confirm: str = input("Are you sure? [y/N] ").strip().lower()
            if confirm != "y":
                print(_yellow("Cancelled"))
                return

    deleted: bool = await mgr.delete_memory(memory_id)
    if deleted:
        print(_green(f"Memory {memory_id[:8]} deleted"))
    else:
        print(_red(f"Memory not found: {memory_id}"), file=sys.stderr)


async def cmd_tag(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'tag' subcommand — add or remove tags."""
    memory_id: Optional[str] = args.id

    if args.fzf or not memory_id:
        if args.fzf or (not memory_id and sys.stdin.isatty()):
            memory_id = await mgr.fzf_select_memory("Select memory to tag")
            if not memory_id:
                return
        elif not memory_id:
            print(_red("Memory ID required (use --fzf for interactive selection)"), file=sys.stderr)
            return

    full_id: Optional[str] = await mgr._resolve_uuid(memory_id)
    if not full_id:
        print(_red(f"Memory not found: {memory_id}"), file=sys.stderr)
        return

    if args.remove:
        # Remove tags
        for tag_name in args.tags:
            await mgr.pool.execute(
                "UPDATE memories SET tags = array_remove(tags, $1) WHERE id = $2",
                tag_name, full_id,
            )
        print(_green(f"Removed tags from {full_id[:8]}: {', '.join(args.tags)}"))
    else:
        # Add tags (avoid duplicates)
        for tag_name in args.tags:
            await mgr.pool.execute(
                """
                UPDATE memories
                SET tags = CASE
                    WHEN NOT ($1 = ANY(tags)) THEN array_append(tags, $1)
                    ELSE tags
                END
                WHERE id = $2
                """,
                tag_name, full_id,
            )
        print(_green(f"Added tags to {full_id[:8]}: {', '.join(args.tags)}"))


async def cmd_stats(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'stats' subcommand — show aggregate statistics."""
    stats: dict = await mgr.get_stats()

    fmt: str = args.format if hasattr(args, "format") else "table"
    if fmt == "json":
        print(format_as_json(stats))
        return
    if fmt in ("yaml", "yml"):
        print(format_as_yaml(stats))
        return

    print(_bold("━━━ Agent Memory Statistics ━━━"))
    print(f"  Total memories:    {stats['total']}")
    print(f"  Active:            {stats['active']}")
    print(f"  Archived:          {stats['archived']}")
    print(f"  Pinned:            {stats['pinned']}")
    print()

    if stats["by_category"]:
        print(_bold("  By Category:"))
        for row in stats["by_category"]:
            print(f"    {row['category']:<15} {row['count']}")
        print()

    if stats["by_importance"]:
        print(_bold("  By Importance:"))
        for row in stats["by_importance"]:
            print(f"    {row['importance']:<15} {row['count']}")
        print()

    if stats["top_tags"]:
        print(_bold("  Top Tags:"))
        for row in stats["top_tags"]:
            print(f"    {row['tag']:<20} {row['count']}")
        print()

    if stats["most_accessed"]:
        print(_bold("  Most Accessed:"))
        for row in stats["most_accessed"]:
            print(f"    {str(row['id'])[:8]} ({row['access_count']}x) {row['summary'][:50]}")


async def cmd_export(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'export' subcommand — export all memories."""
    memories: list[dict] = await mgr.list_memories(
        include_archived=True, limit=100000
    )

    fmt: str = args.format
    if fmt == "json":
        output: str = format_as_json(memories)
    elif fmt in ("yaml", "yml"):
        output = format_as_yaml(memories)
    else:
        output = format_as_json(memories)

    if args.output:
        with open(args.output, "w") as f:
            f.write(output)
        print(_green(f"Exported {len(memories)} memories to {args.output}"))
    else:
        print(output)


async def cmd_import(mgr: MemoryManager, args: argparse.Namespace) -> None:
    """Handle the 'import' subcommand — import memories from file."""
    with open(args.file, "r") as f:
        raw: str = f.read()

    # Auto-detect format
    fmt: str = args.format or ""
    if not fmt:
        if args.file.endswith(".json"):
            fmt = "json"
        elif args.file.endswith((".yaml", ".yml")):
            fmt = "yaml"
        else:
            fmt = "json"

    if fmt == "json":
        data: list[dict] = json.loads(raw)
    elif fmt in ("yaml", "yml"):
        if yaml is None:
            print(_red("PyYAML not available"), file=sys.stderr)
            sys.exit(1)
        data = yaml.safe_load(raw)
    else:
        print(_red(f"Unknown format: {fmt}"), file=sys.stderr)
        sys.exit(1)

    if not isinstance(data, list):
        data = [data]

    count: int = 0
    for mem in data:
        await mgr.add_memory(
            content=mem.get("content", ""),
            summary=mem.get("summary"),
            category=mem.get("category", "general"),
            subcategory=mem.get("subcategory"),
            importance=mem.get("importance", "normal"),
            source=mem.get("source"),
            tags=mem.get("tags", []),
            metadata=mem.get("metadata"),
        )
        count += 1

    print(_green(f"Imported {count} memories"))


# =============================================================================
# Argument parsing and main
# =============================================================================

async def main() -> None:
    """Parse arguments and dispatch to the appropriate command handler."""
    parser: argparse.ArgumentParser = argparse.ArgumentParser(
        description="Agent memory store — searchable, persistent memory for AI agents",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
examples:
  agent_memories add "Zach prefers YAML over JSON" -c preference -t config -t formatting
  agent_memories add - < notes.txt
  agent_memories search "yaml preference"
  agent_memories search --fzf
  agent_memories list --category decision --importance high
  agent_memories show --fzf
  agent_memories edit --fzf
  agent_memories tag abc123 python async --fzf
  agent_memories pin --fzf
  agent_memories stats
  agent_memories export -o backup.json

categories: """ + ", ".join(CATEGORIES) + """
importance: """ + ", ".join(IMPORTANCE_LEVELS),
    )
    parser.add_argument("--license", action="store_true", help="Show license info")

    subparsers = parser.add_subparsers(dest="command")

    # --- add ---
    p_add = subparsers.add_parser("add", help="Add a new memory")
    p_add.add_argument("content", help="Memory content (use '-' to read from stdin)")
    p_add.add_argument("-s", "--summary", help="Short summary (auto-generated if omitted)")
    p_add.add_argument("-c", "--category", default="general", choices=CATEGORIES, help="Category")
    p_add.add_argument("--subcategory", help="Subcategory for finer classification")
    p_add.add_argument("-i", "--importance", default="normal", choices=IMPORTANCE_LEVELS, help="Importance level")
    p_add.add_argument("--source", help="Source of the memory (e.g., conversation, heartbeat)")
    p_add.add_argument("--source-context", help="Additional source context")
    p_add.add_argument("--conversation-id", help="Link to a conversation")
    p_add.add_argument("-t", "--tag", action="append", help="Tag (repeatable)")
    p_add.add_argument("--related-to", help="UUID of related memory")
    p_add.add_argument("--pin", action="store_true", help="Pin this memory")
    p_add.add_argument("--metadata", help="JSON metadata string")

    # --- show ---
    p_show = subparsers.add_parser("show", help="Show memory details")
    p_show.add_argument("id", nargs="?", help="Memory ID (full or prefix)")
    p_show.add_argument("--fzf", action="store_true", help="Select with fzf")
    p_show.add_argument("--format", choices=["detail", "json", "yaml"], default="detail")

    # --- list ---
    p_list = subparsers.add_parser("list", help="List memories")
    p_list.add_argument("--cols", help="Columns to display (comma-separated)")
    p_list.add_argument("--format", choices=["table", "json", "yaml", "markdown", "md"], default="table")
    p_list.add_argument("--category", help="Filter by category")
    p_list.add_argument("--subcategory", help="Filter by subcategory")
    p_list.add_argument("--importance", choices=IMPORTANCE_LEVELS, help="Filter by importance")
    p_list.add_argument("--source", help="Filter by source")
    p_list.add_argument("-t", "--tag", action="append", help="Filter by tag (repeatable, all must match)")
    p_list.add_argument("--pinned", action="store_true", help="Show only pinned")
    p_list.add_argument("--include-archived", action="store_true", help="Include archived")
    p_list.add_argument("--only-archived", action="store_true", help="Show only archived")
    p_list.add_argument("--limit", type=int, default=50, help="Max results (default: 50)")
    p_list.add_argument("--offset", type=int, default=0, help="Pagination offset")
    p_list.add_argument("--sort", help="Sort column (default: created_at)")
    p_list.add_argument("--ascending", action="store_true", help="Sort ascending")

    # --- search ---
    p_search = subparsers.add_parser("search", help="Search memories")
    p_search.add_argument("query", nargs="?", help="Search query")
    p_search.add_argument("--fzf", action="store_true", help="Interactive fzf search")
    p_search.add_argument("--exact", action="store_true",
                          help="Use tsvector full-text search (stemming, boolean ops) instead of fuzzy trgm")
    p_search.add_argument("--category", help="Filter by category")
    p_search.add_argument("--include-archived", action="store_true", help="Include archived")
    p_search.add_argument("--limit", type=int, default=25, help="Max results")
    p_search.add_argument("--format", choices=["table", "json", "yaml"], default="table")

    # --- edit ---
    p_edit = subparsers.add_parser("edit", help="Edit memory in $EDITOR")
    p_edit.add_argument("id", nargs="?", help="Memory ID")
    p_edit.add_argument("--fzf", action="store_true", help="Select with fzf")

    # --- archive ---
    p_archive = subparsers.add_parser("archive", help="Archive a memory")
    p_archive.add_argument("id", nargs="?", help="Memory ID")
    p_archive.add_argument("--fzf", action="store_true", help="Select with fzf")
    p_archive.add_argument("--unarchive", action="store_true", help="Unarchive instead")

    # --- pin ---
    p_pin = subparsers.add_parser("pin", help="Pin a memory")
    p_pin.add_argument("id", nargs="?", help="Memory ID")
    p_pin.add_argument("--fzf", action="store_true", help="Select with fzf")
    p_pin.add_argument("--unpin", action="store_true", help="Unpin instead")

    # --- rm ---
    p_rm = subparsers.add_parser("rm", help="Permanently delete a memory")
    p_rm.add_argument("id", nargs="?", help="Memory ID")
    p_rm.add_argument("--fzf", action="store_true", help="Select with fzf")
    p_rm.add_argument("-f", "--force", action="store_true", help="Skip confirmation")

    # --- tag ---
    p_tag = subparsers.add_parser("tag", help="Add or remove tags")
    p_tag.add_argument("id", nargs="?", help="Memory ID")
    p_tag.add_argument("tags", nargs="*", help="Tags to add/remove")
    p_tag.add_argument("--fzf", action="store_true", help="Select with fzf")
    p_tag.add_argument("-r", "--remove", action="store_true", help="Remove tags instead of adding")

    # --- stats ---
    p_stats = subparsers.add_parser("stats", help="Show memory statistics")
    p_stats.add_argument("--format", choices=["table", "json", "yaml"], default="table")

    # --- export ---
    p_export = subparsers.add_parser("export", help="Export all memories")
    p_export.add_argument("-o", "--output", help="Output file (stdout if omitted)")
    p_export.add_argument("--format", choices=["json", "yaml"], default="json")

    # --- import ---
    p_import = subparsers.add_parser("import", help="Import memories from file")
    p_import.add_argument("file", help="Input file (json or yaml)")
    p_import.add_argument("--format", choices=["json", "yaml"], help="File format (auto-detected)")

    args: argparse.Namespace = parser.parse_args()

    if args.license:
        print("agent_memories — AGPLv3")
        print("Copyright (C) 2026  Zach Podbielniak")
        print("https://www.gnu.org/licenses/agpl-3.0.html")
        return

    if not args.command:
        parser.print_help()
        return

    mgr: MemoryManager = MemoryManager()
    try:
        await mgr.init_db()

        dispatch: dict = {
            "add": cmd_add,
            "show": cmd_show,
            "list": cmd_list,
            "search": cmd_search,
            "edit": cmd_edit,
            "archive": cmd_archive,
            "pin": cmd_pin,
            "rm": cmd_rm,
            "tag": cmd_tag,
            "stats": cmd_stats,
            "export": cmd_export,
            "import": cmd_import,
        }

        handler = dispatch.get(args.command)
        if handler:
            await handler(mgr, args)
        else:
            parser.print_help()
    finally:
        await mgr.close_db()


if __name__ == "__main__":
    asyncio.run(main())
