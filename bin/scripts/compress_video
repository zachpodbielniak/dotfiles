#!/bin/bash

# dotfiles - Personal configuration files and scripts
# Copyright (C) 2025  Zach Podbielniak
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

set -euo pipefail

# ==============================================================================
# compress_video - Video Compression Utility
# ==============================================================================
# Author: Zach
# Version: 1.0
# Last Updated: $(date)
# Location: ~/.dotfiles/bin/scripts/compress_video
#
# Description:
# A robust video compression script that uses podman with the linuxserver/ffmpeg
# container. Supports hardware acceleration via VAAPI when available, configurable
# codecs, quality settings, and various output options.
#
# Features:
# - Hardware acceleration support (VAAPI) with automatic detection
# - H.265/HEVC default encoding with H.264 fallback
# - Vorbis audio encoding by default
# - Configurable quality settings
# - Batch processing support
# - Output directory management
# - Flexible codec and format options
#
# Dependencies:
# - podman: Container runtime
# - linuxserver/ffmpeg container image
# - /dev/dri/renderD128: For hardware acceleration (optional)
# - parallel: GNU parallel for concurrent processing (optional)
#
# Usage: See show_help() function or run with -h/--help
# ==============================================================================

# Default configuration
QUALITY="medium"
VIDEO_CODEC="h265"
AUDIO_CODEC="vorbis"
OUTPUT_FORMAT="mkv"
USE_HWACCEL="auto"
PREFER_VULKAN=false
PREFER_SOFTWARE=false
OUTPUT_DIR="output"
CONTAINER_IMAGE="docker.io/linuxserver/ffmpeg:latest"
HWACCEL_DEVICE="/dev/dri/renderD128"
VERBOSE=false
DRY_RUN=false
USE_JOURNAL=false
JOURNAL_FILE=""
FORCE_RECONVERT=false
CUSTOM_CRF=""
PARALLEL_JOBS=1
PARALLEL_TYPE=""
PARALLEL_CHILD=false
CONTAINER_CPUS=""
CONTAINER_MEMORY=""
AUTO_QUALITY=false
CUSTOM_QP=""

# Media library directories (easy to change for different mount points)
MOVIES_DIR="${HOME}/.mnt/nas/Media/Movies"
TV_SERIES_DIR="${HOME}/.mnt/nas/Media/TV Series"
IS_MOVIE=false
IS_TV_SERIES=false
IS_VIDEO=false
MEDIA_TAGS=""

# Logging configuration
LOG_FILE="./compress_video.log"
LOG_LEVEL="INFO"  # DEBUG, INFO, WARN, ERROR
LOG_TO_FILE=true
LOG_TO_STDERR=true

# Quality presets (CRF values)
declare -A QUALITY_PRESETS=(
    ["low"]="28"
    ["medium"]="24"
    ["high"]="18"
    ["veryhigh"]="15"
)

# Quality presets for bitrate (used for Vulkan)
declare -A QUALITY_BITRATES=(
    ["low"]="2M"
    ["medium"]="5M"
    ["high"]="10M"
    ["veryhigh"]="20M"
)

# Video codec mapping
declare -A VIDEO_CODEC_MAP=(
    ["h264"]="libx264"
    ["h265"]="libx265"
    ["vp9"]="libvpx-vp9"
    ["av1"]="libaom-av1"
)

# Audio codec mapping
declare -A AUDIO_CODEC_MAP=(
    ["vorbis"]="libvorbis"
    ["opus"]="libopus"
    ["aac"]="aac"
    ["mp3"]="libmp3lame"
    ["copy"]="copy"
)

# Show help message
show_help() {
    cat << EOF
compress_video - Video compression utility using podman and ffmpeg

USAGE:
    compress_video [OPTIONS] <input_file> [input_file2 ...]

DESCRIPTION:
    Compress video files using ffmpeg in a podman container with optional
    hardware acceleration support.

OPTIONS:
    -h, --help                  Show this help message
    -q, --quality QUALITY       Quality preset: low, medium, high, veryhigh (default: medium)
    -c, --crf VALUE            Custom CRF value (overrides quality preset)
    --qp VALUE                 Custom QP value for GPU encoding (overrides quality preset)
    --auto-quality             Automatically adjust quality based on video resolution
    -v, --video-codec CODEC    Video codec: h264, h265, vp9, av1 (default: h265)
    -a, --audio-codec CODEC    Audio codec: vorbis, opus, aac, mp3, copy (default: vorbis)
    -f, --format FORMAT        Output format: mkv, mp4, webm (default: mkv)
    -o, --output-dir DIR       Output directory (default: ./output)
    -O, --output-file FILE     Specific output filename (single file mode only)
    --no-hwaccel               Disable hardware acceleration
    --force-hwaccel            Force hardware acceleration (fail if unavailable)
    --vulkan                   Prefer Vulkan over VAAPI when available
    --resolution RES           Scale to resolution (e.g., 1280x720, 1920x1080)
    --bitrate RATE             Target bitrate (e.g., 4M, 8M)
    --preset PRESET            FFmpeg preset: ultrafast, fast, medium, slow, veryslow
    --dry-run                  Show command without executing
    --verbose                  Enable verbose output
    --container IMAGE          Use custom container image (default: docker.io/linuxserver/ffmpeg:latest)
    --journal                  Enable journal tracking to skip already converted files
    --journal-file FILE        Custom journal file path (default: ./compress_video_journal.md)
    --force-reconvert          Force reconversion even if file is in journal
    --log-file FILE            Write detailed logs to specified file (default: ./compress_video.log)
    --log-level LEVEL          Set log level: DEBUG, INFO, WARN, ERROR (default: INFO)
    --no-log                   Disable file logging (console output only)
    --list-encoders            List available video encoders in the container
    --prefer-software          Prefer software encoding over hardware acceleration
    --parallel N               Process N files in parallel (default: 1)
    --cpus N                   Limit CPU usage per container (e.g., 2, 1.5)
    --memory SIZE              Limit memory usage per container (e.g., 4096m, 4g)
    --movie                    Copy completed file to movies library directory and add to media DB
    --tv-series                Copy completed file to TV series library directory and add to media DB
    --video                    Add completed file to media DB as generic video
    --tags TAGS                Comma-separated tags to add to media DB entry

EXAMPLES:
    # Basic compression with defaults (H.265, medium quality)
    compress_video input.mp4

    # High quality H.264 compression
    compress_video -q high -v h264 input.mp4

    # Custom CRF with specific output
    compress_video -c 20 -O compressed.mkv input.mp4

    # Batch processing with VP9
    compress_video -v vp9 -f webm *.mp4

    # Force software encoding with custom resolution
    compress_video --no-hwaccel --resolution 1280x720 input.mp4

    # Batch processing with journal (resumable)
    compress_video --journal *.mp4

    # Resume interrupted batch processing
    compress_video --journal *.mp4  # Will skip already converted files

    # Use Vulkan hardware acceleration
    compress_video --vulkan input.mp4

    # Force software encoding (if hardware encoders fail)
    compress_video --prefer-software input.mp4
    
    # Process 2 files in parallel
    compress_video --parallel 2 *.mp4
    
    # Parallel processing with journal
    compress_video --parallel 3 --journal *.mp4
    
    # Compress movie and copy to movies library
    compress_video --movie "Avatar.mkv"
    
    # Compress TV series episode and organize by series/season
    compress_video --tv-series "The Office - S03E04 - The Convention.mkv"
    compress_video --tv-series "The Office - S03E05.mkv"  # Also works without episode title
    
    # Limit resources per container
    compress_video --cpus 2 --memory 4g input.mp4
    
    # Parallel processing with resource limits (each container gets 2 CPUs and 4GB RAM)
    compress_video --parallel 2 --cpus 2 --memory 4096m *.mp4
    
    # Auto-quality based on resolution
    compress_video --auto-quality input.mp4
    
    # GPU encoding with custom QP value
    compress_video --qp 25 input.mp4
    
    # Auto-quality with hardware acceleration
    compress_video --auto-quality --force-hwaccel *.mkv
    
    # Compress and add to media DB as generic video with tags
    compress_video --video --tags "family,vacation" vacation.mp4
    
    # Compress movie and add to DB with custom tags
    compress_video --movie --tags "action,favorite" "Die Hard (1988).mkv"
    
JOURNAL ANALYSIS EXAMPLES:
    # Enable journal and compress videos
    compress_video --journal --quality high *.mp4
    
    # Get comprehensive statistics summary
    md_table_summarize --comprehensive compress_video_journal.md
    
    # Find all failed operations
    md_table_query --query "SELECT * FROM data WHERE status='FAILED'" compress_video_journal.md
    
    # Calculate average compression ratio by codec
    md_table_query --query "SELECT video_codec, AVG(CAST(REPLACE(compression_ratio, ':1', '') AS FLOAT)) as avg_ratio FROM data WHERE status='SUCCESS' GROUP BY video_codec" compress_video_journal.md
    
    # Find videos with best compression ratios
    md_table_query --query "SELECT input_file, compression_ratio FROM data WHERE status='SUCCESS' ORDER BY CAST(REPLACE(compression_ratio, ':1', '') AS FLOAT) DESC LIMIT 10" compress_video_journal.md
    
    # Calculate total space saved
    md_table_calc "SUM(\$_input_size) - SUM(\$_output_size)" compress_video_journal.md
    
    # Visualize compression performance by codec
    md_table_plot --type bar --columns "video_codec,compression_ratio" --title "Compression Ratios by Codec" compress_video_journal.md
    
    # Create dashboard for monitoring
    md_table_dashboard --title "Video Compression Analytics" compress_video_journal.md
    
    # Export detailed report to Excel
    md_table_export_enhanced --format excel --style professional --sheet-name "Compression Log" compress_video_journal.md

JOURNAL INTEGRATION:
    The --journal flag creates a markdown table (compress_video_journal.md) that tracks:
    - File sizes, compression ratios, processing times
    - Success/failure status with detailed notes  
    - Video codec, audio codec, and quality settings used
    
    Journal columns available for analysis:
    - timestamp, input_file, output_file, input_size, output_size
    - compression_ratio, video_codec, audio_codec, quality, duration
    - status, notes

QUALITY GUIDE:
    Software encoding (CRF mode):
    - low (CRF 28): Smaller files, acceptable quality
    - medium (CRF 24): Balanced size/quality (default)
    - high (CRF 18): Very good quality, larger files
    - veryhigh (CRF 15): Excellent quality, much larger files
    
    VAAPI encoding (CRF or QP mode):
    - Uses CRF by default, or QP with --qp option
    - QP values typically range from 20-35 (lower = better quality)
    
    Vulkan (Bitrate mode):
    - low: 2 Mbps bitrate
    - medium: 5 Mbps bitrate (default)
    - high: 10 Mbps bitrate
    - veryhigh: 20 Mbps bitrate
    
    Auto-quality (--auto-quality):
    - Width â‰¤ 1280px: CRF 24 (software) / QP 26 (GPU)
    - Width > 1280px: CRF 26 (software) / QP 28 (GPU)
    - Width > 1920px: CRF 28 (software) / QP 30 (GPU)

VULKAN SUPPORT:
    The script automatically detects your GPU vendor and sets the appropriate
    environment variables for Vulkan video decode:
    - Intel GPUs: ANV_VIDEO_DECODE=1
    - AMD GPUs: RADV_PERFTEST=video_decode
    - NVIDIA GPUs: Requires Vulkan Beta drivers installed on host

EOF
}

# Initialize logging
init_logging() {
    if [[ "$LOG_TO_FILE" == "true" ]]; then
        # Use the configured log file (defaults to ./compress_video.log)
        # The LOG_FILE variable is already set with default value
        
        # Create log file and directory if needed
        local log_dir="$(dirname "$LOG_FILE")"
        if [[ ! -d "$log_dir" ]]; then
            mkdir -p "$log_dir" || {
                echo "[ERROR] Failed to create log directory: $log_dir" >&2
                LOG_TO_FILE=false
                return 1
            }
        fi
        
        # Initialize log file with header
        {
            echo "=========================================="
            echo "compress_video log - $(date)"
            echo "PID: $$"
            echo "Command: $0 $*"
            echo "=========================================="
        } >> "$LOG_FILE" 2>/dev/null || {
            echo "[ERROR] Failed to initialize log file: $LOG_FILE" >&2
            LOG_TO_FILE=false
            return 1
        }
    fi
}

# Enhanced logging functions with file support
write_log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp="$(date '+%Y-%m-%d %H:%M:%S')"
    local log_entry="[$timestamp] [$level] $message"
    
    # Write to log file if enabled
    if [[ "$LOG_TO_FILE" == "true" ]] && [[ -n "$LOG_FILE" ]]; then
        echo "$log_entry" >> "$LOG_FILE" 2>/dev/null
    fi
    
    # Write to console based on level and settings
    case "$level" in
        ERROR)
            [[ "$LOG_TO_STDERR" == "true" ]] && echo "$log_entry" >&2
            ;;
        WARN)
            [[ "$LOG_TO_STDERR" == "true" ]] && echo "$log_entry" >&2
            ;;
        INFO)
            echo "$message"  # Keep simple format for user-facing messages
            ;;
        DEBUG)
            if [[ "$VERBOSE" == "true" ]] || [[ "$LOG_LEVEL" == "DEBUG" ]]; then
                [[ "$LOG_TO_STDERR" == "true" ]] && echo "$log_entry" >&2
            fi
            ;;
    esac
}

log() {
    write_log "INFO" "$@"
}

error() {
    write_log "ERROR" "$@"
}

warn() {
    write_log "WARN" "$@"
}

debug() {
    write_log "DEBUG" "$@"
}

# Journal functions
init_journal() {
    if [[ "$USE_JOURNAL" == "true" ]]; then
        # Set default journal file if not specified
        if [[ -z "$JOURNAL_FILE" ]]; then
            JOURNAL_FILE="./compress_video_journal.md"
        fi
        
        # Create journal file if it doesn't exist
        if [[ ! -f "$JOURNAL_FILE" ]]; then
            create_journal_header "$JOURNAL_FILE"
            debug "Created journal file: $JOURNAL_FILE"
        else
            debug "Using existing journal file: $JOURNAL_FILE"
        fi
    fi
}

# Create markdown table header for journal
create_journal_header() {
    local journal_file="$1"
    cat > "$journal_file" << 'EOF'
# Video Compression Journal

This file tracks video compression operations performed by compress_video script.

| timestamp | input_file | output_file | input_size | output_size | compression_ratio | video_codec | audio_codec | quality | duration | status | notes |
|-----------|------------|-------------|------------|-------------|-------------------|-------------|-------------|---------|----------|--------|-------|
EOF
}

# Check if a file has been converted based on journal
is_converted() {
    local input_file="$1"
    local output_file="$2"
    
    if [[ "$USE_JOURNAL" != "true" ]] || [[ "$FORCE_RECONVERT" == "true" ]]; then
        return 1  # Not converted or force reconvert
    fi
    
    # Check if entry exists in journal by looking for the input and output file combination
    if [[ -f "$JOURNAL_FILE" ]]; then
        # Escape special regex characters in filenames
        local escaped_input=$(basename "$input_file" | sed 's/[[\.^$()|*+?{]/\\&/g')
        local escaped_output=$(basename "$output_file" | sed 's/[[\.^$()|*+?{]/\\&/g')
        
        # Skip header lines and check for matching input/output files
        if tail -n +4 "$JOURNAL_FILE" | grep -qE "\| [^|]+ \| ${escaped_input} \| ${escaped_output} \| [^|]+ \| [^|]+ \| [^|]+ \| [^|]+ \| [^|]+ \| [^|]+ \| [^|]+ \| SUCCESS \|"; then
            return 0  # Already converted successfully
        fi
    fi
    
    return 1  # Not converted
}

# Add entry to journal
add_to_journal() {
    local input_file="$1"
    local output_file="$2"
    local status="${3:-SUCCESS}"
    local notes="${4:-}"
    
    if [[ "$USE_JOURNAL" == "true" ]]; then
        local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
        local input_basename=$(basename "$input_file")
        local output_basename=$(basename "$output_file")
        
        # Get file sizes
        local input_size="N/A"
        local output_size="N/A"
        local compression_ratio="N/A"
        
        if [[ -f "$input_file" ]]; then
            input_size=$(stat -c%s "$input_file" 2>/dev/null || echo "N/A")
            if [[ "$input_size" != "N/A" ]]; then
                input_size=$(numfmt --to=iec --suffix=B "$input_size" 2>/dev/null || echo "$input_size bytes")
            fi
        fi
        
        if [[ -f "$output_file" && "$status" == "SUCCESS" ]]; then
            output_size=$(stat -c%s "$output_file" 2>/dev/null || echo "N/A")
            if [[ "$output_size" != "N/A" ]]; then
                output_size=$(numfmt --to=iec --suffix=B "$output_size" 2>/dev/null || echo "$output_size bytes")
                
                # Calculate compression ratio if both sizes are available
                if [[ "$input_size" != "N/A" ]]; then
                    local input_bytes=$(stat -c%s "$input_file" 2>/dev/null)
                    local output_bytes=$(stat -c%s "$output_file" 2>/dev/null)
                    if [[ -n "$input_bytes" && -n "$output_bytes" && "$output_bytes" -gt 0 ]]; then
                        compression_ratio=$(echo "scale=2; $input_bytes / $output_bytes" | bc 2>/dev/null || echo "N/A")
                        if [[ "$compression_ratio" != "N/A" ]]; then
                            compression_ratio="${compression_ratio}:1"
                        fi
                    fi
                fi
            fi
        fi
        
        # Get video duration if available (requires ffprobe, but we'll make it optional)
        local duration="N/A"
        if [[ -f "$input_file" ]] && command -v ffprobe >/dev/null 2>&1; then
            duration=$(ffprobe -v quiet -show_entries format=duration -of csv=p=0 "$input_file" 2>/dev/null | cut -d. -f1)
            if [[ -n "$duration" && "$duration" != "N/A" ]]; then
                # Convert seconds to HH:MM:SS
                duration=$(printf "%02d:%02d:%02d" $((duration/3600)) $(((duration%3600)/60)) $((duration%60)))
            else
                duration="N/A"
            fi
        fi
        
        # Determine quality string
        local quality_str="$QUALITY"
        if [[ -n "$CUSTOM_CRF" ]]; then
            quality_str="crf:$CUSTOM_CRF"
        fi
        
        # Create markdown table row
        local row="| $timestamp | $input_basename | $output_basename | $input_size | $output_size | $compression_ratio | $VIDEO_CODEC | $AUDIO_CODEC | $quality_str | $duration | $status | $notes |"
        
        # Add to journal file with file locking to prevent race conditions
        local lock_file="${JOURNAL_FILE}.lock"
        local lock_acquired=false
        local retry_count=0
        local max_retries=10
        
        while [[ $retry_count -lt $max_retries ]]; do
            if (set -C; echo $$ > "$lock_file") 2>/dev/null; then
                lock_acquired=true
                break
            fi
            # Wait a bit and retry
            sleep 0.1
            ((retry_count++))
        done
        
        if [[ "$lock_acquired" == "true" ]]; then
            # We have the lock, write to journal
            echo "$row" >> "$JOURNAL_FILE"
            local write_status=$?
            
            # Remove lock file
            rm -f "$lock_file"
            
            if [[ $write_status -eq 0 ]]; then
                debug "Added to journal: $input_basename -> $output_basename ($status)"
            else
                error "Failed to write to journal file: $JOURNAL_FILE"
                warn "Journal entry lost: $row"
            fi
        else
            error "Failed to acquire journal lock after $max_retries attempts"
            warn "Journal entry lost: $row"
        fi
    fi
}

# Input validation functions
validate_crf() {
    local crf="$1"
    if ! [[ "$crf" =~ ^[0-9]+$ ]]; then
        error "CRF value must be a positive integer"
        return 1
    fi
    if [[ $crf -lt 0 ]] || [[ $crf -gt 51 ]]; then
        error "CRF value must be between 0 and 51 (got: $crf)"
        return 1
    fi
    return 0
}

validate_qp() {
    local qp="$1"
    if ! [[ "$qp" =~ ^[0-9]+$ ]]; then
        error "QP value must be a positive integer"
        return 1
    fi
    if [[ $qp -lt 0 ]] || [[ $qp -gt 51 ]]; then
        error "QP value must be between 0 and 51 (got: $qp)"
        return 1
    fi
    return 0
}

validate_resolution() {
    local resolution="$1"
    if ! [[ "$resolution" =~ ^[0-9]+x[0-9]+$ ]]; then
        error "Resolution must be in format WIDTHxHEIGHT (e.g., 1920x1080)"
        return 1
    fi
    local width="${resolution%x*}"
    local height="${resolution#*x}"
    if [[ $width -lt 1 ]] || [[ $height -lt 1 ]]; then
        error "Resolution dimensions must be positive integers"
        return 1
    fi
    if [[ $width -gt 7680 ]] || [[ $height -gt 4320 ]]; then
        warn "Resolution exceeds 8K (7680x4320). This may cause performance issues."
    fi
    return 0
}

validate_bitrate() {
    local bitrate="$1"
    if ! [[ "$bitrate" =~ ^[0-9]+(\.?[0-9]*)?[KkMmGg]?$ ]]; then
        error "Bitrate must be a number optionally followed by K, M, or G (e.g., 5M, 2000K)"
        return 1
    fi
    return 0
}

validate_parallel_jobs() {
    local jobs="$1"
    if ! [[ "$jobs" =~ ^[1-9][0-9]*$ ]]; then
        error "Parallel jobs must be a positive integer"
        return 1
    fi
    if [[ $jobs -gt 32 ]]; then
        error "Parallel jobs cannot exceed 32 (got: $jobs)"
        return 1
    fi
    return 0
}

# Get video resolution from input file
get_video_resolution() {
    local input_file="$1"
    local width=""
    
    # Try to get video width using ffprobe in the container
    local ffprobe_cmd=(
        "podman" "run" "--rm"
        "--security-opt" "label=disable"
        "-v" "$(dirname "$(realpath "$input_file")"):/input:z"
        "$CONTAINER_IMAGE"
        "-v" "error"
        "-select_streams" "v:0"
        "-show_entries" "stream=width"
        "-of" "default=noprint_wrappers=1:nokey=1"
        "/input/$(basename "$input_file")"
    )
    
    width=$("${ffprobe_cmd[@]}" 2>/dev/null | head -1)
    
    if [[ -z "$width" ]] || ! [[ "$width" =~ ^[0-9]+$ ]]; then
        debug "Could not determine video width, using default quality"
        echo ""
    else
        debug "Detected video width: $width"
        echo "$width"
    fi
}

# Determine automatic quality based on resolution
get_auto_quality() {
    local width="$1"
    local is_gpu="$2"
    local quality=""
    
    # Default CRF values for software encoding
    local default_crf=24
    local crf_1280=26
    local crf_1920=28
    
    # For GPU encoding, add 2 to each value
    if [[ "$is_gpu" == "true" ]]; then
        ((default_crf+=2))
        ((crf_1280+=2))
        ((crf_1920+=2))
    fi
    
    # Determine quality based on width
    if [[ -z "$width" ]] || ! [[ "$width" =~ ^[0-9]+$ ]]; then
        quality=$default_crf
    elif [[ $width -gt 1920 ]]; then
        quality=$crf_1920
    elif [[ $width -gt 1280 ]]; then
        quality=$crf_1280
    else
        quality=$default_crf
    fi
    
    debug "Auto-quality: width=$width, is_gpu=$is_gpu, quality=$quality"
    echo "$quality"
}

# Check if hardware acceleration is available
check_hwaccel() {
    if [[ -c "$HWACCEL_DEVICE" ]]; then
        debug "Hardware acceleration device found: $HWACCEL_DEVICE"
        return 0
    else
        debug "Hardware acceleration device not found: $HWACCEL_DEVICE"
        return 1
    fi
}

# Check if Vulkan is available and detect GPU vendor
check_vulkan() {
    # Check if DRI device exists (required for Vulkan)
    if [[ ! -d "/dev/dri" ]]; then
        debug "No DRI devices found, Vulkan not available"
        return 1
    fi
    
    # Detect GPU vendor
    local gpu_vendor=""
    if command -v lspci >/dev/null 2>&1; then
        local gpu_info=$(lspci 2>/dev/null | grep -E "VGA|3D|Display" | head -1)
        if [[ "$gpu_info" =~ Intel ]]; then
            gpu_vendor="intel"
            debug "Intel GPU detected for Vulkan"
        elif [[ "$gpu_info" =~ AMD|ATI|Radeon ]]; then
            gpu_vendor="amd"
            debug "AMD GPU detected for Vulkan"
        elif [[ "$gpu_info" =~ NVIDIA|GeForce ]]; then
            gpu_vendor="nvidia"
            debug "NVIDIA GPU detected for Vulkan"
        fi
    fi
    
    # If lspci is not available, try checking render nodes
    if [[ -z "$gpu_vendor" ]] && [[ -e "/sys/class/drm/renderD128/device/vendor" ]]; then
        local vendor_id=$(cat /sys/class/drm/renderD128/device/vendor 2>/dev/null)
        case "$vendor_id" in
            "0x8086") gpu_vendor="intel" ;;
            "0x1002") gpu_vendor="amd" ;;
            "0x10de") gpu_vendor="nvidia" ;;
        esac
        debug "GPU vendor detected via sysfs: $gpu_vendor"
    fi
    
    if [[ -n "$gpu_vendor" ]]; then
        echo "$gpu_vendor"
        return 0
    else
        debug "Could not detect GPU vendor, but Vulkan may still work"
        echo "unknown"
        return 0
    fi
}

# List available encoders
list_encoders() {
    log "Listing available video encoders in container..."
    
    local podman_cmd=(
        "podman" "run" "--rm" "-it"
        "--security-opt" "label=disable"
        "$CONTAINER_IMAGE"
        "-encoders"
    )
    
    # Run the command and filter for video encoders
    "${podman_cmd[@]}" 2>/dev/null | grep -E "^ V.*" | sort
    
    exit 0
}

# Parse command line arguments
parse_args() {
    local args=()
    
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -h|--help)
                show_help
                exit 0
                ;;
            -q|--quality)
                QUALITY="$2"
                if [[ ! "${QUALITY_PRESETS[$QUALITY]+isset}" ]]; then
                    error "Invalid quality preset: $QUALITY"
                    exit 1
                fi
                shift 2
                ;;
            -c|--crf)
                if ! validate_crf "$2"; then
                    exit 1
                fi
                CUSTOM_CRF="$2"
                shift 2
                ;;
            -v|--video-codec)
                VIDEO_CODEC="$2"
                if [[ ! "${VIDEO_CODEC_MAP[$VIDEO_CODEC]+isset}" ]]; then
                    error "Invalid video codec: $VIDEO_CODEC"
                    exit 1
                fi
                shift 2
                ;;
            -a|--audio-codec)
                AUDIO_CODEC="$2"
                if [[ ! "${AUDIO_CODEC_MAP[$AUDIO_CODEC]+isset}" ]]; then
                    error "Invalid audio codec: $AUDIO_CODEC"
                    exit 1
                fi
                shift 2
                ;;
            -f|--format)
                OUTPUT_FORMAT="$2"
                shift 2
                ;;
            -o|--output-dir)
                OUTPUT_DIR="$2"
                shift 2
                ;;
            -O|--output-file)
                OUTPUT_FILE="$2"
                shift 2
                ;;
            --no-hwaccel)
                USE_HWACCEL="no"
                shift
                ;;
            --force-hwaccel)
                USE_HWACCEL="force"
                shift
                ;;
            --vulkan)
                PREFER_VULKAN=true
                shift
                ;;
            --resolution)
                if ! validate_resolution "$2"; then
                    exit 1
                fi
                RESOLUTION="$2"
                shift 2
                ;;
            --bitrate)
                if ! validate_bitrate "$2"; then
                    exit 1
                fi
                BITRATE="$2"
                shift 2
                ;;
            --preset)
                FFMPEG_PRESET="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --verbose)
                VERBOSE=true
                shift
                ;;
            --container)
                CONTAINER_IMAGE="$2"
                shift 2
                ;;
            --journal)
                USE_JOURNAL=true
                shift
                ;;
            --journal-file)
                USE_JOURNAL=true
                JOURNAL_FILE="$2"
                shift 2
                ;;
            --log-file)
                LOG_TO_FILE=true
                LOG_FILE="$2"
                shift 2
                ;;
            --log-level)
                LOG_LEVEL="$2"
                if [[ ! "$LOG_LEVEL" =~ ^(DEBUG|INFO|WARN|ERROR)$ ]]; then
                    error "Invalid log level: $LOG_LEVEL (must be DEBUG, INFO, WARN, or ERROR)"
                    exit 1
                fi
                shift 2
                ;;
            --no-log)
                LOG_TO_FILE=false
                shift
                ;;
            --force-reconvert)
                FORCE_RECONVERT=true
                shift
                ;;
            --list-encoders)
                list_encoders
                ;;
            --prefer-software)
                PREFER_SOFTWARE=true
                shift
                ;;
            --parallel)
                if ! validate_parallel_jobs "$2"; then
                    exit 1
                fi
                PARALLEL_JOBS="$2"
                shift 2
                ;;
            --parallel-child)
                # Internal flag to indicate this is a child process from moreutils parallel
                PARALLEL_CHILD=true
                shift
                ;;
            --movie)
                IS_MOVIE=true
                shift
                ;;
            --tv-series)
                IS_TV_SERIES=true
                shift
                ;;
            --video)
                IS_VIDEO=true
                shift
                ;;
            --tags)
                MEDIA_TAGS="$2"
                shift 2
                ;;
            --cpus)
                CONTAINER_CPUS="$2"
                shift 2
                ;;
            --memory)
                CONTAINER_MEMORY="$2"
                shift 2
                ;;
            --auto-quality)
                AUTO_QUALITY=true
                shift
                ;;
            --qp)
                if ! validate_qp "$2"; then
                    exit 1
                fi
                CUSTOM_QP="$2"
                shift 2
                ;;
            -*)
                error "Unknown option: $1"
                show_help
                exit 1
                ;;
            *)
                args+=("$1")
                shift
                ;;
        esac
    done
    
    # Store remaining arguments as input files
    INPUT_FILES=("${args[@]}")
    
    # Validate input files
    if [[ ${#INPUT_FILES[@]} -eq 0 ]]; then
        error "No input files specified"
        show_help
        exit 1
    fi
    
    # Check for conflicting options
    if [[ -n "${OUTPUT_FILE:-}" ]] && [[ ${#INPUT_FILES[@]} -gt 1 ]]; then
        error "Cannot use --output-file with multiple input files"
        exit 1
    fi
    
    # Check for conflicting media library options
    local media_count=0
    [[ "$IS_MOVIE" == "true" ]] && ((media_count++)) || true
    [[ "$IS_TV_SERIES" == "true" ]] && ((media_count++)) || true
    [[ "$IS_VIDEO" == "true" ]] && ((media_count++)) || true
    
    if [[ $media_count -gt 1 ]]; then
        error "Cannot use multiple media type options (--movie, --tv-series, --video) together"
        exit 1
    fi
}

# Build FFmpeg command arguments
build_ffmpeg_args() {
    local input_file="$1"
    local output_file="$2"
    local input_dir="$3"
    local output_dir="$4"
    local args=()
    
    # Determine hardware acceleration type
    local hw_type="none"
    local use_hw=false
    local gpu_vendor=""
    
    if [[ "$USE_HWACCEL" != "no" ]] && [[ "$PREFER_SOFTWARE" != "true" ]]; then
        # Check for Vulkan first if preferred
        if [[ "$PREFER_VULKAN" == "true" ]]; then
            gpu_vendor=$(check_vulkan)
            if [[ $? -eq 0 ]]; then
                hw_type="vulkan"
                use_hw=true
                debug "Using Vulkan with GPU vendor: $gpu_vendor"
            fi
        fi
        
        # Fall back to VAAPI if Vulkan not available or not preferred
        if [[ "$use_hw" == "false" ]] && check_hwaccel; then
            hw_type="vaapi"
            use_hw=true
        fi
        
        # Handle force mode
        if [[ "$USE_HWACCEL" == "force" ]] && [[ "$use_hw" == "false" ]]; then
            error "Hardware acceleration forced but no device available"
            exit 1
        fi
    else
        debug "Using software encoding (hardware acceleration disabled or software preferred)"
    fi
    
    # Determine if using GPU encoding
    local is_gpu_encoding=false
    if [[ "$hw_type" == "vaapi" ]] || [[ "$hw_type" == "vulkan" ]]; then
        is_gpu_encoding=true
    fi
    
    # Determine CRF/QP value
    local crf=""
    local qp=""
    
    if [[ "$AUTO_QUALITY" == "true" ]]; then
        # Get video resolution for auto quality
        local width=$(get_video_resolution "$input_file")
        local auto_value=$(get_auto_quality "$width" "$is_gpu_encoding")
        
        if [[ "$is_gpu_encoding" == "true" ]]; then
            qp="${CUSTOM_QP:-$auto_value}"
        else
            crf="${CUSTOM_CRF:-$auto_value}"
        fi
    else
        # Use manual settings
        if [[ "$is_gpu_encoding" == "true" ]] && [[ -n "$CUSTOM_QP" ]]; then
            qp="$CUSTOM_QP"
        else
            crf="${CUSTOM_CRF:-${QUALITY_PRESETS[$QUALITY]}}"
        fi
    fi
    
    # Build FFmpeg arguments based on acceleration type
    if [[ "$hw_type" == "vulkan" ]]; then
        args+=("-init_hw_device" "vulkan=vk:0")
        args+=("-hwaccel" "vulkan")
        args+=("-hwaccel_output_format" "vulkan")
    elif [[ "$hw_type" == "vaapi" ]]; then
        args+=("-vaapi_device" "/dev/dri/renderD128")
    fi
    
    # Determine input path in container
    local input_basename
    input_basename="$(basename "$input_file")"
    if [[ "$input_dir" == "$output_dir" ]]; then
        args+=("-i" "/config/${input_basename}")
    else
        args+=("-i" "/input/${input_basename}")
    fi
    
    # Video codec settings
    if [[ "$hw_type" == "vulkan" ]]; then
        # Vulkan uses h264_vulkan or hevc_vulkan encoders
        if [[ "$VIDEO_CODEC" == "h264" ]]; then
            args+=("-c:v" "h264_vulkan")
        elif [[ "$VIDEO_CODEC" == "h265" ]]; then
            args+=("-c:v" "hevc_vulkan")
        else
            # For other codecs, fall back to software (Vulkan only supports h264/h265)
            args+=("-c:v" "${VIDEO_CODEC_MAP[$VIDEO_CODEC]}")
            debug "Warning: Vulkan only supports h264/h265, falling back to software for $VIDEO_CODEC"
        fi
        
        # Vulkan needs format conversion and proper filter chain
        if [[ -n "${RESOLUTION:-}" ]]; then
            args+=("-vf" "format=nv12,hwupload,scale_vulkan=${RESOLUTION}")
        else
            # Even without scaling, Vulkan needs format conversion
            args+=("-vf" "format=nv12,hwupload")
        fi
    elif [[ "$hw_type" == "vaapi" ]] && [[ "$VIDEO_CODEC" == "h264" || "$VIDEO_CODEC" == "h265" ]]; then
        # VAAPI uses h264_vaapi but hevc_vaapi (not h265_vaapi)
        if [[ "$VIDEO_CODEC" == "h265" ]]; then
            args+=("-c:v" "hevc_vaapi")
        else
            args+=("-c:v" "${VIDEO_CODEC}_vaapi")
        fi
        
        # Hardware scaling if resolution is specified
        if [[ -n "${RESOLUTION:-}" ]]; then
            local width="${RESOLUTION%x*}"
            local height="${RESOLUTION#*x}"
            args+=("-vf" "format=nv12|vaapi,hwupload,scale_vaapi=w=${width}:h=${height}")
        else
            args+=("-vf" "format=nv12|vaapi,hwupload")
        fi
    else
        args+=("-c:v" "${VIDEO_CODEC_MAP[$VIDEO_CODEC]}")
        
        # Software scaling if resolution is specified
        if [[ -n "${RESOLUTION:-}" ]]; then
            args+=("-vf" "scale=${RESOLUTION}")
        fi
    fi
    
    # Quality settings
    if [[ -n "${BITRATE:-}" ]]; then
        # User specified bitrate
        args+=("-b:v" "$BITRATE")
    elif [[ "$hw_type" == "vulkan" ]]; then
        # Vulkan doesn't support CRF, use bitrate based on quality preset
        local vulkan_bitrate="${QUALITY_BITRATES[$QUALITY]}"
        args+=("-b:v" "$vulkan_bitrate")
        debug "Using bitrate $vulkan_bitrate for Vulkan (quality: $QUALITY)"
    elif [[ "$hw_type" == "vaapi" ]] && [[ -n "$qp" ]]; then
        # VAAPI with QP value
        args+=("-qp" "$qp")
        debug "Using QP $qp for VAAPI encoding"
    elif [[ -n "$crf" ]]; then
        # Use CRF for software encoding (and VAAPI without QP)
        args+=("-crf" "$crf")
        debug "Using CRF $crf for encoding"
    fi
    
    # FFmpeg preset if specified
    if [[ -n "${FFMPEG_PRESET:-}" ]]; then
        args+=("-preset" "$FFMPEG_PRESET")
    fi
    
    # Audio codec settings
    if [[ "$AUDIO_CODEC" == "copy" ]]; then
        args+=("-c:a" "copy")
    else
        args+=("-c:a" "${AUDIO_CODEC_MAP[$AUDIO_CODEC]}")
        
        # Audio quality settings
        if [[ "$AUDIO_CODEC" == "vorbis" ]]; then
            args+=("-q:a" "4")
        elif [[ "$AUDIO_CODEC" == "opus" ]]; then
            args+=("-b:a" "128k")
        fi
    fi
    
    # Language selection - keep English tracks and subtitles with fallbacks
    args+=("-map" "0:v")  # Keep video
    
    # Audio: keep all audio streams (or use first available)
    args+=("-map" "0:a?")
    
    # Subtitles (optional) - copy instead of converting to avoid format mismatch
    args+=("-map" "0:s?")
    
    # Subtitle codec - copy to preserve original format
    args+=("-c:s" "copy")
    
    # Determine output path in container
    local output_basename
    output_basename="$(basename "$output_file")"
    if [[ "$input_dir" == "$output_dir" ]]; then
        args+=("/config/${output_basename}")
    else
        args+=("/output/${output_basename}")
    fi
    
    # Output each argument on a separate line
    printf '%s\n' "${args[@]}"
    
    # Output GPU vendor info on a special line if using Vulkan
    if [[ "$hw_type" == "vulkan" ]] && [[ -n "$gpu_vendor" ]]; then
        printf '__GPU_VENDOR__%s\n' "$gpu_vendor"
    fi
}

# Process a single video file
process_video() {
    local input_file="$1"
    local output_file="$2"
    
    # Check journal to see if already converted
    if is_converted "$input_file" "$output_file"; then
        log "Skipping (already converted): $input_file"
        
        # Even if already converted, check if we need to copy to media library
        if [[ -f "$output_file" ]]; then
            if [[ "$IS_MOVIE" == "true" ]]; then
                # Check if already in movie library
                local basename="$(basename "$output_file")"
                local name="${basename%.*}"
                local movie_file="${MOVIES_DIR}/${name}/${basename}"
                
                if [[ ! -f "$movie_file" ]]; then
                    log "File converted but not in movie library, copying..."
                    if ! copy_to_movie_library "$output_file"; then
                        error "Failed to copy to movie library"
                        return 1
                    fi
                fi
            elif [[ "$IS_TV_SERIES" == "true" ]]; then
                # For TV series, checking is more complex due to directory structure
                # For now, just log that it was already converted
                debug "TV series file already converted, skipping library check"
            fi
        fi
        
        return 0
    fi
    
    log "Processing: $input_file -> $output_file"
    
    # Get absolute paths
    local input_dir="$(dirname "$(realpath "$input_file")")"
    
    # Create output directory if needed
    local output_parent="$(dirname "$output_file")"
    if [[ ! -d "$output_parent" ]]; then
        mkdir -p "$output_parent"
    fi
    
    local output_dir="$(realpath "$output_parent")"
    
    # Build FFmpeg arguments as array and extract GPU vendor
    local ffmpeg_args=()
    local gpu_vendor=""
    while IFS= read -r arg; do
        if [[ "$arg" =~ ^__GPU_VENDOR__(.*)$ ]]; then
            gpu_vendor="${BASH_REMATCH[1]}"
        else
            ffmpeg_args+=("$arg")
        fi
    done < <(build_ffmpeg_args "$input_file" "$output_file" "$input_dir" "$output_dir")
    
    # Build podman command
    local podman_cmd=(
        "podman" "run" "--rm" "-it"
        "--security-opt" "label=disable"
    )
    
    # Add resource limits if specified
    if [[ -n "$CONTAINER_CPUS" ]]; then
        podman_cmd+=("--cpus" "$CONTAINER_CPUS")
    fi
    if [[ -n "$CONTAINER_MEMORY" ]]; then
        podman_cmd+=("--memory" "$CONTAINER_MEMORY")
    fi
    
    # Add hardware acceleration device if needed
    if [[ "$USE_HWACCEL" != "no" ]]; then
        # For Vulkan, we need the entire /dev/dri directory
        if [[ "$PREFER_VULKAN" == "true" ]] && [[ -n "$gpu_vendor" ]]; then
            podman_cmd+=("--device=/dev/dri:/dev/dri")
            
            # Add vendor-specific Vulkan environment variable
            case "$gpu_vendor" in
                "intel")
                    podman_cmd+=("-e" "ANV_VIDEO_DECODE=1")
                    debug "Setting Intel Vulkan env: ANV_VIDEO_DECODE=1"
                    ;;
                "amd")
                    podman_cmd+=("-e" "RADV_PERFTEST=video_decode")
                    debug "Setting AMD Vulkan env: RADV_PERFTEST=video_decode"
                    ;;
                "nvidia")
                    # Nvidia requires beta drivers on host
                    debug "NVIDIA GPU detected - ensure Vulkan Beta drivers are installed"
                    ;;
                *)
                    # Try Intel env var as default
                    podman_cmd+=("-e" "ANV_VIDEO_DECODE=1")
                    debug "Unknown GPU vendor, trying Intel Vulkan env"
                    ;;
            esac
        elif check_hwaccel; then
            podman_cmd+=("--device=$HWACCEL_DEVICE:$HWACCEL_DEVICE")
        fi
    fi
    
    # Add volume mounts
    # If input and output directories are the same, mount once
    if [[ "$input_dir" == "$output_dir" ]]; then
        podman_cmd+=("-v" "${input_dir}:/config:z")
    else
        # Mount both directories - we'll need to adjust paths
        podman_cmd+=(
            "-v" "${input_dir}:/input:z"
            "-v" "${output_dir}:/output:z"
        )
    fi
    
    # Add container image and ffmpeg command
    podman_cmd+=(
        "$CONTAINER_IMAGE"
        "${ffmpeg_args[@]}"
    )
    
    # Show command if verbose or dry run
    if [[ "$VERBOSE" == "true" ]] || [[ "$DRY_RUN" == "true" ]]; then
        debug "Command: ${podman_cmd[*]}"
    fi
    
    # Execute command with retry logic (simplified for parallel child processes)
    if [[ "$DRY_RUN" == "false" ]]; then
        # Record start time for duration calculation
        local start_time=$(date +%s)
        
        # Retry logic variables - reduce retries for parallel child processes
        local max_retries=3
        if [[ "$PARALLEL_CHILD" == "true" ]]; then
            max_retries=1  # No retries in parallel child processes to avoid job queue issues
        fi
        
        local retry_count=0
        local success=false
        
        while [[ $retry_count -lt $max_retries ]] && [[ "$success" == "false" ]]; do
            if [[ $retry_count -gt 0 ]]; then
                log "Retry attempt $retry_count/$max_retries for: $input_file"
            fi
            
            # Execute the command and capture exit code and stderr
            local stderr_file=$(mktemp)
            "${podman_cmd[@]}" 2>"$stderr_file"
            local exit_code=$?
            
            if [[ $exit_code -eq 0 ]]; then
                rm -f "$stderr_file"
                success=true
                local end_time=$(date +%s)
                local process_duration=$((end_time - start_time))
                local duration_str=$(printf "%02d:%02d:%02d" $((process_duration/3600)) $(((process_duration%3600)/60)) $((process_duration%60)))
                
                log "Successfully compressed: $output_file (took $duration_str)"
                # Add to journal on success
                local retry_note=""
                if [[ $retry_count -gt 0 ]]; then
                    retry_note=" (succeeded after $retry_count retries)"
                fi
                add_to_journal "$input_file" "$output_file" "SUCCESS" "Processed in $duration_str$retry_note"
            else
                ((retry_count++))
                error "FFmpeg failed with exit code $exit_code (attempt $retry_count/$max_retries)"
                
                # Log stderr output for debugging
                if [[ -f "$stderr_file" ]] && [[ -s "$stderr_file" ]]; then
                    local stderr_content=$(tail -n 20 "$stderr_file")
                    error "FFmpeg stderr output:"
                    error "$stderr_content"
                fi
                
                # For parallel child processes, don't retry on failure to avoid blocking the queue
                if [[ "$PARALLEL_CHILD" == "true" ]]; then
                    rm -f "$stderr_file"
                    break
                fi
                
                # Check for specific exit codes that shouldn't be retried
                case $exit_code in
                    1)
                        # Generic error, worth retrying
                        debug "Generic error, will retry"
                        ;;
                    134|139)
                        # SIGABRT or SIGSEGV - definitely worth retrying
                        debug "Segmentation fault or abort detected, will retry"
                        ;;
                    *)
                        # Other exit codes might also be worth retrying
                        debug "Exit code $exit_code detected, will retry"
                        ;;
                esac
                
                # Small delay before retry to avoid hammering the system
                if [[ $retry_count -lt $max_retries ]]; then
                    sleep 2
                fi
            fi
        done
        
        # Clean up temp stderr file
        rm -f "$stderr_file"
        
        if [[ "$success" == "false" ]]; then
            error "Failed to compress after $max_retries attempts: $input_file"
            # Add failure to journal
            add_to_journal "$input_file" "$output_file" "FAILED" "Compression failed after $max_retries attempts"
            return 1
        fi
        
        # Copy to media library if requested
        if [[ "$DRY_RUN" == "false" ]] && [[ -f "$output_file" ]]; then
            if [[ "$IS_MOVIE" == "true" ]]; then
                if ! copy_to_movie_library "$output_file"; then
                    error "Failed to copy to movie library, but compression succeeded"
                    # Don't fail the entire operation if just the copy failed
                fi
            elif [[ "$IS_TV_SERIES" == "true" ]]; then
                if ! copy_to_tv_series_library "$output_file"; then
                    error "Failed to copy to TV series library, but compression succeeded"
                    # Don't fail the entire operation if just the copy failed
                fi
            elif [[ "$IS_VIDEO" == "true" ]]; then
                # Just add to media database without copying
                if ! add_to_media_db "$output_file" "video"; then
                    error "Failed to add to media database, but compression succeeded"
                    # Don't fail the entire operation if just the database add failed
                fi
            fi
        fi
    else
        log "[DRY RUN] Would execute: ${podman_cmd[*]}"
        # Add dry run entry to journal
        add_to_journal "$input_file" "$output_file" "DRY_RUN" "Command would be: ${podman_cmd[*]:0:50}..."
    fi
}

# Check if parallel is available for concurrent processing
check_parallel() {
    if ! command -v parallel >/dev/null 2>&1; then
        error "parallel is required for --parallel option but not found"
        error "Install with: sudo apt install parallel (or equivalent for your distro)"
        exit 1
    fi
    
    # Detect which version of parallel we have
    if parallel --version 2>&1 | grep -q "GNU parallel"; then
        PARALLEL_TYPE="gnu"
        debug "GNU parallel detected"
    else
        PARALLEL_TYPE="moreutils"
        debug "moreutils parallel detected"
    fi
}

# Copy file to movie library
copy_to_movie_library() {
    local output_file="$1"
    local basename="$(basename "$output_file")"
    local name="${basename%.*}"
    
    # Create movie directory
    local movie_dir="${MOVIES_DIR}/${name}"
    if [[ ! -d "$movie_dir" ]]; then
        debug "Creating movie directory: $movie_dir"
        mkdir -p "$movie_dir"
    fi
    
    # Copy file with rsync
    local dest_file="${movie_dir}/${basename}"
    log "Copying to movie library: $dest_file"
    if rsync -ruhv --progress "$output_file" "$dest_file"; then
        log "Successfully copied to movie library"
        # Add to media database
        add_to_media_db "$dest_file" "movie"
    else
        error "Failed to copy to movie library"
        return 1
    fi
}

# Add entry to media database
add_to_media_db() {
    local output_file="$1"
    local media_type="$2"
    
    # Check if media script exists
    if ! command -v media >/dev/null 2>&1; then
        debug "media script not found, skipping database entry"
        return 0
    fi
    
    # Run media ingest for the specific file
    debug "Adding $output_file to media database as $media_type"
    
    # Check if file exists before trying to ingest
    if [[ ! -f "$output_file" ]]; then
        error "Cannot add to media database: file does not exist: $output_file"
        return 1
    fi
    
    # Use ingest command which is more direct for single files
    # Use --update flag to ensure existing entries are updated with fresh metadata
    log "Running media ingest with update flag for: $output_file"
    if media ingest --type "$media_type" --path "$output_file" --update >/dev/null 2>&1; then
        debug "Successfully ingested/updated file in media database"
        
        # If tags were specified, update them
        if [[ -n "$MEDIA_TAGS" ]]; then
            debug "Attempting to add tags: $MEDIA_TAGS"
            
            # Use jq with --arg to safely pass the filepath (prevents injection)
            local media_id=$(media --format json search --type "$media_type" 2>/dev/null | \
                jq -r --arg filepath "$output_file" '.[] | select(.full_filepath == $filepath) | .id' 2>/dev/null | head -1)
            
            if [[ -n "$media_id" ]] && [[ "$media_id" != "null" ]]; then
                if media tag "$media_id" "$MEDIA_TAGS" >/dev/null 2>&1; then
                    log "Successfully updated tags for media ID $media_id"
                else
                    error "Failed to update tags for media ID $media_id"
                fi
            else
                warn "Could not find media ID for tagging. File path: $output_file"
                # Try alternative search by basename
                local basename=$(basename "$output_file")
                debug "Attempting to find media by basename: $basename"
                media_id=$(media --format json search --type "$media_type" 2>/dev/null | \
                    jq -r --arg name "$basename" '.[] | select(.name == $name) | .id' 2>/dev/null | head -1)
                
                if [[ -n "$media_id" ]] && [[ "$media_id" != "null" ]]; then
                    if media tag "$media_id" "$MEDIA_TAGS" >/dev/null 2>&1; then
                        log "Successfully updated tags for media ID $media_id (found by basename)"
                    else
                        error "Failed to update tags for media ID $media_id"
                    fi
                else
                    error "Could not find media entry for tagging"
                fi
            fi
        fi
        log "Successfully added to media database"
    else
        error "Failed to add to media database: $output_file"
        return 1
    fi
}

# Copy file to TV series library
copy_to_tv_series_library() {
    local output_file="$1"
    local basename="$(basename "$output_file")"
    
    # Extract series name (everything before the first ' - ')
    local series_name="${basename%% - *}"
    
    # Extract season number from SxxExx pattern
    local season=""
    if [[ "$basename" =~ S([0-9]{2})E[0-9]{2} ]]; then
        season="${BASH_REMATCH[1]}"
    else
        error "Could not extract season number from filename: $basename"
        error "Expected format: 'Series Name - SxxExx - Episode Title.ext' or 'Series Name - SxxExx.ext'"
        return 1
    fi
    
    # Create TV series directory structure
    local tv_dir="${TV_SERIES_DIR}/${series_name}/Season ${season}"
    if [[ ! -d "$tv_dir" ]]; then
        debug "Creating TV series directory: $tv_dir"
        mkdir -p "$tv_dir"
    fi
    
    # Copy file with rsync
    local dest_file="${tv_dir}/${basename}"
    log "Copying to TV series library: $dest_file"
    if rsync -ruhv --progress "$output_file" "$dest_file"; then
        log "Successfully copied to TV series library"
        # Add to media database
        add_to_media_db "$dest_file" "tv_series"
    else
        error "Failed to copy to TV series library"
        return 1
    fi
}

# Export function for parallel to use
export -f process_video log error warn debug write_log is_converted add_to_journal check_hwaccel check_vulkan build_ffmpeg_args copy_to_movie_library copy_to_tv_series_library add_to_media_db get_video_resolution get_auto_quality

# Wrapper function that parallel can call
process_video_wrapper() {
    local input_file="$1"
    local output_file="$2"
    
    # Reconstruct associative arrays from environment variables
    declare -A QUALITY_PRESETS=(["low"]="28" ["medium"]="23" ["high"]="18" ["veryhigh"]="15")
    declare -A QUALITY_BITRATES=(["low"]="2M" ["medium"]="5M" ["high"]="10M" ["veryhigh"]="20M")
    declare -A VIDEO_CODEC_MAP=(["h264"]="libx264" ["h265"]="libx265" ["vp9"]="libvpx-vp9" ["av1"]="libaom-av1")
    declare -A AUDIO_CODEC_MAP=(["vorbis"]="libvorbis" ["opus"]="libopus" ["aac"]="aac" ["mp3"]="libmp3lame" ["copy"]="copy")
    
    # Call the main processing function
    process_video "$input_file" "$output_file"
}

# Main function
main() {
    parse_args "$@"
    
    # Initialize logging
    init_logging "$@"
    
    # Initialize journal if enabled
    init_journal
    
    # Create output directory if it doesn't exist
    if [[ -z "${OUTPUT_FILE:-}" ]] && [[ "$DRY_RUN" == "false" ]]; then
        mkdir -p "$OUTPUT_DIR"
    fi
    
    # Check for parallel dependency if needed
    if [[ "$PARALLEL_JOBS" -gt 1 ]]; then
        check_parallel
    fi
    
    # Prepare job list for processing
    local job_list=()
    local failed=0
    local skipped=0
    
    for input_file in "${INPUT_FILES[@]}"; do
        # Check if input file exists
        if [[ ! -f "$input_file" ]]; then
            error "Input file not found: $input_file"
            ((failed++))
            continue
        fi
        
        # Determine output filename
        local output_file
        if [[ -n "${OUTPUT_FILE:-}" ]]; then
            output_file="$OUTPUT_FILE"
        else
            local basename="$(basename "$input_file")"
            local name="${basename%.*}"
            output_file="${OUTPUT_DIR}/${name}.${OUTPUT_FORMAT}"
        fi
        
        # Check if already converted (for counting)
        if is_converted "$input_file" "$output_file"; then
            ((skipped++))
        else
            # Add to job list for processing
            job_list+=("$input_file|$output_file")
        fi
    done
    
    # Process videos
    if [[ ${#job_list[@]} -gt 0 ]]; then
        if [[ "$PARALLEL_JOBS" -gt 1 ]] && [[ "$PARALLEL_CHILD" == "false" ]]; then
            # Use parallel processing
            log "Processing ${#job_list[@]} files with $PARALLEL_JOBS parallel jobs..."
            
            # Export the wrapper function and variables for parallel
            export -f process_video_wrapper
            export QUALITY CUSTOM_CRF VIDEO_CODEC AUDIO_CODEC OUTPUT_FORMAT USE_HWACCEL PREFER_VULKAN
            export PREFER_SOFTWARE CONTAINER_IMAGE HWACCEL_DEVICE VERBOSE DRY_RUN USE_JOURNAL 
            export JOURNAL_FILE FORCE_RECONVERT RESOLUTION BITRATE FFMPEG_PRESET PARALLEL_TYPE
            export IS_MOVIE IS_TV_SERIES IS_VIDEO MOVIES_DIR TV_SERIES_DIR
            export CONTAINER_CPUS CONTAINER_MEMORY AUTO_QUALITY CUSTOM_QP MEDIA_TAGS
            
            # Process jobs in parallel
            local parallel_failed=0
            
            if [[ "$PARALLEL_TYPE" == "gnu" ]]; then
                # GNU parallel syntax
                printf '%s\n' "${job_list[@]}" | parallel -j "$PARALLEL_JOBS" --colsep '|' \
                    'if ! process_video_wrapper "{1}" "{2}"; then exit 1; fi' || parallel_failed=$?
            else
                # moreutils parallel with retry mechanism at parent level
                # Build the command with all our current options
                local cmd_args=()
                [[ -n "$CUSTOM_CRF" ]] && cmd_args+=("--crf" "$CUSTOM_CRF")
                [[ "$QUALITY" != "medium" ]] && cmd_args+=("--quality" "$QUALITY")
                [[ "$VIDEO_CODEC" != "h265" ]] && cmd_args+=("--video-codec" "$VIDEO_CODEC")
                [[ "$AUDIO_CODEC" != "vorbis" ]] && cmd_args+=("--audio-codec" "$AUDIO_CODEC")
                [[ "$OUTPUT_FORMAT" != "mkv" ]] && cmd_args+=("--format" "$OUTPUT_FORMAT")
                [[ "$OUTPUT_DIR" != "output" ]] && cmd_args+=("--output-dir" "$OUTPUT_DIR")
                [[ "$USE_HWACCEL" == "no" ]] && cmd_args+=("--no-hwaccel")
                [[ "$USE_HWACCEL" == "force" ]] && cmd_args+=("--force-hwaccel")
                [[ "$PREFER_VULKAN" == "true" ]] && cmd_args+=("--vulkan")
                [[ "$PREFER_SOFTWARE" == "true" ]] && cmd_args+=("--prefer-software")
                [[ -n "${RESOLUTION:-}" ]] && cmd_args+=("--resolution" "$RESOLUTION")
                [[ -n "${BITRATE:-}" ]] && cmd_args+=("--bitrate" "$BITRATE")
                [[ -n "${FFMPEG_PRESET:-}" ]] && cmd_args+=("--preset" "$FFMPEG_PRESET")
                [[ "$VERBOSE" == "true" ]] && cmd_args+=("--verbose")
                [[ "$DRY_RUN" == "true" ]] && cmd_args+=("--dry-run")
                [[ "$USE_JOURNAL" == "true" ]] && cmd_args+=("--journal")
                [[ -n "$JOURNAL_FILE" ]] && [[ "$JOURNAL_FILE" != "./compress_video_journal.md" ]] && cmd_args+=("--journal-file" "$JOURNAL_FILE")
                [[ "$FORCE_RECONVERT" == "true" ]] && cmd_args+=("--force-reconvert")
                [[ "$IS_MOVIE" == "true" ]] && cmd_args+=("--movie")
                [[ "$IS_TV_SERIES" == "true" ]] && cmd_args+=("--tv-series")
                [[ "$IS_VIDEO" == "true" ]] && cmd_args+=("--video")
                [[ -n "$MEDIA_TAGS" ]] && cmd_args+=("--tags" "$MEDIA_TAGS")
                [[ -n "$CONTAINER_CPUS" ]] && cmd_args+=("--cpus" "$CONTAINER_CPUS")
                [[ -n "$CONTAINER_MEMORY" ]] && cmd_args+=("--memory" "$CONTAINER_MEMORY")
                [[ "$AUTO_QUALITY" == "true" ]] && cmd_args+=("--auto-quality")
                [[ -n "$CUSTOM_QP" ]] && cmd_args+=("--qp" "$CUSTOM_QP")
                
                # Implement retry logic at parent level for moreutils parallel
                local remaining_jobs=("${job_list[@]}")
                local max_retry_rounds=3
                local retry_round=0
                
                while [[ ${#remaining_jobs[@]} -gt 0 ]] && [[ $retry_round -lt $max_retry_rounds ]]; do
                    if [[ $retry_round -gt 0 ]]; then
                        log "Retry round $retry_round: ${#remaining_jobs[@]} files remaining"
                    fi
                    
                    # Extract input files from remaining jobs
                    local input_files=()
                    for job in "${remaining_jobs[@]}"; do
                        IFS='|' read -r input_file output_file <<< "$job"
                        input_files+=("$input_file")
                    done
                    
                    # Run moreutils parallel on current batch
                    debug "Executing moreutils parallel with ${#input_files[@]} files (round $((retry_round + 1)))"
                    
                    local batch_failed=0
                    parallel -j "$PARALLEL_JOBS" "$0" --parallel-child "${cmd_args[@]}" -- "${input_files[@]}" || batch_failed=$?
                    
                    # Check which jobs actually failed by examining journal/output files
                    local new_remaining_jobs=()
                    for job in "${remaining_jobs[@]}"; do
                        IFS='|' read -r input_file output_file <<< "$job"
                        
                        # Check if conversion was successful
                        if [[ -f "$output_file" ]] && [[ "$USE_JOURNAL" == "true" ]] && is_converted "$input_file" "$output_file"; then
                            # Success - don't add to retry list
                            continue
                        elif [[ -f "$output_file" ]] && [[ "$USE_JOURNAL" != "true" ]]; then
                            # Success without journal - don't add to retry list
                            continue
                        else
                            # Failed - add to retry list
                            new_remaining_jobs+=("$job")
                        fi
                    done
                    
                    remaining_jobs=("${new_remaining_jobs[@]}")
                    ((retry_round++))
                    
                    # If no jobs remain, we're done
                    if [[ ${#remaining_jobs[@]} -eq 0 ]]; then
                        break
                    fi
                    
                    # Small delay between retry rounds
                    if [[ $retry_round -lt $max_retry_rounds ]] && [[ ${#remaining_jobs[@]} -gt 0 ]]; then
                        log "Waiting 5 seconds before retry round $((retry_round + 1))..."
                        sleep 5
                    fi
                done
                
                # Set parallel_failed based on remaining jobs
                if [[ ${#remaining_jobs[@]} -gt 0 ]]; then
                    parallel_failed=${#remaining_jobs[@]}
                    error "Failed to process ${#remaining_jobs[@]} files after $max_retry_rounds retry rounds"
                fi
            fi
                
            # Count failures (parallel doesn't give us exact count, so we estimate)
            if [[ $parallel_failed -ne 0 ]]; then
                error "Some parallel jobs failed"
                failed=$parallel_failed
            fi
        else
            # Sequential processing
            for job in "${job_list[@]}"; do
                IFS='|' read -r input_file output_file <<< "$job"
                if ! process_video "$input_file" "$output_file"; then
                    ((failed++))
                fi
            done
        fi
    fi
    
    # Summary
    if [[ ${#INPUT_FILES[@]} -gt 1 ]]; then
        local processed=$((${#INPUT_FILES[@]} - failed - skipped))
        log "Summary: Processed $processed, Skipped $skipped, Failed $failed (Total: ${#INPUT_FILES[@]})"
        if [[ "$USE_JOURNAL" == "true" ]]; then
            log "Journal file: $JOURNAL_FILE"
        fi
    fi
    
    # Log final status
    if [[ "$LOG_TO_FILE" == "true" ]]; then
        log "Log file: $LOG_FILE"
        write_log "INFO" "=== Compression session completed ==="
        write_log "INFO" "Total files: ${#INPUT_FILES[@]}, Processed: $((${#INPUT_FILES[@]} - failed - skipped)), Failed: $failed, Skipped: $skipped"
    fi
    
    # Exit with error if any files failed
    if [[ $failed -gt 0 ]]; then
        exit 1
    fi
}

# Run main function
main "$@"
